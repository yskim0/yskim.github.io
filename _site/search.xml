<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title><![CDATA[StyleGAN:A Style-Based Generator Architecture for Generative Adversarial Networks]]></title>
      <url>/paper%20review/2020/09/20/StyleGAN/</url>
      <content type="text"><![CDATA[StyleGAN : A Style-Based Generator Architecture for Generative Adversarial Networks 를 읽고 정리한 글입니다.StyleGAN : A Style-Based Generator Architecture for Generative Adversarial Networks (CVPR 2019)Overview      GAN의 generator 부분은 black box로 여겨져 이미지 생성 과정을 이해하기 어려웠음.    style transfer 에서 기반한 generator 구조          각 레이어마다 style의 정보를 입힘. -&gt; AdaIN      전체적인 스타일(머리 색, 인종, 성별 등), 세세한 부분(곱슬 등) 등까지 조정 가능 -&gt; noise        baseline : progressive GAN          latent vector로 부터 이미지 합성하고 점점 해상도를 올려서 high-resolution image 생성 =&gt; scale-specific control            loss function, discriminator 등 수정하지 않고 오직 제너레이터에 대해서만 다룸.    latent space의 interpolation quality 측정하는 measure 제안          perceptual path length      linear separability        FFHQ 데이터셋 오픈Related work (Basic concepts)  Progressive GAN          GAN을 저해상도에서 고해상도로 점진적으로 학습        style transfer          content image &amp; style image가 있을 때 content 이미지와 유사하게 style image에 입히는 것      Methods(Explain one of the methods that the thesis used.)Generator Architecture      left : traditional generaotr : latent code z를 input layer에 바로 넣음.        right : style-based generator          first, map the input to an intermediate latent space W.      then controls the generator through adaptive instance normalization (AdaIN) at each conv. layer.      Gaussian noise is added after each conv.      제안한 모델을 차근차근 뜯어보자면Mapping Networkhttps://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431input vector z를 바로 input layer에 넣는 것이 아니라, mapping network를 거쳐 intermediate vector w 로 변환한 후 이미지를 생성한다.  바로 인풋 레이어에 넣지 않는 이유 : 고정된 input distribution에 맞춰야 해서 non-linear하게 mapping이 되고, 이것은 머리 색등과 같은 attribute를 변경하기 힘들어지기 때문.  위처럼 intermediate vector를 사용하게 되면 유동적인 공간에 mapping 시킬 수 있기 때문에 visual attribute 조절이 쉬워진다. =&gt; disentanglement 하다.즉, 이 네트워크에서는 z로부터 만들어진 style w를 구하고, 이를 affine transformation을 거친 A를 synthesis network에 넘겨주어 AdaIN operation을 통해 레이어에 스타일을 입힌다.Style Modules (AdaIN)https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431  위에서 생성된 w는 style에 대한 정보를 가지고 있다.  Synthesis network는 학습가능한 constant tensor(4x4x512)를 upsampling, convolution을 통해 1024x1024x3 이미지로 변환시킨다.  w의 affine transfomation을 통해 얻어진 A를 가지고 AdaIN operation을 통해 스타일을 입힌다.          normalize하고, 이를 scale하고 bias를 더함. 이게 스타일을 입히는 효과를 낸다.      매 conv 레이어마다 하므로, 각각의 레이어마다 다른 스타일을 조정할 수 있다. 이 말은 곧, 각 레이어가 특정한 attribute만을 담당한다는 뜻.                  세밀한 스타일 조정 가능해진다.                    Stochastic variation머리카락, 수염 등 stochastic한 요소들은 사진의 디테일에 매우 중요함.  위의 architecture에서 noise가 이에 대한 역할을 한다.  synthesis network에서 by adding per-pixel noise after each convolution.Style Mixingtwo random latent codes(w1,w2)를 사용하는 regularization 기법  하나의 w로 학습할 경우 여러 레이어에 대한 style이 correlate되는 문제점이 생길 수 있음.  ex. w1 스타일로 입혀놓지만, 랜덤으로 몇 개는 w2 스타일을 사용한다 …  위와 같은 방법을 통해 각 레이어가 담당하는 스타일을 명확하게 구분지을 수 있다.  (dropout과 비슷한 원리라고 함)Disentanglement studies  이 내용이 어려워서 제대로 이해하지 못함. 짧게 요약하겠음.  Disentanglment : latent space가 선형적인 구조를 가지게 되어, 하나의 factor가 움직였을 때 정해진 특성이 바뀌게 만드는 것.          예. z의 특정한 값을 바꿨을 때 생성되는 이미지의 하나의 특성(성별, 머리카락 길이 등)만 영향을 주게 되는 것        fixed distribution을 따르게 되면 억지로 끼워맞추게 되어 어색한 이미지가 만들어질 수 있음.  하지만 이 모델처럼 비선형 mapping function을 가지게 될 경우, 고정된 분포를 따를 필요가 없음.          위 그림에서 (c)와 같은 형태가 됨. 어느정도 a와 생김새가 비슷하면서 자연스럽게 맞출 수 있게 된 것        A major beneﬁt of our generator architecture is that the intermediate latent space W does not have to support sam-pling according to any ﬁxed distribution; its sampling density is induced by the learned piecewise continuous mapping f(z).  본 논문에서는 disentanglement를 학습할 수 있는 두 가지 평가 지표를 제안함.          Perceptual path length      Linear seperability      위의 내용을 자세히 알고 싶다면 이 곳을 참조                  링크                    Conclusion  our investigations to the separation of high-level attributes and stochastic effects, as well as the linearity of the intermediate latent space will prove fruitful in improving the understanding and controllability of GAN synthesis.Appendix. Truncation trick in W      트레이닝 중에 하는 게 아니고, generator가 만든 것 중에 더 나은 latent space 을 뽑는 법에 대한 trick        학습이 완료된 네트워크의 input을 제어하는 방법  위 수식을 통한 w' vector를 뽑는다.Additional studies(If you have some parts that cannot understand, you have to do additional studies for them. It’s optional.)disentanglement에 대한 명확한 이해가 필요함.References(References for your additional studies)  https://www.youtube.com/watch?v=TWzEbMrH59o&amp;feature=youtu.be  https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431  https://jayhey.github.io/deep%20learning/2019/01/16/style_based_GAN_2/  https://blog.lunit.io/2019/02/25/a-style-based-generator-architecture-for-generative-adversarial-networks/]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Computer Vision </tag>
        
          <tag> GAN </tag>
        
          <tag> Generative Model </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[HarDNet:A Low Memory Traffic network]]></title>
      <url>/paper%20review/2020/09/11/HarDNet/</url>
      <content type="text"><![CDATA[HarDNet : A Low Memory Traffic network 를 읽고 개인적으로 정리한 글입니다.HarDNet : A Low Memory Traffic network (ICCV 2019)Key Idea  기존의 metrics들에서의 inference time 측정은 부정확하다.          새로운 metric =&gt; memory traffic for accessing intermediate feature maps 측정                  inference latency 측정에 유용할 것, especially in such tasks as real-time object detection and semantic segmentation of high-resolution video.                    CIO : approximation of DRAM traffic이 될 수 있다.        computation, energy efficiency를 위해서는 fewer MACs, less DRAM이 좋은 것임 -&gt; 연구 방향  각각의 레이어의 MoC에 soft constraint를 적용했음.          low CIO network model with a reasonable increase of MACs를 위해      방법 -&gt; avoid to employ a layer with a very low MoC such as a Conv1x1 layer that has a very large input/output channel ratio.                  input/output channel ratio가 크면 low MoC를 가진다는 사실을 알 수 있음.                      Densely Connected Networks에 영감을 받아 모델 빌딩함.          DenseNet의 다수의 layer connections들을 줄였음. =&gt; concatenation cost를 줄이기 위해      balance the input/output channel ratio by increasing the channel width of a layer according to its connections.        DRAM trafficBasic Concepts  MAC : number of multiply-accumulate operations or floating point operations  DRAM : Dynamic Random-Access Memory          read/write model param. and feature maps        CIO : Convolutional input/output          모든 conv layer에 대해 IN(C,W,H) X OUT(C,W,H) sum        MoC : MACs over CIO of a layer = MACs/CIORelated Works  TREND : exploiting shortcuts  Highway networks, Residual Networks : add shortcuts to sum up a layer with multiple preceeding layers.  DenseNet : concatenates all preceeding layers as a shortcut achieving more efficent deep supervision.  그러나 shortcuts는 large memory usage, heavy DRAM traffic을 유발할 수 있다.                            Using shortcuts elongates the lifetime of a tensor, which may result in frequent data exchanges betwwen DRAM and cache.                      DenseNet의 sparsified version : LogDenseNet, SparseNet          Sparse                  The pros? If you have a lot of zeros, you don’t have to compute some multiplications, and you don’t have to store them. So you may gain on size and speed, for training and inference (more on this today).          The cons? Of course, having all these zeros will probably have an impact on network accuracy/performance.                    increase the growth rate(output channel width) to recover the accuracy dropping from the connection pruning, and the increase of growth rate can compromise the CIO reduction                  즉 increase of growth rate는 좋게 작용된다.                    Harmonic DenseNetSparsification and weighting  let layer k connect to layer k-2^n if 2^n divides k, where n is a non-negative integer and k-2^n &gt;= 0class HarDBlock(nn.Module):    def get_link(self, layer, base_ch, growth_rate, grmul):        if layer == 0:          return base_ch, 0, []        out_channels = growth_rate        link = []        for i in range(10):          dv = 2 ** i          if layer % dv == 0:            k = layer - dv            link.append(k)            if i &gt; 0:                out_channels *= grmul        out_channels = int(int(out_channels + 1) / 2) * 2        in_channels = 0        for i in link:          ch,_,_ = self.get_link(i, base_ch, growth_rate, grmul)          in_channels += ch        return out_channels, in_channels, link  2^n 개의 layer들이 이런 식으로 processed되면 layer [1 : 2^n -1]는 메모리에서 flush된다.          어떻게 flush 된다는 건지 잘 이해가 되지 않음.        Power-of-two-th harmonic waves가 만들어짐. 그래서 Harmonic 이다.      이 방식은 concatenation cost를 눈에 띄게 감소시킨다.        layers with an index divided by a larger power of two are more influential than those that divided by a smaller power of two.          많이 connection되니까 당연히 influential 하다.      In this model, they amplify these key layers by increasing their channels, which can balance the channel ratio between the input and output of a layer to avoid a low MoC.                  이런 key layer들을 amplify 했음(channel 수를 늘리면서)                      layer l has an initial growth rate k, we let its channel number to be k * m^n , where n is the max number satisfying that l is divided by 2^n                    m  은 low-dimensional compression factor 역할을 한다.          m 을 2보다 작게하면 input channel을 output channel보다 작게 할 수 있다.                          Empirically, settin m between 1.6 and 1.9                                          Transition and Bottleneck Layers  HDB(Harmonic Dense Block) : the proposed connection pattern forms a group of layers          is followed by a Conv1x1 layer as a transition        HDB의 depth는 2의 제곱수로 설정          HDB의 마지막 레이어가 가장 큰 채널수를 가지도록 하기 위해서        DenseNet -&gt; gradient할 때 모든 레이어를 다 pass함  논문의 HBD with depth L -&gt; pass through at most log L layers          degradation을 완화시키기위해, depth-L HDB를 layer L과 all its preceeding odd numbered layers  를 concatenation시킨다.      2~L-2의 all even layer들의 아웃풋은 HDB가 한번 끝날때마다 버려진다.        Bottleneck layer          DenseNet에서는 param. efficiency를 위해 매 Conv3x3 layer전에 bottleneck을 두었다.      하지만 HarDnet에서는 위에서 이미 channel ratio(매 레이어마다 input&amp;output 사이의)의 균형을 잡았으므로 bottleneck layer는 쓸모없어진다.      그래서 HBD에서는 Bottleneck layer없이 Conv3x3 for all layers        Transition layer                inverted trainsition module                  maps input tensor to an additional max pooling function along with the original average pooling, followed by concatenation and Conv1x1.          50% of CIO를 감소시킴                    Experiments      CamVid Dataset          replace all the blocks in a FC-DenseNet with HDBs      the architecture of FC-DenseNet with an encoder-decoder structure and block level shortcuts to create models for sematic segmentation.              We propose FC-HarDNet84 as specified in Table 3 for comparing with FC-DenseNet103. The new network achieves CIO reduction by 41% and GPU inference time reduction by 35%. A smaller version, FC-HarDNet68, also outperforms FC-DenseNet56 by a 65% less CIO and 52% less GPU inference time.        ImageNet Datasets  Object Detection          HarDNet-68 as a backbone model for a Single Shot Detector (SSD) and train it with PASCAL VOC 2007 and MS COCO datasets      Discussion  There is an assumption with the CIO, which is a CNN model that is processed layer by layer without a fusion. In contrast, fused-layer computation for multiple convolutional layers has been proposed.  CIO still failed to predict the actual inference time such as comparing two network models with significantly differnent architectures  In some of the layers CIO may dominate, but for the other layers, MACs can still be the key factor if its computational density is relatively higher. To precisely predict the inference latency of a network, we need to breakdown to each of the layers and investigate its MoC to predict the inference latency of the layer.  어쨌거나 DRAM traffic의 중요성을 강조하고 싶어함.  traffic reduction을 위한 가장 좋은 방법은 MoC를 증가시키는 것          which might be counter-intuitive to the widely-accepted knowledge of that using more Conv1x1 achieves a higher efficiency.      ]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Traffic </tag>
        
          <tag> Computer Vision </tag>
        
          <tag> Semantic Segmentation </tag>
        
          <tag> Network </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Neural Architecture Search With Reinforcement Learning]]></title>
      <url>/paper%20review/2020/08/29/NEURAL-ARCHITECTURE-SEARCH-WITH-REINFORCEMENT-LEARNING/</url>
      <content type="text"><![CDATA[Neural Architecture Search With Reinforcement Learning 논문을 읽고 정리한 글입니다.Overview(You should include contents of summary and introduction.)  we use a re- current network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set.RNN을 이용해서 neural network의 model description(하이퍼 파라미터: # of filters, stride length …)을 문자열로 생성한다.강화학습을 통해 expected accuracy를 최대로 만든다.  Controller에서 p의 확률로 A라는 Architecture를 생성한다.  자식 네트워크에서는 A 아키텍쳐를 훈련시켜 정확도 R을 구한다.  정확도를 리워드의 신호로 사용한다. policy gradient를 계산해서 컨트롤러를 업데이트한다.  반복하다보면 더 높은 확률로 더 높은 정확도를 보이는 아키텍쳐를 찾을 수 있다.Related work (Basic concepts)NAS 부분의 거의 최초라고 볼 수 있음.이전 연구들 : Hyperparameter optimization  it is difficult to ask them to generate a variable-length configuration that specifies the structure and connectivity of a network유전자 알고리즘  search-based 방식이라 탐색속도가 느림.컨트롤러에서의 Neural Architecture 방식은 이전 예측값들을 input으로 받아 하이퍼 파라미터를 한 번에 하나씩 예측하는 auto-regressive한 방식이다.Methods(Explain one of the methods that the thesis used.)이 논문의 Key point : skip connection 예측하여 모델의 복잡도를 높인 것, 파라미터 접근방식을 사용해서 훈련 속도를 높인 것  Generate Model with a Controller Recurrent Neural Network  It predicts filter height, filter width, stride height, stride width, and number of filters for one layer and repeats. Every prediction is carried out by a softmax classifier and then fed into the next time step as input.컨트롤러를 이용하여 CNN 모델에 사용하는 하이퍼파라미터들을 생성함.레이어마다 사용할 필터, Stride 값을 예측하고 반복함.하이퍼 파라미터 예측시에 softmax classifier를 거친값이 다음 스텝의 input으로 들어감.컨트롤러 RNN이 아키텍쳐를 생성하면 생성된 아키텍쳐의 뉴럴 네트워크를 훈련시킴.  The parameters of the controller RNN, θc, are then optimized in order to maximize the expected validation accuracy of the proposed architectures.Validation set으로 네트워크의 정확도를 측정하고, 컨트롤러 RNN의 파라미터 세타C는 정확도의 기대값을 최대화하기 위해 최적화됨.  Training with Reinforce      controller to maximize its expected reward        컨트롤러 token list a[1]:a[T] : Architecture predicted by the controller RNN viewed as a sequence of actions    자식 네트워크는 생성된 구조의 정확도 R을 출력하고, 이 R을 강화학습의 리워드로 사용해서 컨트롤러를 강화학습 훈련시킴.  Layer 하나짜리 CNN에서의 T=3임.          a1 : filter height      a2 : filter width      a3 : # of filters        In this work, we use the REINFORCE rule from Williams (1992)  Standard REINFORCE Update Rule  R은 미분 불가능함. =&gt; policy gradient를 써서 세타 C를 업데이트한다.Accelerate Training with Parallelism and Asynchronous Updates  자식 네트워크 : 하나의 모델을 뜻함  여러 컨트롤러 * 여러 자식 네트워크 =&gt; 많은 네트워크를 만들어냄          훈련 속도를 높이기 위해 파라미터-서버 구조 사용      S개의 파라미터 서버가 있고 이 서버와 연결된 K개의 복제된 컨트롤러에 공유된 파라미터 값이 저장됨.각각의 컨트롤러는 m개의 자식 네트워크를 복제해서 병렬로 훈련시킴.이 때 자식 네트워크의 정확도는 파라미터 서버에 보낼 세타 C에 대한 gradient를 계산하기 위해 기록됨.  Increase Architecture Complexity with Skip Connection and Other Layer TypesSkip connection을 추가해서 탐생 공간을 넓힌다.레이어마다 anchor point를 더해서 이전 레이어들 중 어떤 레이어를 현재 레이어의 input으로 할지 결정함.  Generate Recurrent Cell Architectures지금까지 CNN을 위한 Neural Architecture, 지금은 RNNRNN, LSTM은 x(t), h(t-1)을 input으로 하고 h(t)를 output으로 하는 트리구조로 나타낼 수 있음(맨 오른쪽)RNN 컨트롤러에서는 트리 노드들의 결합방석(addition, elementwise multiplication)과 활성화함수(sigmoid,tanh)를 선택할 수 있음.  그림 (b)의 Cell indices 의 왼쪽 1부분이 의미하는 것은 다음 메모리구조 C_t와 연결되는것은 Tree index 1 이며 오른쪽 0부분은 h_t 를 구할때 사용되는 것이 Tree index 0 이라는 것입니다. 그림 (b)의 Tree index 2 는 Tree0과 Tree1의 결합방식을 나타내는 것으로 그림에선 elementwise multiplication와 sigmoid의 결합이 됩니다.Experiments기존 SOTA 모델과 비교했을 때 약간의 성능 감소는 있었지만 더 작은 파라미터로 구현이 되었음,  CNN (CIFAR-10 dataset)  RNN (Penn Treebank dataset)  Transfer Learning on Neural Machine Translation          LSTM을 빼고 NAS를 통해 만든 cell을 넣었음.      LSTM에 특화된 하이퍼파라미터들을 튜닝하지 않음      BELU score 0.5 오름      Additional studies(If you have some parts that cannot understand, you have to do additional studies for them. It’s optional.)      Understanding Deep Learning Requires Rethinking Generalization        Designing Neural Network Architectures Using RL  References(References for your additional studies)https://www.youtube.com/watch?v=XP3vyVrrt3Qhttps://medium.com/@sunwoopark/slow-paper-neural-architecture-search-with-reinforcement-learning-6de601560522]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Reinforcement Learning </tag>
        
          <tag> Neural Architecture Search </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[딥러닝 모델을 이용한 수화 교육 웹 어플리케이션-Handlang(2)]]></title>
      <url>/project/2020/08/26/Handlang2/</url>
      <content type="text"><![CDATA[DSC EWHA에서 2019.9~2020.8 까지 진행한 팀프로젝트로, 딥러닝 모델을 이용한 수화 학습 웹 어플리케이션입니다.이 포스팅에서는 웹에 관련된 것을 다룹니다.Handlang - ASL(American Sign Language) Education by using deep learning model딥러닝으로 학습된 수화 인식 모델을 바탕으로 알파벳, 숫자에 해당되는 수화를 학습 및 연습 할 수 있는 웹 어플리케이션입니다.Wireframe - FigmaFigma를 사용하여 팀원들과 홈페이지 와이어프레임을 구상하였습니다.Flask웹 개발 초보자에게 비교적 쉬운 Flask를 사용하여 구현하였습니다.Model Deploy  학습시킨 모델을 불러오는 법...from keras.models import load_model...model = load_model('model/handlang_model_4.h5') # 지문자 모델model2 = load_model('model/su_adamax.h5') # 숫자 모델Ajax웹캠으로 받은 이미지를 실시간으로 Detect해야하기 때문에 페이지를 새로 고치지 않아도 데이터를 로드할 수 있는 Ajax를 사용하였습니다.Translation한글/영어 버전의 웹페이지를 구현하기 위해 flask_babel을 사용했습니다.Study &amp; QuizTeam HandlangProject Github Link]]></content>
      <categories>
        
          <category> Project </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Object Detection </tag>
        
          <tag> Flask </tag>
        
          <tag> Education Application </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[딥러닝 모델을 이용한 수화 교육 웹 어플리케이션-Handlang(1)]]></title>
      <url>/project/2020/08/26/Handlang/</url>
      <content type="text"><![CDATA[DSC EWHA에서 2019.9~2020.8 까지 진행한 팀프로젝트로, 딥러닝 모델을 이용한 수화 학습 웹 어플리케이션입니다.이 포스팅에서는 수화 인식 딥러닝 모델에 대해서만 다룹니다.Handlang - ASL(American Sign Language) Education by using deep learning model딥러닝으로 학습된 수화 인식 모델을 바탕으로 알파벳, 숫자에 해당되는 수화를 학습 및 연습 할 수 있는 웹 어플리케이션입니다.모델 정확도 개선을 위한 여러 시도들[About models]YOLO darknetYOLO is the model with excellent performance in Object detection.We used darkflow, not yolo darknet, to take advantage of tensorflow.https://github.com/thtrieu/darkflowThe most attempts were made at darkflow.  YOLO_experiment_1          [a~z] 600 images each. training 500 epochs      acc : 0.42      Feedback -&gt; Predict performance is poor.  YOLO_experiment_2          pretrained weight - hand tracking model (https://github.com/Abdul-Mukit/dope_with_hand_tracking)      a~y 600 images each. 140 epochs      acc : 0.47              YOLO_experiment_3          pretrained weight - yolov2-tiny.weight(https://pjreddie.com/darknet/yolov2/)      a~y 600 images each. 220 epochs      acc : 0.56            Feedback -&gt; It is still not a satisfactory performance.Inception-v3We tried transfer learning by using inception-v3.  a~y 600 images each. 1000 steps  test acc. : about 88%          but not that much at real-time…            Tensorflow-Object-Detection-APIWe tried transfer learning by using fast r-cnn.  a~y 600 images each. 6000 steps  test acc. : about 80%          not test by images, but test by webcam.                  poor performance                    Self-feedback: It is still not a satisfactory performance.Finally Custom CNN model(our current model)!handlang_model = Sequential()handlang_model.add(Conv2D(64, kernel_size=4, strides=1, activation='relu', input_shape=target_dims))handlang_model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))handlang_model.add(Dropout(0.5))handlang_model.add(Conv2D(128, kernel_size=4, strides=1, activation='relu'))handlang_model.add(Conv2D(128, kernel_size=4, strides=2, activation='relu'))handlang_model.add(Dropout(0.5))handlang_model.add(Conv2D(256, kernel_size=4, strides=1, activation='relu'))handlang_model.add(Conv2D(256, kernel_size=4, strides=2, activation='relu'))handlang_model.add(Flatten())handlang_model.add(Dropout(0.5))handlang_model.add(Dense(512, activation='relu'))handlang_model.add(Dense(n_classes, activation='softmax'))handlang_model.summary()handlang_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=["accuracy"])Feedback : 위 모델을 사용하고, 웹 코드 내에서의 trick을 이용하여 조금 더 빠른 인식과 높은 정확도를 가질 수 있었음.Datasets아래 데이터 셋들은 모델 트레이닝에 사용되었습니다.참고로, 우리 모델에서는 알파벳 i,z 제외했습니다. (손동작이 포함되었기 때문에)  https://www.kaggle.com/grassknoted/asl-alphabet          가장 성능이 좋은 모델에 사용된 데이터 셋입니다.      다른 모델에서는 아래의 데이터셋들을 사용했습니다.  https://www.kaggle.com/rajarshighoshal/asltestimages  https://www.kaggle.com/muhammadkhalid/sign-language-for-alphabets  https://www.kaggle.com/ayuraj/asl-datasetTeam HandlangProject Github Link]]></content>
      <categories>
        
          <category> Project </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Object Detection </tag>
        
          <tag> Flask </tag>
        
          <tag> Education Application </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Meta Reinforcement Learning As Task Inference]]></title>
      <url>/paper%20review/2020/08/22/Meta-RL-as-task-inference/</url>
      <content type="text"><![CDATA[Tensorflow KR 논문 읽기 모임 PR12(Season 3)의 Meta Reinforcement Learning As Task Inference (PR-239)를 발표하신 정창훈님 영상을 보고 정리하였습니다.Meta Reinforcement Learning As Task InferenceOverview(You should include contents of summary and introduction.)  접근 방법 : Meta-RL을 하나의 paritally observed로 본다.          MDP의 모든 정보를 agent가 전부 받는 게 아니라 부분적으로만 관찰      RL은 하나의 control문제로 볼 수 있는데, 여기에 inference problem이 추가된 것        즉 POMDP(Partially-Observable Markov Decision Processes)문제를 해결하는 문제가 됨.          POMDP의 솔루션 : observation trajetory를 가지고 optimal policy를 찾는 것(미래 보상이 최대가 되는 쪽으로) == Reinforcement learning                  그러나 주어진 데이터가 partially observation이기 때문에 또 하나의 모듈이 필요함 -&gt; belief state                      Belief State : 어떤 observation trajectory가 주어졌을 때 실제 true state의 probability          이걸 구할 수 있으면 POMDP가 구해짐                  POMDP가 구해지면 Meta-RL 문제 해결!                    Observation이 주어졌을 때 optimal policy를 구하는 것은 belief state를 구할 수 있으면 문제가 풀린다!-&gt; 그러면 Meta-RL 문제도 풀린다.  이 논문의 key point : 두 가지 Neural Network를 사용          control하는 policy Network      belief state를 예측하는 inference Belief Module                  auxilary supervised learning 로 해결 (Meta-learning때에만)          즉, belief module은 meta-learning 때 supervised learning으로 학습됨.                      off-policy 사용(Meta-RL 에서는 대개 on-policy)Related work (Basic concepts)  Meta Learning : Learning to Learn      A trajectory is just a sequence of states and actions.    Meta RL          env.는 MDP로 표현됨. M = {S,A,P,r}      Agent &lt;-&gt; env. : 서로 interact하면서 future reward를 Max. 시키는 세타 찾기      Meta learning : 여러 개의 task들을 sampling하여 meta-learning한 후, meta-test시 빠르게 adaption될 수 있어야 함.                  RL -&gt; 그 task들 각각이 하나의 MDP로 정의 가능!                                  MDP를 여러개 sampling해서 학습하고, 그걸 통해 optimal theta얻는 것이 목표          test시에는 처음 보는 태스크(전체적인 쉐잎은 비슷해야)에 잘 적용되어야 함.                    접근 방법                  Recurrent policies : RNN          Optimization problem : MAML          partially observed RL                          MDP의 모든 정보를 받는 게 아니라 부분적으로만 받는다 -&gt; inference problem 추가됨                                                  z : task들의 모든 정보를 담고 있는 true information              z를 inference하면서 RL 컨트롤도 할 수 있는 해석하는 관점                                            MDP(Markov Decision Processes) : (X,A,P,p0, R, discount factor)          control이 있다 -&gt; 대표적으로 RL      state가 완전히 관측되냐, 부분적으로 관측이 되냐 -&gt; MDP/POMDP        POMDP(Partially-Observable Markov Decision Processes)          MDP의 general한 버전      MDP에서 omega, O가 추가됨      X : state space. Agent 입장에서는 부분적으로 관측/아예 관측할 수 없게 됨.      그래서 Agent는 부분적으로 관측되는 observation state를 통해서만 학습할 수 있음.              off-policy algorithm : 현재 학습하는 policy가 과거에 했던 experience도 학습에 사용이 가능하고, 심지어는 해당 policy가 아니라 예를 들어 사람이 한 데이터로부터도 학습을 시킬 수가 있다.    on-policy : 1번이라도 학습을 해서 policy improvement를 시킨 순간, 그 policy가 했던 과거의 experience들은 모두 사용이 불가능하다.Methods(Explain one of the methods that the thesis used.)      Solution to POMDP          observed trajectory를 가지고 optimal policy를 찾는 것(미래 보상의 합이 최대가 되는 action set, policy) == RL      그러나 주어진 데이터가 partially 하기 때문에 또 하나의 모듈이 필요함      Belief State 를 구할 수 있으면 위의 문제가 풀림.      Belief State -&gt; POMDP -&gt; Meta-RL 해결        최근 Meta-RL에서의 POMDP 해석 문제          방금까지는 unobserved state      But 우리는 unobserved task        내가 어느 task를 풀고 있는지 모르는 상태      state를 완전히 관측을 못한다는 것이 아니라!! 내가 어떤 task를 풀고 있는지를 관측하지 못한다는 관점으로 문제를 푸는 것임 == 어떤 task를 풀어야 하는지 task 정보를 완전하게 관측할 수 X -&gt; 그래서 Task Inference                  State, Action은 모든 MDP간에 sharing되어 있음. W가 붙은 것들은 task-specific함.                  이 세가지에 접근해서 Meta RL을 푼다.                    목표 : meta-test시 처음 보는 task에도 적은 interaction으로 reward를 Max. 시키는 optimal policy 찾기            Meta-RL using POMDP    A, S는 sharing      - S는 true state와 Agent 입장에서 모르는 task에 대한 w를 concat해서 만듦          나머지들은 task-specific하게 정의      w만이 agent입장에서는 unobserved state라고 정의            optimal agent pi*는 아래와 같은 문제를 푼다.    agent입장에서는 실제 task label인 w에 access 할 수 없다고 가정. (task에 대한 MDP를 다 모르는 것)          과거 observation trajectories은 LSTM, GRU등으로 agent network는 학습할 수 있음.      POMDP 문제를 해결하려면 task에 대한 belief state를 계산할 수 있어야 함.                  observation trajectory가 주어졌을 때 실제 true task일 확률 (posterior)                          이걸 계산할 수 있으면 POMDP 문제 해결, 그러나 계산 어려움.                                appendix)                        belief state의 posterior는 bayes Rule과 유사  policy가 식 안에 없음 -&gt; task에 대한 posterior는 policy와 independent하다.  off-policy algorithm 사용 가능 (보통 meta-RL에서는 on-policy : 데이터를 모으자마자 바로 업데이트)Train어떻게 모델을 학습시키는가      current state x와 current belief b_t(w)만 있으면 가능    앞서 언급한 z 가 여기서는 belief state(task에 대한 모든 정보를 담고 있다)  belief state estimate 가능 -&gt; optimal policy 구할 수 있다.  컴퓨팅 어려움 -&gt; 2가지 NN 모델로 approximate 해야 한다.      Control하는 Policy Network        Belief Module    어떻게 학습시키는가?          Meta-Learning 안에서는 Supervised Learning이 된다.                  label 가능성                          Task Description : task를 잘 표현하는 representation.              Expert actions              Task embeddings                                            meta-learning 때에만 사용. 실제 우리가 원하는 meta-test에서 적은 에피소드만으로 빠르게 adapt할 때는 이 정보들을 더이상 사용하지 않음.      task를 supervised learning으로 풀었다!      w, h_t : independent of policy =&gt; belief network도 off-policy로 효율적으로 학습 가능      ArchitectureLSTM, IB : optional (IB : regularization 효과)A. Baseline LSTM Agent : belief network가 없는 일반 agentB. 논문에서 제안된 모델 : trajectory 넣어서 Belief network 학습    - Belief feature + trajectory 해서 policy network 학습    - 각자 역할에 집중C. Mixed : Network 하나에 합친 것Experiment  Multi-armed bandit : 20 arms and 100 horizon.          20번 당겼을 때 reward probability =&gt; task description. (arm들의 vec.)        Semicircle : 반원 안에서 naviagtion          task desription : 각도        cheetah : task description -&gt; velocityMain contributions  Supervised Learning을 통해서 performance 높임  Belief network 학습시킬 때 off-policy 알고리즘 사용 가능  continuous, sparse rewards 환경에서도 좋았다Additional studies(If you have some parts that cannot understand, you have to do additional studies for them. It’s optional.)POMDPBelief State?References(References for your additional studies)https://www.youtube.com/watch?v=phi7_QIhfJ4 - 논문 설명https://newsight.tistory.com/250 - policy 부분 개념]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Meta Learning </tag>
        
          <tag> Reinforcement Learning </tag>
        
          <tag> Meta RL </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Model-Agnostic Meta-Learning for fast adaptation of deep networks]]></title>
      <url>/paper%20review/2020/08/14/Model-Agnostic-Meta/</url>
      <content type="text"><![CDATA[Model-Agnostic Meta-Learning for fast adaptation of deep networks 를 읽고 정리한 글입니다.Model-Agnostic Meta-Learning for fast adaptation of deep networksOverview(You should include contents of summary and introduction.)좋은 Weight로 initialize하는 방법에 대한 것.어떻게 하면 좋은 initial weight를 찾을 수 있는가?어떤 inital weight를 가지면 모르는 태스크들에 대해서도 빨리 적응시킬 수 있는가?  Key Point- **주어진 태스크들에 대해서 1 step 갔을 때, 모든 태스크에 대해서 로스가 미니멈이 되는 현재의 세타를 찾는 것!**Related work (Basic concepts)  Model-Agnostic          학습에 사용된 model이 무엇인지에 구애받지 않고 독립적으로 모델을 해석할 수 있다는 뜻      즉, 학습에 사용되는 모델과 설명에 사용되는 모델을 분리      이 방법은 어떤 모델이든 상관 없이 적용할 수 있는 방법이다.        Meta learning          learning to learn      좋은 메타 러닝 모델 = 트레이닝 때 접하지 않았던 새로운 태스크나 환경에 대해서 잘 적응되거나 일반화가 잘 됨.      Reinforcement learning과 결합한 meta-learning(meta reinforcement learning) 얘기가 많이 나오고 있음      Few-shot classification은 supervised-learning 상황에서 meta-learning을 활용한 예시임.                  하나의 데이터셋 자체가 하나의 data sample로 활용되고 있음.                                  즉 Meta-learning에서는 training, test의 개념이 일반과 약간 다르고, 그 때 들어가는 데이터셋도 다르다.          약간의 fine-tuning 과 유사한 접근법                      Few-shot learning          적은 수의 데이터로 학습 시키는 것      one-shot learning : 한 장의 데이터만으로 학습 시키는 것      K-shot learning이라고 많이 부르는 듯      Methods(Explain one of the methods that the thesis used.)  세타 1,2,3 -&gt; 1,2,3번 태스크라고 보자.  만약 1번 태스크에 대해서 학습을 시킨다 그러면, 1의 optimum point로 가게끔 학습시켜야 함.  근데 샘플이 많지 않으니까 중간에 Local min.에 빠지는 경우 등 원하는 방향으로 흘러가지 않을 가능성이 더 큼.  메타러닝을 통해 세타를 저 점(화살표가 가리키는점)에 가지고 오면 1,2,3에 가장 가까운 포인트. 즉, 여기를 어떻게 보낼거냐는 문제!  예를 들어, 3번 태스크에 대한 One-shot이 주어졌을 때 gradient 1번해서 3번쪽으로 딱 가고 싶은 것.수식으로 보는 아이디어  i번째 태스크에 대한 세타프라임 정의  1 step gradient를 갔을 때의 포인트임.우리는 이 세타 프라임의 포인트에서 loss가 최소가 되게 하고 싶음! –&gt; 세타 프라임에서 로스가 미니멈이 되는 세타를 찾고 싶다!!  세타 프라임을 위에서 정의했으므로, loss 식에 넣을 수 있다.  세타에서 1 스텝 더 간 포인트의 미니멈을 정의하게 되는 것(== 세타프라임)  세타에 대해서 미분함!  태스크가 여러 가지 있으니까 여러 가지에 대해 전체가 미니멈이 되는 포인트를 찾아야 함.  세타 프라임 안에는 이미 세타에 대한 미분이 들어가있으므로 여기서 미분을 또 하게 되면 hessian이 나올 것이다(?)다시 요약하자면,      우리가 찾고 싶은 세타는 태스크 각각을 minimize하는 세타가 아니라,        주어진 태스크들에 대해서 1 step 갔을 때 모든 태스크에 대해서 minimum이 되는        지금 현재의 세타를 찾는 것.  Algorithm  Model-Agnostic Meta-Learning  우선 파라미터들을(세타) 랜덤하게 initialize  태스크들을 sampling하고, for문 안에서는 각각의 태스크에 대한 그래디언트를 찾음          1 step 더 가는 그래디언트        모든 태스크들에 대해서 다시 그래디언트를 해서 sum함.  원래 파라미터 세타를 업데이트  위의 과정 반복  MAML for Few-shot Supervised learning  regression loss      classification loss    Few-shot 이미지 classification일 경우 loss를 크로스 엔트로피로 계산  메타 업데이트를 위한 샘플링을 함.          최종 메타 파라미터(세타)를 찾기 위해서 쓰이는 샘플들      이전의 샘플 D는 세타 프라임을 위한 샘플들임.        MAML for Reinforcement Learning  Reward는 미분이 가능해야하니까 policy gradient를 사용함.  f(theta)는 policy를 나타내는 뉴럴 넷  negative reward를 loss로 사용  에피소드 길이만큼 쭉 진행해서 sum한 것이 loss가 됨.  마찬가지로 각 태스크에 대해서 샘플을 하고, 전체 에피소드 length 만큼 K번 trajecctories 샘플  그래디언트 계산해서 1 step 더 간 포인트를 찾아내고  1 step 더 간 파라미터 셋에서의 샘플 trajectories들을 샘플링 한 다음에  다 하고 바깥으로 나와서 파라미터 업데이트를 위해 loss를 계산하고 그래디언트를 구함.1,2,3번 모두 크게 다르지 않다.Experimental Result  The goal of our experimental evaluation          얼마나 빨리 learning을 할 수 있는가      서로 다른 도메인에서 사용이 될 수 있는가 -&gt; supervised regression, classification, reinforcement learning      여러 번 gradeint update를 할수록 더 좋아지는가        Regression  sine wave fitting 을 실험.          임의의 sine wave 를 만들어서, 그것을 fitting 하는 예제        삼각형 : 트레이닝 샘플  빨간색 = ground truth  연두색 = 메타러닝을 통해 학습된 pre-weight  초록색 = 그래디언트를 1 step / 10 steps 밟았을 때a) K = 5(5개의 샘플이 주어졌을 때)b) K = 10 (10개의 샘플이 주어졌을 때)  그래디언트 10번하면 거의 똑같이 됨c,d) Pre-traineed model 사용  fitting하는 뉴럴 넷을 sine wave task로 잔뜩 만들어서 평균적인 sine wave에 대해 학습된 것  pre-update는 meta-learning으로 만들어진 모델과 유사하나 1 step 간다고 해서 막 변하지 않음.          fitting이 잘 안된다.        Classification  One-shot, few-shot learning에서 주로 쓰이는 데이터 셋 : Omniglot dataset          few-shot learning의 mnist같은 데이터셋        First order approx          두 번 미분하기 위해 hessian이 들어간다고 했음.      근데 ReLU는 중간에 미분 불가능한 포인트가 있고, 이를 제외하면 Linear함.      따라서 이것을 first order까지만 계산하고 업데이트해도 성능이 그렇게 떨어지지 않는다고 함.      정석대로 두 번 미분하면 33%정도 더 오래걸린다고 함.        Reinforcement learning  2D navigation 실험 : 위치를 정해주고 goal까지 가기  3step update하면 잘 간다  pre-train하고 fine-tuning하는 방법과 비교…Codefrom dragen1860 / MAML-Pytorch    def forward(self, x_spt, y_spt, x_qry, y_qry):        """        :param x_spt:   [b, setsz, c_, h, w]        :param y_spt:   [b, setsz]        :param x_qry:   [b, querysz, c_, h, w]        :param y_qry:   [b, querysz]        :return:        """        task_num, setsz, c_, h, w = x_spt.size()        querysz = x_qry.size(1)        losses_q = [0 for _ in range(self.update_step + 1)]  # losses_q[i] is the loss on step i        corrects = [0 for _ in range(self.update_step + 1)]        for i in range(task_num):            # 1. run the i-th task and compute loss for k=0            logits = self.net(x_spt[i], vars=None, bn_training=True)            loss = F.cross_entropy(logits, y_spt[i])            grad = torch.autograd.grad(loss, self.net.parameters())            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, self.net.parameters())))            # this is the loss and accuracy before first update            with torch.no_grad():                # [setsz, nway]                logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=True)                loss_q = F.cross_entropy(logits_q, y_qry[i])                losses_q[0] += loss_q                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)                correct = torch.eq(pred_q, y_qry[i]).sum().item()                corrects[0] = corrects[0] + correct            # this is the loss and accuracy after the first update            with torch.no_grad():                # [setsz, nway]                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)                loss_q = F.cross_entropy(logits_q, y_qry[i])                losses_q[1] += loss_q                # [setsz]                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)                correct = torch.eq(pred_q, y_qry[i]).sum().item()                corrects[1] = corrects[1] + correct            for k in range(1, self.update_step):                # 1. run the i-th task and compute loss for k=1~K-1                logits = self.net(x_spt[i], fast_weights, bn_training=True)                loss = F.cross_entropy(logits, y_spt[i])                # 2. compute grad on theta_pi                grad = torch.autograd.grad(loss, fast_weights)                # 3. theta_pi = theta_pi - train_lr * grad                fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights)))                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)                # loss_q will be overwritten and just keep the loss_q on last update step.                loss_q = F.cross_entropy(logits_q, y_qry[i])                losses_q[k + 1] += loss_q                with torch.no_grad():                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)                    correct = torch.eq(pred_q, y_qry[i]).sum().item()  # convert to numpy                    corrects[k + 1] = corrects[k + 1] + correct        # end of all tasks        # sum over all losses on query set across all tasks        loss_q = losses_q[-1] / task_num        # optimize theta parameters        self.meta_optim.zero_grad()        loss_q.backward()        # print('meta update')        # for p in self.net.parameters()[:5]:        # 	print(torch.norm(p).item())        self.meta_optim.step()        accs = np.array(corrects) / (querysz * task_num)        return accsAdditional studies(If you have some parts that cannot understand, you have to do additional studies for them. It’s optional.)Advanced researches  Meta-SGD : 성능이 더 괜찮음  Bayesian Model-Agnostic Meta-Learning          한 포인트로 지정하는 것이 아니라 probability를 이용      optimum point들이 서로 가깝고 몰려있으면 좋겠지만, 여러 곳에 있을 수도 있고 확률적으로 분포할 수도 있음.      이런 것들을 어떻게 잘 정의할 수 있느냐에 대한 approach인 듯        Gradient-based meta-learning with learned layerwise metric and subspace          그래디언트 포인트들이 마구잡이로 갈 수 있지만, optimum 포인트들이 분포해있는 subspace가 있을 수 있음.      subspace 안에서만 그래디언트를 가면 훨씬 더 빨리 갈 수 있음. 그것 관련한 논문        ICML 2019 : Online Meta-Learning (같은 저자!)References(References for your additional studies)https://www.youtube.com/watch?v=fxJXXKZb-ikhttps://talkingaboutme.tistory.com/entry/DL-Meta-Learning-Learning-to-Learn-Fasthttps://elapser.github.io/machine-learning/2019/03/08/Model-Agnostic-Interpretation.html]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Meta Learning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Attention Is All You Need]]></title>
      <url>/paper%20review/2020/08/10/Attention/</url>
      <content type="text"><![CDATA[Attention Is All You Need 를 읽고 정리한 글입니다.Attention Is All You NeedOverview(You should include contents of summary and introduction.)We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  recurrent, convolution 을 사용하지 않고 Attention을 이용해서 더 빠른 성능에 도달Related work (Basic concepts)  layer normalization  RNN  AttentionMethods(Explain one of the methods that the thesis used.)Architecture      the encoder maps an input sequence of symbol representations (x1,…,xn) to a sequence of continuous representations z = (z1,…,zn)    Encoder          6개의 identicla layer로 구성되어 있음.                  each layer has 2 sub-layers.                          The first is a multi-head self-attention mechanism, and the second is a simple, position- wise fully connected feed-forward network.                                          Add : residual connection을 의미함.      Layer Norm. : LayerNorm(x + Sublayer(x))      produce outputs of dimension d_model = 512        Decoder          Encoder와 동일하게 6개의 동일한 레이어로 구성됨.      Masked Multi-Head Attention                  We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i.                    Attention  Scaled Dot-Product Attention          Input : Q(Queries), K(Keys), V(Values)      compute the dot products query with all keys, divide each by root(dk), and apply a softmax function to obtain the weights on the values.                We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections.        Multi-Head Attention          linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively.              perform the attention function in parallel yielding dv -dimensional output values.      위의 과정이 완료된 후에는 concatenate 시킴        Position-wise Feed-Forward NetworksPositional EncodingTransformer에서는 시간의 연속성을 모델의 핵심부에서 다루지 않음. -&gt; 그러나 시간의 순서는 실제 언어에서 중요하므로 단어의 위치 정보를 포함시키기 위해 Positional Encoding을 사용Why Self-Attention      Total computational complexity per layer        The amount of computation that can be parallelized, as measured by the minimum number of sequential operations required.        The path length between long-range dependencies in the network.  A self-attention layer connects all positions with a constant number of sequentially executed operations, whereas a recurrent layer requires O(n) sequential operations.Training논문 참조.Additional studies(If you have some parts that cannot understand, you have to do additional studies for them. It’s optional.)[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016.[2] BERTReferences(References for your additional studies)https://www.youtube.com/watch?v=EyXehqvkfF0https://www.youtube.com/watch?v=mxGCEWOxfe8]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> NLP </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Generative Adversarial Nets]]></title>
      <url>/paper%20review/2020/08/08/GAN/</url>
      <content type="text"><![CDATA[Generative Adversarial Nets 를 읽고 정리한 글입니다.Generative Adversarial NetsOverview(You should include contents of summary and introduction.)GAN에는 두 가지 모델이 존재함.  Discriminator  GeneratorImage를 만들어 내는 Generator(G)가 이 만들어진 모델을 평가하는 Discriminator(D)를 최대한 속일 수 있도록, 확률 분포의 차이를 줄이는 것이 목적  즉, G는 D를 최대한 속이려고 노력하고, D는 G가 만든 이미지를 최대한 감별하려고 노력함.  이 경쟁 속에서 두 모델은 모두 발전하게 되고, 결과적으로는 G가 만든 이미지를 구별할 수 없는 상태에 도달하게 됨.위의 목표를 이루기 위해서는, (ref. output -&gt; [0,1] : 0==false, 1==true)  D : 진짜 이미지를 진짜 이미지라고 인식(분류)하도록 학습  G : random한 코드를 받아서 img를 생성한 후, 그 이미지가 D를 속여야 함.          즉, D(G(z)) = 1(진짜라 인식)이 나오도록 학습.                  학습할수록 진짜같은 가짜 img가 만들어지는 것                    Related work (Basic concepts)  generative model  Adversarial  VAEMethods(Explain one of the methods that the thesis used.)GAN loss/objective function  D 입장에서는 위 수식이 0인게 Maximize  G 입장에서는 속이는 게 좋으니 Mininmize+) G는 처음에 형편없는 이미지를 만듦.  D는 그 이미지를 가짜라 확신. =&gt; D(G(z))=0  하지만 위의 log(1-x) 로는 그때 기울기의 절댓값이 작음.  practical use : D가 가짜라 확신하는 상황을 최대한 빨리 벗어나려면, D(G(z))=0인 점에서 기울기가 거의 무한인 log(x)를 씀  모델이 생성한 이미지 분포와 실제 이미지 분포 간의 차이를 계산해주는 함수로 Jenson-Shannon divergence 사용함.Approach  The minimax problem of GAN has a global opt. at p(g) = p(data)  Proposition 1.  Main Theorem.위를 이용해서 D가 optimal 가정.The global minimum of the virtual training criterion C(G) is achieved if and only if p(g)=p(data). At that point, C(G) achieves the value −log(4).  The proposed algorithm can find that global opt.  그래서 알고리즘이 위 문제를 풀 수 있는가를 확인1번==&gt;minimax problem -&gt; global opt. 가진다는 증명이었음.  global opt. -&gt; 모델의 분포 == 실제 분포  즉 우리가 풀려는 문제 C(G)가 convex문제임을 확인했음.          minimization problem이 쉬워짐.      MLP로 충분히 가능하다.Vector arithmetic 하다.안경 낀 남자 - 안경 안 낀 남자 + 안경 안 낀 여자 = 안경 낀 여자Code# https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/generative_adversarial_network/main.pyimport osimport torchimport torchvisionimport torch.nn as nnfrom torchvision import transformsfrom torchvision.utils import save_image# Device configurationdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')# Hyper-parameterslatent_size = 64hidden_size = 256image_size = 784num_epochs = 200batch_size = 100sample_dir = 'samples'# Create a directory if not existsif not os.path.exists(sample_dir):    os.makedirs(sample_dir)# Image processing# transform = transforms.Compose([#                 transforms.ToTensor(),#                 transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels#                                      std=(0.5, 0.5, 0.5))])transform = transforms.Compose([                transforms.ToTensor(),                transforms.Normalize(mean=[0.5],   # 1 for greyscale channels                                     std=[0.5])])# MNIST datasetmnist = torchvision.datasets.MNIST(root='../../data/',                                   train=True,                                   transform=transform,                                   download=True)# Data loaderdata_loader = torch.utils.data.DataLoader(dataset=mnist,                                          batch_size=batch_size,                                           shuffle=True)# DiscriminatorD = nn.Sequential(    nn.Linear(image_size, hidden_size),    nn.LeakyReLU(0.2),    nn.Linear(hidden_size, hidden_size),    nn.LeakyReLU(0.2),    nn.Linear(hidden_size, 1),    nn.Sigmoid())# Generator G = nn.Sequential(    nn.Linear(latent_size, hidden_size),    nn.ReLU(),    nn.Linear(hidden_size, hidden_size),    nn.ReLU(),    nn.Linear(hidden_size, image_size),    nn.Tanh())# Device settingD = D.to(device)G = G.to(device)# Binary cross entropy loss and optimizercriterion = nn.BCELoss()d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)def denorm(x):    out = (x + 1) / 2    return out.clamp(0, 1)def reset_grad():    d_optimizer.zero_grad()    g_optimizer.zero_grad()# Start trainingtotal_step = len(data_loader)for epoch in range(num_epochs):    for i, (images, _) in enumerate(data_loader):        images = images.reshape(batch_size, -1).to(device)                # Create the labels which are later used as input for the BCE loss        real_labels = torch.ones(batch_size, 1).to(device)        fake_labels = torch.zeros(batch_size, 1).to(device)        # ================================================================== #        #                      Train the discriminator                       #        # ================================================================== #        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))        # Second term of the loss is always zero since real_labels == 1        outputs = D(images)        d_loss_real = criterion(outputs, real_labels)        real_score = outputs                # Compute BCELoss using fake images        # First term of the loss is always zero since fake_labels == 0        z = torch.randn(batch_size, latent_size).to(device)        fake_images = G(z)        outputs = D(fake_images)        d_loss_fake = criterion(outputs, fake_labels)        fake_score = outputs                # Backprop and optimize        d_loss = d_loss_real + d_loss_fake        reset_grad()        d_loss.backward()        d_optimizer.step()                # ================================================================== #        #                        Train the generator                         #        # ================================================================== #        # Compute loss with fake images        z = torch.randn(batch_size, latent_size).to(device)        fake_images = G(z)        outputs = D(fake_images)                # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf        g_loss = criterion(outputs, real_labels)                # Backprop and optimize        reset_grad()        g_loss.backward()        g_optimizer.step()                if (i+1) % 200 == 0:            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'                   .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(),                           real_score.mean().item(), fake_score.mean().item()))        # Save real images    if (epoch+1) == 1:        images = images.reshape(images.size(0), 1, 28, 28)        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))        # Save sampled images    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))# Save the model checkpoints torch.save(G.state_dict(), 'G.ckpt')torch.save(D.state_dict(), 'D.ckpt')Additional studies(If you have some parts that cannot understand, you have to do additional studies for them. It’s optional.)이후 GAN 논문들References(References for your additional studies)https://www.youtube.com/watch?v=L3hz57whyNwhttps://www.youtube.com/watch?v=odpjk7_tGY0http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-2.html]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Computer Vision </tag>
        
          <tag> GAN </tag>
        
          <tag> Generative Model </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[PEGASUS:Pre-training with Extracted Gap-sentences for Abstractive Summarization]]></title>
      <url>/paper%20review/2020/08/05/PEGASUS/</url>
      <content type="text"><![CDATA[PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization 를 읽고 정리한 글입니다.PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive SummarizationOverview  What is the good pre-training objectives tailored for abstractive text summarization?–&gt; GSG  self- supervised objective  important sentences are removed/masked from an input doc- ument and are generated together as one output sequence from the remaining sentences, similar to an extractive summary.          중요한 문장은 인풋 과정에서 masked되고, 남은 문장들 중에서 extractive summary처럼 가져오는 건가 봄.        scoring : ROUGE  GSG, MLMRelated Work (Basic Concepts)  논문 참조MethodsArchitectureGap Sentences Generation(GSG)  our proposed pre-training objec- tive involves generating summary-like text from an input document. In order to leverage massive text corpora for pre- training, we design a sequence-to-sequence self-supervised objective in the absence of abstactive summaries.  we select and mask whole sentences from documents, and concatenate the gap-sentences into a pseudo-summary. The corresponding position of each selected gap sentence is replaced by a mask token [MASK1] to inform the model. Gap sentences ratio, or GSR, refers to the number of selected gap sentences to the total number of sentences in the document, which is similar to mask rate in other works.  워드를 마스킹하는 게 아니라 센텐스 단위로 마스킹          이것을 트랜스포머 모델에 넣고 마스킹한 문장을 추론하는 태스크 수행        어떻게 하면 중요한 센텐스를 선택해서 마스킹할 수 있는가?          ROUGE1-F1 score 사용      ROUGE  ROUGE + F1 score  정답 센텐스가 있다고 가정하는 것          pretraining에 활용하고 싶은 것이기 때문에 정답 센텐스가 없음      셀렉트 센텐스와 나머지 센텐스를 비교해서 ROUGE1-F1 스코어를 구함.        기존의 ROUGE 정의와는 약간 다르다.AlgorithmMasked Language Model(MLM)  Following BERT, we select 15% tokens in the input text, and the selected tokens are (1) 80% of time replaced by a mask token [MASK2], or (2) 10% of time replaced by a random token, or (3) 10% of time unchanged.  랜덤하게 특정 단어를 masking 시킴.          인풋을 넣어줄 때 이 단어들을 넣어주지 않는다        마스킹된 단어가 무엇인지 추측하는 …-&gt; Can get gnereal linguistic knowledge-&gt; labeling, data를 가질 필요없이 모든 데이터로 사용할 수 있다.Pre-training each corpus  C4  HugeNewsFine-tuning datasets  XSum  CNN/DailyMail  NEWSROOM  Multi-News  …tfds에서 가져옴.Experiments  Pre-training ablation experiments to choices of pre-training corpus, objective, and vocabulary size Using PEGASUS_Base instead of PEGASUS_Large  Ind-Orig  masking : 30%  Unigram 96K  Larger Model Results          base모델로 찾은 다음에 large모델을 생성        Fine-tuning with low-resource          적은 데이터셋에 대해서도 성능이 좋다        Qualitative Observations          사람이 봤을 때 진짜 좋은 성능인지 확인      실험결과 -&gt; 실제로는 GSG 방식만 사용하는 것이 더 좋다.]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> NLP </tag>
        
          <tag> Text Summarization </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[You Only Look Once(YOLO):Unified, Real-Time Object Detection]]></title>
      <url>/paper%20review/2020/07/31/YOLO/</url>
      <content type="text"><![CDATA[You Only Look Once : Unified, Real-Time Object Detection 를 읽고 정리한 글입니다.You Only Look Once : Unified, Real-Time Object DetectionOverview(You should include contents of summary and introduction.)기존의 object detection = repurpose classifiers to perform detection  DPM : sliding window  R-CNN : region proposal  Classifier를 통해 클래스 분류 -&gt; post-processing 통해 refine -&gt; rescore 후 합침YOLO : a single network, end-to-end directly on detection performance  Unified Model (feat. GoogLeNet, NIN)  Real-time 가능할 정도로 빠름.  Single regression problem          Reasons globally about the image when making predictions      bbox coord. &amp; class probability 동시에 구할 수 있음.      CNN -&gt; Non-max. supprestion -&gt; Finish!        Can learns generalizable representations of obj.  다양한 datasets 가능하다.Related work (Basic concepts)GoogLeNet architectureNIN(Network in Network)  네트워크를 구성할 때 또 다른 micro network 포함하여 설계했을 때 성능 향상이 됨.Methods(Explain one of the methods that the thesis used.)Unified Detection  모든 bbox, class를 한번에 고려한다 (=&gt; 즉, 전체 이미지로 한번 본다)1. S x S grid2. bbox &amp; confidence score(bbox에서 물체가 많이 포함되는지)    - confidence = Pr(object) * IOU    - no obj -&gt; 0(zero)    - each bbox contains : x,y,w,h,confidence    - x, y : bbox안의 cell 위치 (norm. 0~1)    - w, h : bbox width, height (norm. 0~1)    - c : bbox confidence3. Class probability  \[Pr(class(i)|Object) * Pr(Object)\]    Predictions are encoded as an S x S x (B*5 + C)  On Pascal Voc, S=7, B=2. C(class) = 20      - Thus, 7 x 7 x 30 tensor.Architecture  GoogLeNet을 응용  24 conv. layer + 2 FC layer          Fast YOLO(tiny YOLO) : 9 conv layer 사용함.        GoogLeNet에서 쓰이는 Inception module 대신, Reduction layer(1x1 conv)를 사용하여 파라미터 size 줄임.  Feature Extractor에 해당하는 20 conv layer로 pretrain함.          Pretrained layer 바탕으로 VOC data에 fine-tuning        좀 더 좋은 detection을 위해 224 -&gt; 448로 size 2배 늘림.  NIN(network in network) - 4 conv layer, 2 FC layer =&gt; classifier 역할Loss function  MSE보다 SSE가 단순하니 SSE로 선택  Object의 유무는 grid cell 자체에서 cell 기준으로 classify하므로 유무를 판단하는 loss보다는 bbox 좌표를 찍는 loss를 더 크게 봄.          lambda(coord) = 5 and lambda(noobj) = 0.5        bbox 중에서도 larger box는 오차로 인한 로스 변동이 클 것이므로 루트를 씌워서 작은 bbox에는 전보다 더 크게 반응, 큰 bbox에는 전보다 조금 더 작게 반응하도록 함.  1(obj,i) : if object appears in cell i  1(obj,ij) : the j-th bbox predictor in cell i is “responsible” for that predictionLimitations  Bbox가 grid size에 의존.          Image가 domain에 자주 나타나는 object size를 제대로 반영하지 못한다면 bad        Grid size보다 작은 물체가 있을 경우 badExperiment rusults      bg 관련해서 덜 실수함.        Fast R-CNN과 combine했더니 속도 떨어짐    새로운 dataset에도 잘 작동함.Code      pytorch        network implementation      # feature extractor 부분       feature_extract_net = nn.Sequential(          nn.Conv2d(3, 64, 7, stride=2, padding=3),          nn.LeakyReLU(0.1, inplace=True),          nn.MaxPool2d(2),          nn.Conv2d(64, 192, 3, padding=1),          nn.LeakyReLU(0.1, inplace=True),          nn.MaxPool2d(2),          nn.Conv2d(192, 128, 1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(128, 256, 3, padding=1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(256, 256, 1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(256, 512, 3, padding=1),          nn.LeakyReLU(0.1, inplace=True),          nn.MaxPool2d(2),          nn.Conv2d(512, 256, 1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(256, 512, 3, padding=1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(512, 256, 1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(256, 512, 3, padding=1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(512, 256, 1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(256, 512, 3, padding=1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(512, 256, 1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(256, 512, 3, padding=1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(512, 512, 1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(512, 1024, 3, padding=1),          nn.LeakyReLU(0.1, inplace=True),          nn.MaxPool2d(2),          nn.Conv2d(1024, 512, 1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(512, 1024, 3, padding=1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(1024, 512, 1),          nn.LeakyReLU(0.1, inplace=True),          nn.Conv2d(512, 1024, 3, padding=1),          nn.LeakyReLU(0.1, inplace=True)      )          # classifier 부분  conv = nn.Sequential(              # 4 conv layer              nn.Conv2d(1024, 1024, 3, padding=1),              nn.LeakyReLU(0.1, inplace=True),              nn.Conv2d(1024, 1024, 3, stride=2, padding=1),              nn.LeakyReLU(0.1),              nn.Conv2d(1024, 1024, 3, padding=1),              nn.LeakyReLU(0.1, inplace=True),              nn.Conv2d(1024, 1024, 3, padding=1),              nn.LeakyReLU(0.1, inplace=True)              Flatten(),              # 2 FC layer              nn.Linear(7 * 7 * 1024, 4096),              nn.LeakyReLU(0.1, inplace=True),              nn.Dropout(0.5, inplace=False),               nn.Linear(4096, S * S * (5 * B + C)),              nn.Sigmoid()      )      Additional studies(If you have some parts that cannot understand, you have to do additional studies for them. It’s optional.)NIN(network in network)References(References for your additional studies)https://www.youtube.com/watch?v=eTDcoeqj1_whttps://arclab.tistory.com/162https://arclab.tistory.com/165]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Computer Vision </tag>
        
          <tag> Object Detection </tag>
        
          <tag> Real-Time </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Text Summarization with Pretrained Encoders]]></title>
      <url>/paper%20review/2020/07/26/Text-Summarization-with-Pretrained-Encoders/</url>
      <content type="text"><![CDATA[Text Summarization with Pretrained Encoders 를 읽고 정리한 글입니다.Text Summarization with Pretrained Encoders이 저자가 참여한 전 논문이 Fine-tune BERT for Extractive Summarization였음.  따라서 발전된 부분에 대해 살펴볼 것임.이전 연구와의 차이점 (Differences from previous studies)  전에는 extractive summarization에 대해서만 살펴봤었음.  현 연구에서는 a general framework for both extractive and abstractive models (두 서머리 모델을 사용함)Data  CNN/Dailymail : highlighted된… -&gt; extractive summaries  NYT : abstractive summaries  XSum : one-sentence summaryMethod  extractive model          built on top of the encoder by stacking several inter-sentence Transformer layers        abstractive model          a new fine-tuning schedule which adopts different optimizers for the encoder and the decoder as a means of alleviating the mismathch between two (the former is pretrained while the latter is not)        a two-staged fine-tuning approach          it can further boost the quality of the generated summaries      the combination of extractive and abstractive objectives can help generate better summaries (Gehrmann et al., 2018)      즉 두 가지 모델을 컴바인시키면 성능 향상을 노릴 수 있다는 아이디어에서 착안한 연구.        architecture of BERTSUM  Summarization Encoder          Interval Segment Embeddings                  sent(i)를 홀수,짝수 순서에 따라 E(a) or E(b)로 segment embedding 한다.              sentence -&gt; [sent1,sent2,sent3,sent4,sent5]  embedding -&gt; [E(a),E(b),E(a),E(b),E(a)]                                            Extractive Summarization          이전 연구와 수식 동일        Abstractive Summarization          the encoder is the pretrained BERTSUM and the decoder is a 6-layered Transformer initialized randomly.                  encoder &amp; decoder 사이의 mismatch 가능성 있음                          new fine-tuning schedule!                                          difference optimizer 적용!        two-stage fine-tuning    1. fine-tune the encoder on the extractive summarization2. fine-tune it on the abstractive summarization              using extractive objectives can boost the performance of abstractive summarization.      Results      ROUGE score 사용함        전보다 성능도 많이 좋아짐.  관련 논문접기/펼치기 버튼          Sebastian Gehrmann, Yuntian Deng, and Alexander Rush. 2018. Bottom-up abstractive summarization. In Proceedings of the 2018 Conference on Empiri- cal Methods in Natural Language Processing, pages 4098–4109, Brussels, Belgium.      Chin-Yew Lin. 2004. ROUGE: A package for auto- matic evaluation of summaries. In Text Summariza- tion Branches Out, pages 74–81, Barcelona, Spain.      Shashi Narayan, Shay B. Cohen, and Mirella Lapata. 2018a. Don’t give me the details, just the summary! topic-aware convolutional neural networks for ex- treme summarization. In Proceedings of the 2018 Conference on Empirical Methods in Natural Lan- guage Processing, pages 1797–1807, Brussels, Bel- gium.      Shashi Narayan, Shay B. Cohen, and Mirella Lapata. 2018b. Ranking sentences for extractive summa- rization with reinforcement learning. In Proceed- ings of the 2018 Conference of the North American Chapter of the Association for Computational Lin- guistics: Human Language Technologies, Volume 1 (Long Papers), pages 1747–1759, New Orleans, Louisiana.      Alexander M. Rush, Sumit Chopra, and Jason Weston. 2015. A neural attention model for abstractive sen- tence summarization. In Proceedings of the 2015 Conference on Empirical Methods in Natural Lan- guage Processing, pages 379–389, Lisbon, Portugal.      Xingxing Zhang, Furu Wei, and Ming Zhou. 2019. HI- BERT: Document level pre-training of hierarchical bidirectional transformers for document summariza- tion. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5059–5069, Florence, Italy. Association for Computational Linguistics.      Xingxing Zhang, Mirella Lapata, Furu Wei, and Ming Zhou. 2018. Neural latent extractive document sum- marization. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Pro- cessing, pages 779–784, Brussels, Belgium.      ]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> NLP </tag>
        
          <tag> Text Summarization </tag>
        
          <tag> Encoder </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Fine-tune BERT for Extractive Summarization]]></title>
      <url>/paper%20review/2020/07/25/Fine-tune-BERT-for-Extractive-Summarization/</url>
      <content type="text"><![CDATA[Fine-tune BERT for Extractive Summarization 를 읽고 정리한 글입니다.Fine-tune BERT for Extractive SummarizationSummarization의 종류  abstractive summarization : contains words or phrases that were not in the original text…          paraphrasing와 유사        extractive summarization : by copying and concatenating the most important spans in a document          중요한 문장을 copy &amp; paste 하는 것으로 서머리를 만듦.        이 논문에서는 후자인 extractive summarization을 사용Data  CNN/Dailymail  NYTMethodEncoding Multiple Sentences  insert a [CLS] token before each sentence and a [SEP] token after each sentence          In vanilla BERT, [CLS] is used as a symbol to aggregate features from one sentence or a pair of sentences.      Interval Segment Embeddings  sent(i)를 홀수,짝수 순서에 따라 E(a) or E(b)로 segment embedding 한다.sentence -&gt; [sent1,sent2,sent3,sent4,sent5]embedding -&gt; [E(a),E(b),E(a),E(b),E(a)]Fine-tuning with Summarization Layers  simple classifier : sigmoid function  inter-sentence transformer          extracting document-level features focusing on summarization tasks from the BERT outputs      공식에 layer normalization과 multi-head attention operation를 이용한다 하는데 MHAtt는 더 알아봐야할 듯함.        Recurrent Neural Network          RNN이 더 좋게 만들 수 있음(왜지)      BERT output에 LSTM 레이러를 적용시켜서 summarization-specific features를 학습할 수 있도록 함.      Results  ROUGE score 사용함]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> NLP </tag>
        
          <tag> Text Summarization </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Jacobian Matrix]]></title>
      <url>/math/2020/07/24/Jacobian-Matrix/</url>
      <content type="text"><![CDATA[Jacobian Matrix 에 관한 설명을 적은 글입니다.Jacobian Matrix요약  편미분을 할 때 유용한 행렬  편미분 할 변수들이 많고, 그 변수들로 이루어져 있는 함수가 많을 때 단순히 곱해서 더하는 폼으로 만들어 놓을 수 있는 것설명n개의 변수를 가진 함수가 m개 있을 때이것들을 모두 편미분하기 위한 벡터-&gt; Jacobian matrix  m개의 함수 편미분을 모조리 구할 수 있음.예시일때, Jacobian Matrix는Reference02. 편미분을 간단하게! Jacobian Matrixwikipedia]]></content>
      <categories>
        
          <category> Math </category>
        
      </categories>
      <tags>
        
          <tag> Math </tag>
        
          <tag> Linear Algebra </tag>
        
          <tag> Calculas </tag>
        
          <tag> Deep Learning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Faster R-CNN:Towards Real-Time Object Detection with Region Proposal Networks]]></title>
      <url>/paper%20review/2020/07/23/Faster-R-CNN/</url>
      <content type="text"><![CDATA[Faster R-CNN : Towards Real-Time Object Detection with Region Proposal Networks 를 읽고 정리한 글입니다.Faster R-CNN : Towards Real-Time Object Detection with Region Proposal NetworksOverview(You should include contents of summary and introduction.)  흐름 : R-CNN -&gt; (SPP-net) -&gt; Fast R-CNN -&gt; Faster R-CNN  R-CNN : Region with CNN features. RoI 들을 뽑아내고 CNN에 각각 집어넣음.          Region Proposal – Selective Search : 어떻게 바운딩 박스(bbox)를 뽑아내는가      Training      Pre-train AlexNet      SVM, bounding-box regressor (CNN에 학습이 안된다는 단점이 있음)        Fast R-CNN          RoI projection -&gt; 매 bounding box마다 RoI pooling      어떤 RoI가 나와도 똑같은 size가 나오도록 max pooling =&gt; RoI pooling      Fixed-length feature vector from RoI가 됨.      FC 레이어에 넘기면서 classification(K+1 class) + bounding box location 동시에 계산      Problems of Fast R-CNN : Out-of-network region proposals are the test-time computational bottleneck        Faster R-CNN          Notion : Region Proposal을 Selective Search(CPU에서 했음)을 하지 말고 실제 네트워크 안에서 같이 해보자(GPU로 계산 가능)              Key Point : Region Proposal Network(RPN) + Fast R-CNN                    CNN을 share하는 것을 목표로, 즉 네트워크가 하나인 것처럼 해보자!                            RPN                      Loss function (사진)                    4-step Alternation Training      Summary of experiments(Explain figures briefly.)Proposal time 매우 줄어듦!Methods(Explain one of the methods that the thesis used.)Region Proposal을 실제 네트워크 안에서 같이 해보자Region Proposal Network + Fast R-CNN CNN share하자등 Overview 에서 설명함Ideas for further research(Explain your ideas for further research briefly.)Faster R-CNN의 한계 : RoI pooling 할 때 7의 배수가 아닌 RoI가 나오면 버림이 있을 것  오차 발생… (object detection에는 큰 문제가 아닐 수 있지만 location 등이 중요한 것에는 문제를 일으킬 수 있음)  Mask R-CNN 으로 극복아직도 실시간으로 처리하기에는 조금 부족해 보이기도…  Proposal 시간은 유의미하게 줄이기 힘들 것 같음. Region-wise time을 좀 더 줄이는 방법? Conv도?…Additional studies(If you have some parts that cannot understand, you have to do additional studies for them. It’s optional.)R-CNNFast R-CNNMask R-CNNReferences(References for your additional studies)https://www.youtube.com/watch?v=kcPAGIgBGRs&amp;list=PLXiK3f5MOQ760xYLb2eWbtOKOwUC-bByj&amp;index=13&amp;t=0shttps://curt-park.github.io/2017-03-17/faster-rcnn/]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Computer Vision </tag>
        
          <tag> Object Detection </tag>
        
          <tag> Real-Time </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[sklearn.pipeline]]></title>
      <url>/machine%20learning/2020/05/19/pipeline/</url>
      <content type="text"><![CDATA[사이킷런의 pipline에 관한 정리글입니다.sklearn.pipelinepipeline  전처리를 위한 변환기  여러 변환 단계를 정확한 순서대로 실행할 수 있게 함.  Pipeline은 연속된 단계를 나타내는 이름/추정기 쌍의 목록을 입력으로 받음.  마지막 단게에서는 변환기와 추정기를 모두 사용할 수 있고, 그 외에는 모두 변환기여야 함.          fit_transform() 메서드를 가지고 있어야 함.        파이프 라인의 fit() 메서드를 호출하면 모든 변환기의 fit_transform() 메서드를 순서대로 호출하면서 한 단계의 출력이 다음 단계의 입력으로 전달됨.  마지막 단계에서는 fit() 메서드만 호출함.예제 코드from sklearn.pipeline import Pipelinefrom sklearn.linear_model import LinearRegressionmodel = Pipeline([    ('scaler', StandardScaler()),    ('regressor', LinearRegression()),])파이프라인으로 결합된 모형은 원래의 모형이 가지는 fit, predict 메서드를 가지며 각 메서드가 호출되면 그에 따른 적절한 메서드를 파이프라인의 각 객체에 대해서 호출한다. 예를 들어 파이프라인에 대해 fit 메서드를 호출하면 전처리 객체에는 fit_transform이 내부적으로 호출되고 분류 모형에서는 fit 메서드가 호출된다. 파이프라인에 대해 predict 메서드를 호출하면 전처리 객체에는 transform이 내부적으로 호출되고 분류 모형에서는 predict 메서드가 호출된다.]]></content>
      <categories>
        
          <category> Machine Learning </category>
        
      </categories>
      <tags>
        
          <tag> Machine Learning </tag>
        
          <tag> scikit-learn </tag>
        
          <tag> TIL </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[생활코딩 WEBn - WEB2 Javascript 코스 정리록]]></title>
      <url>/web/2020/03/06/WEB2/</url>
      <content type="text"><![CDATA[생활코딩 WEBn의 WEB2 Javascript코스를 듣고 정리한 글입니다.WEB2style  html 안의 body-style 코드는 CSS로 작성.  &lt;h2 style = "color: balck;"&gt;&lt;/h2&gt;          “{CSS code}”        class = "js" 일 때.js{    ...}  id로 쓸 때는 # 기호 사용(id=”first”)#first{    ...}  여기 있는 모든 span tag에 대해서 적용됨.span{    ...}Javascript  사용자와 상호작용하는 언어  웹 브라우저는 한 번 화면에 출력되면 자기 자신을 바꿀 수 없음.  script 태그 안에 작성  동적(dynamic)함. &lt;–&gt; html: 정적event  onclick = “{Javascript code}”  onkeydown, onchange 등등 매우 많음.div 태그  어떤 기능도 의미도 없는 태그.  CSS, JS 통해 정보 넣음.  줄바꿈 자동span 태그  기능은 div와 동일  줄바꿈이 없음.자바스크립트로 style 사용하기  document.querySelector('body').style.backgroundColor="black";객체 함수var coworkers{    "programmar":"ys",    "designer":"ys"};    coworkers.showAll = function(){        ...    }    var abc = function(){        ...    }jQuery 함수  $.함수의 의미  $('a') : 모든 a tag에 대해 제어하겠다자주 쓰이는 객체들과 검색어  document  DOM  window  ajax  cookie  offline web application  WebRTC  WebGL]]></content>
      <categories>
        
          <category> Web </category>
        
      </categories>
      <tags>
        
          <tag> Web </tag>
        
          <tag> Javascript </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[생활코딩 WEBn - WEB1 Html 코스 정리록]]></title>
      <url>/web/2020/03/05/WEB1/</url>
      <content type="text"><![CDATA[생활코딩 WEBn의 WEB1 Html코스를 듣고 정리한 글입니다.WEB1Tag  &lt;strong&gt;&lt;/strong&gt; : 강조  &lt;u&gt;&lt;/u&gt; : 밑줄  &lt;br&gt; : 단순 줄 바꿈&lt;p&gt;&lt;/p&gt; : 단락의 의미, 정보로써 가치있는 html. 하지만 시각적으로는 자유도가 떨어짐.          CSS로 보완      &lt;p style="margin-top:40px"&gt;        &lt;h1&gt;&lt;/h1&gt; ~ &lt;h6&gt;&lt;/h6&gt; : heading  &lt;img stc="sea.jpg" width="100%"&gt;  &lt;li&gt;&lt;/li&gt; : 목록          ul : li의 부모 tag로, li를 그룹핑시켜줌. unordered list      ol : 마찬가지로 li의 부모 tag. ordered list        &lt;tr&gt; : 테이블 태그. 3대가 같이 다님.  문서의 구조 (tag)          title      meta      html      head      body        &lt;a&gt;&lt;/a&gt; : 링크          href, target, title 의 속성을 지님.      통계에 기반한 학습  html 에서 많이 쓰이는 태그 랭킹을 어떻게 볼 수 있을까?          https://www.advancedwebranking.com/html/      Internet VS WEB  Internet &gt; WEB, FTP, email …  Internet          중앙이 없음. 분산되어 있음. -&gt; 하나가 사라져도 다른 것들이 대체 가능.        http://info.cern.ch/          home of the first website      서버와 클라이언트  Web browser = Client : 정보 요청  Web server = Server : 정보 응답          Web server 직접 구축      Web hosting : 맡기는 방법      웹 호스팅 (github page)  Static(html 파일만…) Web Hosting웹 서버 운영하기  using bitnami MAMP stack  MAMP          M: Mac      A: Apache      M: MySQL      P: PHP            http://127.0.0.1:8080/index.html을 웹브라우저에 입력하면 웹브라우저는 같은 컴퓨터에 설치된 웹서버에게 index.html을 요청함.        웹서버는 웹페이지를 저장하기로 약속된 디렉터리인 htdocs에서 index.html 파일의 코드를 읽어서 웹브라우저에게 전송함.        웹서버는 코드를 해석해서 화면에 웹페이지를 표시합니다.        같은 와이파이를 쓰고 있을 때, mac의 ip address로 접속하면  짜잔.사용한 코드들index.html&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt;  &lt;title&gt;WEB1 - Welcome&lt;/title&gt;  &lt;meta charset="utf-8"&gt;&lt;/head&gt;&lt;body&gt;  &lt;h1&gt;&lt;a href="index.html"&gt;WEB&lt;/a&gt;&lt;/h1&gt;&lt;ol&gt;  &lt;li&gt;&lt;a href="1.html"&gt;html&lt;/a&gt;&lt;/li&gt;  &lt;li&gt;&lt;a href="2.html"&gt;css &lt;/a&gt;&lt;/li&gt;  &lt;li&gt;&lt;a href="3.html"&gt;javascript &lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;WEB&lt;/h2&gt;  &lt;p&gt;The World Wide Web (WWW), commonly known as the Web, is an information system where documents and other web resources are identified by Uniform Resource Locators (URLs, such as https://www.example.com/), which may be interlinked by hypertext, and are accessible over the Internet.[1][2] The resources of the WWW are transferred via the Hypertext Transfer Protocol (HTTP) and may be accessed by users by a software application called a web browser and are published by a software application called a web server.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;1.html&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt;  &lt;title&gt;WEB1 - html&lt;/title&gt;  &lt;meta charset="utf-8"&gt;&lt;/head&gt;&lt;body&gt;  &lt;h1&gt;&lt;a href="index.html"&gt;WEB&lt;/a&gt;&lt;/h1&gt;&lt;ol&gt;  &lt;li&gt;&lt;a href="1.html"&gt;html&lt;/a&gt;&lt;/li&gt;  &lt;li&gt;&lt;a href="2.html"&gt;css &lt;/a&gt;&lt;/li&gt;  &lt;li&gt;&lt;a href="3.html"&gt;javascript &lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;HTML이란 무엇인가?&lt;/h2&gt;&lt;p&gt;  &lt;iframe width="560" height="315" src="https://www.youtube.com/embed/7T7r_oSp0SE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;  &lt;p&gt;&lt;a href="https://www.w3.org/TR/html51/" target="_blank" title="html5 specification"&gt;Hypertext Markup Language (HTML)&lt;/a&gt; is the standard markup language for &lt;strong&gt;creating web pages&lt;/strong&gt; and &lt;u&gt;web&lt;/u&gt; applications.  Web browsers receive HTML documents from a web server or from local storage and render them into multimedia web pages. HTML describes the structure of a web page semantically and originally included cues for the appearance of the document.&lt;/p&gt;  &lt;img src="sea.jpg" width="100%"&gt;  &lt;p style="margin-top:40px"&gt;HTML elements are the building blocks of HTML pages. With HTML constructs, images and other objects, such as interactive forms, may be embedded into the rendered page. It provides a means to create structured documents by denoting structural semantics for text such as headings, paragraphs, lists, links, quotes and other items. HTML elements are delineated by tags, written using angle brackets.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;2.html&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt;  &lt;title&gt;WEB1 - CSS&lt;/title&gt;  &lt;meta charset="utf-8"&gt;&lt;/head&gt;&lt;body&gt;  &lt;h1&gt;&lt;a href="index.html"&gt;WEB&lt;/a&gt;&lt;/h1&gt;&lt;ol&gt;  &lt;li&gt;&lt;a href="1.html"&gt;html&lt;/a&gt;&lt;/li&gt;  &lt;li&gt;&lt;a href="2.html"&gt;css &lt;/a&gt;&lt;/li&gt;  &lt;li&gt;&lt;a href="3.html"&gt;javascript &lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;CSS&lt;/h2&gt;&lt;p&gt;Cascading Style Sheets (CSS) is a style sheet language used for describing the presentation of a document written in a markup language like HTML.[1] CSS is a cornerstone technology of the World Wide Web, alongside HTML and JavaScript.[2]&lt;/p&gt;&lt;p&gt;CSS is designed to enable the separation of presentation and content, including layout, colors, and fonts.[3] This separation can improve content accessibility, provide more flexibility and control in the specification of presentation characteristics, enable multiple web pages to share formatting by specifying the relevant CSS in a separate .css file, and reduce complexity and repetition in the structural content.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;3.html&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt;  &lt;title&gt;WEB1 - javascript&lt;/title&gt;  &lt;meta charset="utf-8"&gt;&lt;/head&gt;&lt;body&gt;  &lt;h1&gt;&lt;a href="index.html"&gt;WEB&lt;/a&gt;&lt;/h1&gt;&lt;ol&gt;  &lt;li&gt;&lt;a href="1.html"&gt;html&lt;/a&gt;&lt;/li&gt;  &lt;li&gt;&lt;a href="2.html"&gt;css &lt;/a&gt;&lt;/li&gt;  &lt;li&gt;&lt;a href="3.html"&gt;javascript &lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;JavaScript&lt;/h2&gt;  &lt;p&gt;JavaScript (/ˈdʒɑːvəˌskrɪpt/),[6] often abbreviated as JS, is a programming language that conforms to the ECMAScript specification.[7] JavaScript is high-level, often just-in-time compiled, and multi-paradigm. It has curly-bracket syntax, dynamic typing, prototype-based object-orientation, and first-class functions.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        
          <category> Web </category>
        
      </categories>
      <tags>
        
          <tag> Web </tag>
        
          <tag> Html </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[슬랙 챗봇 만들기 - 일일 커밋 체크봇]]></title>
      <url>/project/2020/02/12/slackbot/</url>
      <content type="text"><![CDATA[일일 커밋 여부를 체크해주는 Slack chatbot 프로젝트입니다.FrameworkFlask를 이용하여 웹 서버를 만들어 사용함.기능(Chatbot functions)  당일에 깃허브 커밋을 하였는지 체크하고, 매일 정해진 시간에 챗봇이 진행도를 보냄.  일일커밋 규칙이 13일 + 1일 휴식이었기 때문에 루틴을 13일로 잡았음.  커밋을 했다면 해당 차수 날짜에 하트를, 안했다면 깨진 하트  13일 기준 달성률을 표시함.Detail  slack 라이브러리를 사용해 webclient를 만듦.          token 필요        해당 챗봇이 쓰인 슬랙에서는 깃허브 챗봇이 들어간 커밋 로그 채널이 있었음.          위의 채널 정보로 커밋을 했는지 안했는지 체크함.      ]]></content>
      <categories>
        
          <category> Project </category>
        
      </categories>
      <tags>
        
          <tag> Chatbot </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
