<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title><![CDATA[StyleGAN:A Style-Based Generator Architecture for Generative Adversarial Networks]]></title>
      <url>/paper%20review/2020/09/20/StyleGAN/</url>
      <content type="text"><![CDATA[StyleGAN : A Style-Based Generator Architecture for Generative Adversarial Networks 를 읽고 정리한 글입니다.StyleGAN : A Style-Based Generator Architecture for Generative Adversarial Networks (CVPR 2019)Overview      GAN의 generator 부분은 black box로 여겨져 이미지 생성 과정을 이해하기 어려웠음.    style transfer 에서 기반한 generator 구조          각 레이어마다 style의 정보를 입힘. -&gt; AdaIN      전체적인 스타일(머리 색, 인종, 성별 등), 세세한 부분(곱슬 등) 등까지 조정 가능 -&gt; noise        baseline : progressive GAN          latent vector로 부터 이미지 합성하고 점점 해상도를 올려서 high-resolution image 생성 =&gt; scale-specific control            loss function, discriminator 등 수정하지 않고 오직 제너레이터에 대해서만 다룸.    latent space의 interpolation quality 측정하는 measure 제안          perceptual path length      linear separability        FFHQ 데이터셋 오픈Related work (Basic concepts)  Progressive GAN          GAN을 저해상도에서 고해상도로 점진적으로 학습        style transfer          content image &amp; style image가 있을 때 content 이미지와 유사하게 style image에 입히는 것      Methods(Explain one of the methods that the thesis used.)Generator Architecture      left : traditional generaotr : latent code z를 input layer에 바로 넣음.        right : style-based generator          first, map the input to an intermediate latent space W.      then controls the generator through adaptive instance normalization (AdaIN) at each conv. layer.      Gaussian noise is added after each conv.      제안한 모델을 차근차근 뜯어보자면Mapping Networkhttps://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431input vector z를 바로 input layer에 넣는 것이 아니라, mapping network를 거쳐 intermediate vector w 로 변환한 후 이미지를 생성한다.  바로 인풋 레이어에 넣지 않는 이유 : 고정된 input distribution에 맞춰야 해서 non-linear하게 mapping이 되고, 이것은 머리 색등과 같은 attribute를 변경하기 힘들어지기 때문.  위처럼 intermediate vector를 사용하게 되면 유동적인 공간에 mapping 시킬 수 있기 때문에 visual attribute 조절이 쉬워진다. =&gt; disentanglement 하다.즉, 이 네트워크에서는 z로부터 만들어진 style w를 구하고, 이를 affine transformation을 거친 A를 synthesis network에 넘겨주어 AdaIN operation을 통해 레이어에 스타일을 입힌다.Style Modules (AdaIN)https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431  위에서 생성된 w는 style에 대한 정보를 가지고 있다.  Synthesis network는 학습가능한 constant tensor(4x4x512)를 upsampling, convolution을 통해 1024x1024x3 이미지로 변환시킨다.  w의 affine transfomation을 통해 얻어진 A를 가지고 AdaIN operation을 통해 스타일을 입힌다.          normalize하고, 이를 scale하고 bias를 더함. 이게 스타일을 입히는 효과를 낸다.      매 conv 레이어마다 하므로, 각각의 레이어마다 다른 스타일을 조정할 수 있다. 이 말은 곧, 각 레이어가 특정한 attribute만을 담당한다는 뜻.                  세밀한 스타일 조정 가능해진다.                    Stochastic variation머리카락, 수염 등 stochastic한 요소들은 사진의 디테일에 매우 중요함.  위의 architecture에서 noise가 이에 대한 역할을 한다.  synthesis network에서 by adding per-pixel noise after each convolution.Style Mixingtwo random latent codes(w1,w2)를 사용하는 regularization 기법  하나의 w로 학습할 경우 여러 레이어에 대한 style이 correlate되는 문제점이 생길 수 있음.  ex. w1 스타일로 입혀놓지만, 랜덤으로 몇 개는 w2 스타일을 사용한다 …  위와 같은 방법을 통해 각 레이어가 담당하는 스타일을 명확하게 구분지을 수 있다.  (dropout과 비슷한 원리라고 함)Disentanglement studies  이 내용이 어려워서 제대로 이해하지 못함. 짧게 요약하겠음.  Disentanglment : latent space가 선형적인 구조를 가지게 되어, 하나의 factor가 움직였을 때 정해진 특성이 바뀌게 만드는 것.          예. z의 특정한 값을 바꿨을 때 생성되는 이미지의 하나의 특성(성별, 머리카락 길이 등)만 영향을 주게 되는 것        fixed distribution을 따르게 되면 억지로 끼워맞추게 되어 어색한 이미지가 만들어질 수 있음.  하지만 이 모델처럼 비선형 mapping function을 가지게 될 경우, 고정된 분포를 따를 필요가 없음.          위 그림에서 (c)와 같은 형태가 됨. 어느정도 a와 생김새가 비슷하면서 자연스럽게 맞출 수 있게 된 것        A major beneﬁt of our generator architecture is that the intermediate latent space W does not have to support sam-pling according to any ﬁxed distribution; its sampling density is induced by the learned piecewise continuous mapping f(z).  본 논문에서는 disentanglement를 학습할 수 있는 두 가지 평가 지표를 제안함.          Perceptual path length      Linear seperability      위의 내용을 자세히 알고 싶다면 이 곳을 참조                  링크                    Conclusion  our investigations to the separation of high-level attributes and stochastic effects, as well as the linearity of the intermediate latent space will prove fruitful in improving the understanding and controllability of GAN synthesis.Appendix. Truncation trick in W      트레이닝 중에 하는 게 아니고, generator가 만든 것 중에 더 나은 latent space 을 뽑는 법에 대한 trick        학습이 완료된 네트워크의 input을 제어하는 방법  위 수식을 통한 w' vector를 뽑는다.Additional studies(If you have some parts that cannot understand, you have to do additional studies for them. It’s optional.)disentanglement에 대한 명확한 이해가 필요함.References(References for your additional studies)  https://www.youtube.com/watch?v=TWzEbMrH59o&amp;feature=youtu.be  https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431  https://jayhey.github.io/deep%20learning/2019/01/16/style_based_GAN_2/  https://blog.lunit.io/2019/02/25/a-style-based-generator-architecture-for-generative-adversarial-networks/]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Computer Vision </tag>
        
          <tag> GAN </tag>
        
          <tag> Generative Model </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[HarDNet:A Low Memory Traffic network]]></title>
      <url>/paper%20review/2020/09/11/HarDNet/</url>
      <content type="text"><![CDATA[HarDNet : A Low Memory Traffic network 를 읽고 개인적으로 정리한 글입니다.HarDNet : A Low Memory Traffic network (ICCV 2019)Key Idea  기존의 metrics들에서의 inference time 측정은 부정확하다.          새로운 metric =&gt; memory traffic for accessing intermediate feature maps 측정                  inference latency 측정에 유용할 것, especially in such tasks as real-time object detection and semantic segmentation of high-resolution video.                    CIO : approximation of DRAM traffic이 될 수 있다.        computation, energy efficiency를 위해서는 fewer MACs, less DRAM이 좋은 것임 -&gt; 연구 방향  각각의 레이어의 MoC에 soft constraint를 적용했음.          low CIO network model with a reasonable increase of MACs를 위해      방법 -&gt; avoid to employ a layer with a very low MoC such as a Conv1x1 layer that has a very large input/output channel ratio.                  input/output channel ratio가 크면 low MoC를 가진다는 사실을 알 수 있음.                      Densely Connected Networks에 영감을 받아 모델 빌딩함.          DenseNet의 다수의 layer connections들을 줄였음. =&gt; concatenation cost를 줄이기 위해      balance the input/output channel ratio by increasing the channel width of a layer according to its connections.        DRAM trafficBasic Concepts  MAC : number of multiply-accumulate operations or floating point operations  DRAM : Dynamic Random-Access Memory          read/write model param. and feature maps        CIO : Convolutional input/output          모든 conv layer에 대해 IN(C,W,H) X OUT(C,W,H) sum        MoC : MACs over CIO of a layer = MACs/CIORelated Works  TREND : exploiting shortcuts  Highway networks, Residual Networks : add shortcuts to sum up a layer with multiple preceeding layers.  DenseNet : concatenates all preceeding layers as a shortcut achieving more efficent deep supervision.  그러나 shortcuts는 large memory usage, heavy DRAM traffic을 유발할 수 있다.                            Using shortcuts elongates the lifetime of a tensor, which may result in frequent data exchanges betwwen DRAM and cache.                      DenseNet의 sparsified version : LogDenseNet, SparseNet          Sparse                  The pros? If you have a lot of zeros, you don’t have to compute some multiplications, and you don’t have to store them. So you may gain on size and speed, for training and inference (more on this today).          The cons? Of course, having all these zeros will probably have an impact on network accuracy/performance.                    increase the growth rate(output channel width) to recover the accuracy dropping from the connection pruning, and the increase of growth rate can compromise the CIO reduction                  즉 increase of growth rate는 좋게 작용된다.                    Harmonic DenseNetSparsification and weighting  let layer k connect to layer k-2^n if 2^n divides k, where n is a non-negative integer and k-2^n &gt;= 0class HarDBlock(nn.Module):    def get_link(self, layer, base_ch, growth_rate, grmul):        if layer == 0:          return base_ch, 0, []        out_channels = growth_rate        link = []        for i in range(10):          dv = 2 ** i          if layer % dv == 0:            k = layer - dv            link.append(k)            if i &gt; 0:                out_channels *= grmul        out_channels = int(int(out_channels + 1) / 2) * 2        in_channels = 0        for i in link:          ch,_,_ = self.get_link(i, base_ch, growth_rate, grmul)          in_channels += ch        return out_channels, in_channels, link  2^n 개의 layer들이 이런 식으로 processed되면 layer [1 : 2^n -1]는 메모리에서 flush된다.          어떻게 flush 된다는 건지 잘 이해가 되지 않음.        Power-of-two-th harmonic waves가 만들어짐. 그래서 Harmonic 이다.      이 방식은 concatenation cost를 눈에 띄게 감소시킨다.        layers with an index divided by a larger power of two are more influential than those that divided by a smaller power of two.          많이 connection되니까 당연히 influential 하다.      In this model, they amplify these key layers by increasing their channels, which can balance the channel ratio between the input and output of a layer to avoid a low MoC.                  이런 key layer들을 amplify 했음(channel 수를 늘리면서)                      layer l has an initial growth rate k, we let its channel number to be k * m^n , where n is the max number satisfying that l is divided by 2^n                    m  은 low-dimensional compression factor 역할을 한다.          m 을 2보다 작게하면 input channel을 output channel보다 작게 할 수 있다.                          Empirically, settin m between 1.6 and 1.9                                          Transition and Bottleneck Layers  HDB(Harmonic Dense Block) : the proposed connection pattern forms a group of layers          is followed by a Conv1x1 layer as a transition        HDB의 depth는 2의 제곱수로 설정          HDB의 마지막 레이어가 가장 큰 채널수를 가지도록 하기 위해서        DenseNet -&gt; gradient할 때 모든 레이어를 다 pass함  논문의 HBD with depth L -&gt; pass through at most log L layers          degradation을 완화시키기위해, depth-L HDB를 layer L과 all its preceeding odd numbered layers  를 concatenation시킨다.      2~L-2의 all even layer들의 아웃풋은 HDB가 한번 끝날때마다 버려진다.        Bottleneck layer          DenseNet에서는 param. efficiency를 위해 매 Conv3x3 layer전에 bottleneck을 두었다.      하지만 HarDnet에서는 위에서 이미 channel ratio(매 레이어마다 input&amp;output 사이의)의 균형을 잡았으므로 bottleneck layer는 쓸모없어진다.      그래서 HBD에서는 Bottleneck layer없이 Conv3x3 for all layers        Transition layer                inverted trainsition module                  maps input tensor to an additional max pooling function along with the original average pooling, followed by concatenation and Conv1x1.          50% of CIO를 감소시킴                    Experiments      CamVid Dataset          replace all the blocks in a FC-DenseNet with HDBs      the architecture of FC-DenseNet with an encoder-decoder structure and block level shortcuts to create models for sematic segmentation.              We propose FC-HarDNet84 as specified in Table 3 for comparing with FC-DenseNet103. The new network achieves CIO reduction by 41% and GPU inference time reduction by 35%. A smaller version, FC-HarDNet68, also outperforms FC-DenseNet56 by a 65% less CIO and 52% less GPU inference time.        ImageNet Datasets  Object Detection          HarDNet-68 as a backbone model for a Single Shot Detector (SSD) and train it with PASCAL VOC 2007 and MS COCO datasets      Discussion  There is an assumption with the CIO, which is a CNN model that is processed layer by layer without a fusion. In contrast, fused-layer computation for multiple convolutional layers has been proposed.  CIO still failed to predict the actual inference time such as comparing two network models with significantly differnent architectures  In some of the layers CIO may dominate, but for the other layers, MACs can still be the key factor if its computational density is relatively higher. To precisely predict the inference latency of a network, we need to breakdown to each of the layers and investigate its MoC to predict the inference latency of the layer.  어쨌거나 DRAM traffic의 중요성을 강조하고 싶어함.  traffic reduction을 위한 가장 좋은 방법은 MoC를 증가시키는 것          which might be counter-intuitive to the widely-accepted knowledge of that using more Conv1x1 achieves a higher efficiency.      ]]></content>
      <categories>
        
          <category> Paper Review </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Traffic </tag>
        
          <tag> Computer Vision </tag>
        
          <tag> Semantic Segmentation </tag>
        
          <tag> Network </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[딥러닝 모델을 이용한 수화 교육 웹 어플리케이션-Handlang(2)]]></title>
      <url>/project/2020/08/26/Handlang2/</url>
      <content type="text"><![CDATA[DSC EWHA에서 2019.9~2020.8 까지 진행한 팀프로젝트로, 딥러닝 모델을 이용한 수화 학습 웹 어플리케이션입니다.이 포스팅에서는 웹에 관련된 것을 다룹니다.Handlang - ASL(American Sign Language) Education by using deep learning model딥러닝으로 학습된 수화 인식 모델을 바탕으로 알파벳, 숫자에 해당되는 수화를 학습 및 연습 할 수 있는 웹 어플리케이션입니다.Wireframe - FigmaFigma를 사용하여 팀원들과 홈페이지 와이어프레임을 구상하였습니다.Flask웹 개발 초보자에게 비교적 쉬운 Flask를 사용하여 구현하였습니다.Model Deploy  학습시킨 모델을 불러오는 법...from keras.models import load_model...model = load_model('model/handlang_model_4.h5') # 지문자 모델model2 = load_model('model/su_adamax.h5') # 숫자 모델Ajax웹캠으로 받은 이미지를 실시간으로 Detect해야하기 때문에 페이지를 새로 고치지 않아도 데이터를 로드할 수 있는 Ajax를 사용하였습니다.Translation한글/영어 버전의 웹페이지를 구현하기 위해 flask_babel을 사용했습니다.Study &amp; QuizTeam HandlangProject Github Link]]></content>
      <categories>
        
          <category> Project </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Object Detection </tag>
        
          <tag> Flask </tag>
        
          <tag> Education Application </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[딥러닝 모델을 이용한 수화 교육 웹 어플리케이션-Handlang(1)]]></title>
      <url>/project/2020/08/26/Handlang/</url>
      <content type="text"><![CDATA[DSC EWHA에서 2019.9~2020.8 까지 진행한 팀프로젝트로, 딥러닝 모델을 이용한 수화 학습 웹 어플리케이션입니다.이 포스팅에서는 수화 인식 딥러닝 모델에 대해서만 다룹니다.Handlang - ASL(American Sign Language) Education by using deep learning model딥러닝으로 학습된 수화 인식 모델을 바탕으로 알파벳, 숫자에 해당되는 수화를 학습 및 연습 할 수 있는 웹 어플리케이션입니다.모델 정확도 개선을 위한 여러 시도들[About models]YOLO darknetYOLO is the model with excellent performance in Object detection.We used darkflow, not yolo darknet, to take advantage of tensorflow.https://github.com/thtrieu/darkflowThe most attempts were made at darkflow.  YOLO_experiment_1          [a~z] 600 images each. training 500 epochs      acc : 0.42      Feedback -&gt; Predict performance is poor.  YOLO_experiment_2          pretrained weight - hand tracking model (https://github.com/Abdul-Mukit/dope_with_hand_tracking)      a~y 600 images each. 140 epochs      acc : 0.47              YOLO_experiment_3          pretrained weight - yolov2-tiny.weight(https://pjreddie.com/darknet/yolov2/)      a~y 600 images each. 220 epochs      acc : 0.56            Feedback -&gt; It is still not a satisfactory performance.Inception-v3We tried transfer learning by using inception-v3.  a~y 600 images each. 1000 steps  test acc. : about 88%          but not that much at real-time…            Tensorflow-Object-Detection-APIWe tried transfer learning by using fast r-cnn.  a~y 600 images each. 6000 steps  test acc. : about 80%          not test by images, but test by webcam.                  poor performance                    Self-feedback: It is still not a satisfactory performance.Finally Custom CNN model(our current model)!handlang_model = Sequential()handlang_model.add(Conv2D(64, kernel_size=4, strides=1, activation='relu', input_shape=target_dims))handlang_model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))handlang_model.add(Dropout(0.5))handlang_model.add(Conv2D(128, kernel_size=4, strides=1, activation='relu'))handlang_model.add(Conv2D(128, kernel_size=4, strides=2, activation='relu'))handlang_model.add(Dropout(0.5))handlang_model.add(Conv2D(256, kernel_size=4, strides=1, activation='relu'))handlang_model.add(Conv2D(256, kernel_size=4, strides=2, activation='relu'))handlang_model.add(Flatten())handlang_model.add(Dropout(0.5))handlang_model.add(Dense(512, activation='relu'))handlang_model.add(Dense(n_classes, activation='softmax'))handlang_model.summary()handlang_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=["accuracy"])Feedback : 위 모델을 사용하고, 웹 코드 내에서의 trick을 이용하여 조금 더 빠른 인식과 높은 정확도를 가질 수 있었음.Datasets아래 데이터 셋들은 모델 트레이닝에 사용되었습니다.참고로, 우리 모델에서는 알파벳 i,z 제외했습니다. (손동작이 포함되었기 때문에)  https://www.kaggle.com/grassknoted/asl-alphabet          가장 성능이 좋은 모델에 사용된 데이터 셋입니다.      다른 모델에서는 아래의 데이터셋들을 사용했습니다.  https://www.kaggle.com/rajarshighoshal/asltestimages  https://www.kaggle.com/muhammadkhalid/sign-language-for-alphabets  https://www.kaggle.com/ayuraj/asl-datasetTeam HandlangProject Github Link]]></content>
      <categories>
        
          <category> Project </category>
        
      </categories>
      <tags>
        
          <tag> Deep Learning </tag>
        
          <tag> Object Detection </tag>
        
          <tag> Flask </tag>
        
          <tag> Education Application </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Next Theme Tutorial]]></title>
      <url>/tutorial/2017/07/20/next-tutorial/</url>
      <content type="text"><![CDATA[  NexT is a high quality elegant Jekyll theme ported from Hexo Next. It is crafted from scratch, with love.Live PreviewScreenshots      Desktop        Sidebar    Sidebar (Post details page)  MobileInstallationCheck whether you have Ruby 2.1.0 or higher installed:ruby --versionInstall Bundler:gem install bundlerClone Jacman theme:git clone https://github.com/Simpleyyt/jekyll-theme-next.gitcd jekyll-theme-nextInstall Jekyll and other dependencies from the GitHub Pages gem:bundle installRun your Jekyll site locally:bundle exec jekyll serverMore Details：Setting up your GitHub Pages site locally with JekyllFeaturesMultiple languages support, including: English / Russian / French / German / Simplified Chinese / Traditional Chinese.Default language is English.language: en# language: zh-Hans# language: fr-FR# language: zh-hk# language: zh-tw# language: ru# language: deSet language field as following in site _config.yml to change to Chinese.language: zh-HansComment support.NexT has native support for DuoShuo and Disqus comment systems.Add the following snippets to your _config.yml:duoshuo:  enable: true  shortname: your-duoshuo-shortnameORdisqus_shortname: your-disqus-shortnameSocial MediaNexT can automatically add links to your Social Media accounts:social:  GitHub: your-github-url  Twitter: your-twitter-url  Weibo: your-weibo-url  DouBan: your-douban-url  ZhiHu: your-zhihu-urlFeed link.  Show a feed link.Set rss field in theme’s _config.yml, as the following value:  rss: false will totally disable feed link.      rss:   use sites’ feed link. This is the default option.    Follow the installation instruction in the plugin’s README. After the configuration is done for this plugin, the feed link is ready too.    rss: http://your-feed-url set specific feed link.Up to 5 code highlight themes built-in.NexT uses Tomorrow Theme with 5 themes for you to choose from.Next use normal by default. Have a preview about normal and night:Head over to Tomorrow Theme for more details.ConfigurationNexT comes with few configurations.# Menu configuration.menu:  home: /  archives: /archives# Faviconfavicon: /favicon.ico# Avatar (put the image into next/source/images/)# can be any image format supported by web browsers (JPEG,PNG,GIF,SVG,..)avatar: /default_avatar.png# Code highlight theme# available: normal | night | night eighties | night blue | night brighthighlight_theme: normal# Fancybox for image galleryfancybox: true# Specify the date when the site was setupsince: 2013Browser support]]></content>
      <categories>
        
          <category> tutorial </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Gallery Post]]></title>
      <url>/photo/2014/11/19/gallery-post/</url>
      <content type="text"><![CDATA[Nunc dignissim volutpat enim, non sollicitudin purus dignissim id. Nam sit amet urna eu velit lacinia eleifend. Proin auctor rhoncus ligula nec aliquet. Donec sodales molestie lacinia. Curabitur dictum faucibus urna at convallis. Aliquam in lectus at urna rutrum porta. In lacus arcu, molestie ut vestibulum ut, rhoncus sed eros. Sed et elit vitae risus pretium consectetur vel in mi. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi tempus turpis quis lectus rhoncus adipiscing. Proin pulvinar placerat suscipit. Maecenas imperdiet, quam vitae varius auctor, enim mauris vulputate sapien, nec laoreet neque diam non quam.Etiam luctus mauris at mi sollicitudin quis malesuada nibh porttitor. Vestibulum non dapibus magna. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Proin feugiat hendrerit viverra. Phasellus sit amet nunc mauris, eu ultricies tellus. Sed a mi tortor, eleifend varius erat. Proin consectetur molestie tortor eu gravida. Cras placerat orci id arcu tristique ut rutrum justo pulvinar. Maecenas lacinia fringilla diam non bibendum. Aenean vel viverra turpis. Integer ut leo nisi. Pellentesque vehicula quam ut sapien convallis consequat. Aliquam ut arcu purus, eget tempor purus. Integer eu tellus quis erat tristique gravida eu vel lorem.]]></content>
      <categories>
        
          <category> Photo </category>
        
      </categories>
      <tags>
        
          <tag> consectetur </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[MathJax with Jekyll]]></title>
      <url>/opinion/2014/02/16/Mathjax-with-jekyll/</url>
      <content type="text"><![CDATA[One of the rewards of switching my website to Jekyll is theability to support MathJax, which means I can write LaTeX-like equations that getnicely displayed in a web browser, like this one \( \sqrt{\frac{n!}{k!(n-k)!}} \) orthis one \( x^2 + y^2 = r^2 \).What’s MathJax?If you check MathJax website (www.mathjax.org) you’ll seethat it is an open source JavaScript display engine for mathematics that works in allbrowsers.How to implement MathJax with JekyllI followed the instructions described by Dason Kurkiewicz forusing Jekyll and Mathjax.Here are some important details. I had to modify the Ruby library for Markdown inmy _config.yml file. Now I’m using redcarpet so the corresponding line in theconfiguration file is: markdown: redcarpetTo load the MathJax javascript, I added the following lines in my layout post.html(located in my folder _layouts)&lt;script type="text/javascript"    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"&gt;&lt;/script&gt;Of course you can choose a different file location in your jekyll layouts.Note that by default, the tex2jax preprocessor defines theLaTeX math delimiters, which are \\(...\\) for in-line math, and \\[...\\] fordisplayed equations. It also defines the TeX delimiters $$...$$ for displayedequations, but it does not define $...$ as in-line math delimiters. To enable in-line math delimiter with $...$, please use the following configuration:&lt;script type="text/x-mathjax-config"&gt;MathJax.Hub.Config({  tex2jax: {    inlineMath: [['$','$'], ['\\(','\\)']],    processEscapes: true  }});&lt;/script&gt;&lt;script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"&gt;&lt;/script&gt;A Couple of ExamplesHere’s a short list of examples. To know more about the details behind MathJax, you canalways checked the provided documentation available athttp://docs.mathjax.org/en/latest/Let’s try a first example. Here’s a dummy equation:\[a^2 + b^2 = c^2\]How do you write such expression? Very simple: using double dollar signs$$a^2 + b^2 = c^2$$To display inline math use \\( ... \\) like this \\( sin(x^2) \\) which getsrendered as \( sin(x^2) \)Here’s another example using type \mathsf$$ \mathsf{Data = PCs} \times \mathsf{Loadings} $$which gets displayed as\[\mathsf{Data = PCs} \times \mathsf{Loadings}\]Or even better:\\[ \mathbf{X} = \mathbf{Z} \mathbf{P^\mathsf{T}} \\]is displayed as\[ \mathbf{X} = \mathbf{Z} \mathbf{P^\mathsf{T}} \]If you want to use subscripts like this \( \mathbf{X}_{n,p} \) you need to scape theunderscores with a backslash like so \mathbf{X}\_{n,p}:$$ \mathbf{X}\_{n,p} = \mathbf{A}\_{n,k} \mathbf{B}\_{k,p} $$will be displayed as\[ \mathbf{X}_{n,p} = \mathbf{A}_{n,k} \mathbf{B}_{k,p} \]\[\lim_{x\to 0}{\frac{e^x-1}{2x}}\overset{\left[\frac{0}{0}\right]}{\underset{\mathrm{H}}{=}}\lim_{x\to 0}{\frac{e^x}{2}}={\frac{1}{2}}\]]]></content>
      <categories>
        
          <category> opinion </category>
        
      </categories>
      <tags>
        
          <tag> resources </tag>
        
          <tag> jekyll </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
