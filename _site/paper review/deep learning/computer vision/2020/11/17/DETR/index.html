
<!doctype html>














<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/assets/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/assets/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/assets/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Deep Learning,Computer Vision,Object Detection,Encoder-Decoder,Transformer,Panoptic Segmentation,DETR,ViT," />





  <link rel="alternate" href="/atom.xml" title="Yeonsoo Kim's blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico?v=5.1.1" />
















<meta name="description" content="DETR : End-to-End Object Detection with Transformers 를 읽고 정리한 글입니다.">
<meta name="keywords" content="Deep Learning, Computer Vision, Object Detection, Encoder-Decoder, Transformer, Panoptic Segmentation, DETR, ViT">
<meta property="og:type" content="article">
<meta property="og:title" content="DETR:End-to-End Object Detection with Transformers">
<meta property="og:url" content="http://localhost:4000/paper%20review/deep%20learning/computer%20vision/2020/11/17/DETR/">
<meta property="og:site_name" content="Yeonsoo Kim's blog">
<meta property="og:description" content="DETR : End-to-End Object Detection with Transformers 를 읽고 정리한 글입니다.">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://user-images.githubusercontent.com/48315997/99262847-c8c19280-2861-11eb-8c4a-ea37362777ae.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/48315997/99262815-c0695780-2861-11eb-8170-8b6271d35ddd.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/48315997/99263078-11794b80-2862-11eb-9452-ca8b498d812c.png">
<meta property="og:image" content="609">
<meta property="og:image" content="https://user-images.githubusercontent.com/48315997/99273109-eb58a900-286b-11eb-9c47-c2bbeae303b1.png">
<meta property="og:image" content="644">
<meta property="og:image" content="https://user-images.githubusercontent.com/48315997/99273849-e3e5cf80-286c-11eb-8f92-c330bddc9e51.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/48315997/99274139-4dfe7480-286d-11eb-9d6d-e06ab83853f3.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/48315997/99274340-9322a680-286d-11eb-811d-ae3aeb96712f.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/48315997/99275057-60c57900-286e-11eb-87fa-4c29646eb60c.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/48315997/99277842-ab94c000-2871-11eb-803f-d34e1bc3406b.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DETR:End-to-End Object Detection with Transformers">
<meta name="twitter:description" content="DETR : End-to-End Object Detection with Transformers 를 읽고 정리한 글입니다.">
<meta name="twitter:image" content="https://user-images.githubusercontent.com/48315997/99262847-c8c19280-2861-11eb-8c4a-ea37362777ae.png">


<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://localhost:4000/"/>





  <title>DETR:End-to-End Object Detection with Transformers | Yeonsoo Kim's blog</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'G-X7P416ZKCL', 'auto');
  ga('send', 'pageview');
</script>













</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yeonsoo Kim's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            


<div id="posts" class="posts-expand">
  
  

  

  
  
  

  <article class="post post-type- " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://localhost:4000/paper%20review/deep%20learning/computer%20vision/2020/11/17/DETR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yeonsoo Kim">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="assets/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yeonsoo Kim's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
          
          
            DETR:End-to-End Object Detection with Transformers
          
        </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-17T00:00:00+09:00">
                2020-11-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/category/#/Paper%20Review" itemprop="url" rel="index">
                    <span itemprop="name">Paper Review</span>
                  </a>
                </span>

                
                
                  , 
                
              
                
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/category/#/Deep%20Learning" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/category/#/Computer%20Vision" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          
            
          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
  
  












  <p>DETR : End-to-End Object Detection with Transformers 를 읽고 정리한 글입니다.</p>

<hr />

<p>올해 가장 큰 인기를 몰고 있는 논문 중 하나인 DETR을 읽어보겠습니다.</p>

<p>Yann Lecun 교수님께서 삼성 AI 포럼에서 DETR 논문을 언급하면서 Transformer + Vision 의 연구가 이제 주 과제일 것이라고 말씀하셨습니다. 
DETR은 나오자마자 큰 화제가 되었기에 살짝 읽어보고 리뷰는 안하려 했으나, ViT 논문을 읽고 저도 이 분야의 장래가 유망하다고 인식하게 되어 이렇게 하나하나 뜯어봤습니다!</p>

<p>피드백은 언제나 환영합니다! 댓글창을 아직 열지 못해서 메일로 부탁드립니다. 꾸벅(__)</p>

<hr />

<h1 id="abstract">Abstract</h1>

<p><br /></p>

<p>이 논문에서는 object detection을 하나의 <strong>direct set prediction</strong> 문제로 본다.</p>

<p>이 접근법은 <strong>Non-maximum suppression, anchor generation</strong>과 같은 작업들을 사용하지 않는 방법으로, detection pipeline을 매우 간소화시킬 수 있다.</p>

<p>논문에서 제안하는 모델은 DEtection Transformer(이하 DETR)이다. 이 모델의 주요 특징으로는 object detection을 set prediction problem으로 본다 하였으므로, <strong>set 기반의 global loss를 사용</strong>한다는 점이다. Transformer encoder-decoder 구조를 사용하여 bipartite matching을 통해 unique prediction을 한다.</p>

<p>학습된 object 쿼리들의 small set이 주어지면, DETR은 객체들과 전체 이미지 context 간의 관계에 대해 <strong>병렬적(parallel)</strong> 으로 final set에 대한 예측을 directly output으로 내보낸다.</p>

<p>이 모델은 library도 필요없고, 개념적으로 매우 심플하다.
COCO dataset에 대해서 Faster R-CNN baseline 급의 정확도와 런타임 성능을 보여줬다고 한다.</p>

<p>게다가, DETR은 <strong>panoptic segmentation</strong>을 쉽게 일반화할 수 있다!</p>

<p><br /></p>

<h1 id="introduction">Introduction</h1>

<p><br /></p>

<p>Object detection의 목표는 바운딩 박스 set과 label을 맞추는 것이다.</p>

<p>최근 대부분의 detector들은 이를 set of proposals, anchors, or window centers에 대해 regression/classification을 사용하는 ‘간접적인’방식으로 해결하려 한다.</p>

<p>하지만 이런 방식들은 postprocessing 단계에서 중복된 예측값들을 collapse 시키는 과정이나(NMS를 얘기하는 듯하다), 앵커 셋에 대해 미리 assign하는 휴리스틱한 방식 등에 의해 performance가 영향 받을 수 있다.</p>

<p>그래서 이 논문에서는 위와 같은 <em>Indirect</em> 방식이 아닌 <strong><em>Direct</em></strong> 방식을 사용한다.</p>

<blockquote>
  <p>We propose a direct set prediction approach to bypass the surrogate tasks.</p>
</blockquote>

<p>이와 같은 end-to-end 방식은 기존의 object detection 연구에서는 자주 다뤄지지 않았던 것이다.</p>

<p>Obejct detection 문제를 direct set prediction problem으로 만들어 training pipeline을 만든다.
이 때, transformer 기반의 인코더-디코더 구조를 사용한다. 트랜스포머의 self-attention 기법은 elements들 간의 모든 pairwise interactions를 통해 중복된 prediction을 제거할 수 있게 해준다.</p>

<p>DETR은 모든 object들을 <strong>한번에</strong> predict한다. 이는 end-to-end 특성인데, 실제값과 예측값 사이에서 set loss를 통해 bipartite matching(이분 매칭)을 훈련한다. 이로 인해 DETR은 hand-designed 작업 없이 간단한 detection 파이프라인을 가질 수 있는 것이다.</p>

<p>다른 detection model들과 다르게 DETR은 customized layer도 필요하지 않아, 모델 자체도 굉장히 간단하다. CNN과 transformer만 가지고 있다면 쉽게 reproduce 할 수 있다.</p>

<p>이전의 direct set prediction 연구들과 비교할 때, DETR의 주요점은 bipartite matching(이분 매칭)과 parallel decoding을 결합시킨 것이다. 
DETR의 Matching loss function은 예측값을 ground truth에 uniquely 할당할 수 있고, predicted objects의 순열이 변하지 않기 때문에 병렬적으로 predict할 수 있다.</p>

<p>DETR은 COCO dataset에 evaluate 해봤을 때, Faster R-CNN baseline에 대하여 경쟁력 있는 결과를 보여주었다. 특히 큰 object들에 대하여 상당히 좋은 결과를 보여주었다고 한다. <em>하지만, small object들에 대해서는 low performance를 보였다.</em> 이는 아마 Faster R-CNN에 FPN을 적용하여 좋은 성과를 이뤘듯이 future work에서도 해결법이 생기지 않을까 기대한다.</p>

<p>DETR은 복잡한 문제를 쉽게 확장시킬 수 있다. 실험에서는 op pretrained DETR을 이용하여 segmentation head를 학습시켰더니 Panoptic Segmentation에 경쟁력을 가졌다고 한다.</p>

<p><br /></p>

<h1 id="related-work">Related Work</h1>

<p><br /></p>

<blockquote>
  <p>Our work build on prior work in several domains: bipartite matching losses for
set prediction, encoder-decoder architectures based on the transformer, parallel
decoding, and object detection methods.</p>
</blockquote>

<p><br /></p>

<h1 id="the-detr-model">The DETR model</h1>

<p><br /></p>

<p>set prediction을 위해 가장 중요한 요소는 2개이다.</p>

<ol>
  <li><strong>a set prediction loss</strong> that forces <strong>unique matching</strong> between predicted and ground truth boxes</li>
  <li><strong>an architecture</strong> that <strong>predicts</strong> (in a single pass) a set of objects and models their relation</li>
</ol>

<h2 id="object-detection-set-prediction-loss">Object detection set prediction loss</h2>

<p>DETR은 fixed-size set에서 N개의 prediction을 한다. <strong>이 때 N은 이미지의 object 개수보다 상당히 크게 설정한다.</strong></p>

<p>ground truth에 대하여 predicted objects(class, position, size)를 scoring하는 것이 학습과정에서 어려웠다고 한다.
여기서 loss는 예측값과 ground truth 사이의 최적의 이분 매칭을 만들어 내고, 이를 통해 bounding box loss를 최적화한다.</p>

<p>$y$를 ground truth, $\hat{y} = {\hat{y_i}}_{i=1}^N$ 은 N개의 prediction set이라 하자.</p>

<p>N은 이미지내의 object 개수보다 크다고 가정하면, $y$도 a set of size N에 $\varnothing$ (no object)가 padded 됐다고 볼 수 있다.</p>

<p>이러한 y, y_hat 사이의 bipartite matching(이는 ground truth와 prediction 사이의 일대일 매칭이라 생각하면 편할 듯) 찾기 위해서, matching cost가 minimum이 되는 바운딩 박스의 순서들, 즉 순열을 찾아야 한다.</p>

<p>이러한 optimal assignent는 헝가리안 알고리즘에 의해 효율적으로 계산될 수 있음.</p>

<p>이제 다시 matching cost에 대해 알아보자. each element of <em>i</em> of the ground truth set은 $y_i = (c_i, b_i)$ 로 나타낼 수 있음. 이 때 c_i는 target class label, b_i는 box center coordinates(xy의 center, height, width) 임.</p>

\[L_{Hungarian}(y,\hat{y} = \mathbb{-1}_{c_i\neq\varnothing} + \mathbb{1}L_{box}(b_i, \hat{b_{\sigma(i)}})\]

<p>앞의 항에 -1을 곱하는 이유는 해당 클래스 probability가 높을수록 loss를 낮게 산정하기 위함이고, 뒷 항은 bounding box의 로스를 크로스 엔트로피와 같은 과정없이 그대로 적용한다는 것이 조금 특이한 지점이다.</p>

<p>여기서 이 논문의 차별점 혹은 중요한 지점은 중복(duplicates)없이 direct set prediction을 위한 일대일 매칭이 된다는 점이다. 즉, 중복되는 prediction이 존재하지 않다는 뜻. <strong>(일대일 매칭을 하기 때문에 중복되는 예측이 생기지 않음 -&gt; NMS가 필요없다!!)</strong></p>

<p><strong><em>다른 모델에서는 앵커박스를 많이 뽑아서 하나 물체에 여러 개의 바운딩 박스를 그려서 NMS(Non-maximum suppression)을 사용하는 방식이었음!!</em></strong></p>

<p>이렇게 일대일 매칭된 prediction과 ground truth 사이에서는 위에서 언급했듯이 헝가리안 기반의 loss를 사용해서 학습함. (즉 방금했던 것은 matching cost를 계산하는 loss였고, 이번이 진짜 예측값과 Ground Truth사이의 loss인듯?)</p>

<p><img src="https://user-images.githubusercontent.com/48315997/99262847-c8c19280-2861-11eb-8c4a-ea37362777ae.png" alt="image" /></p>

<p>L_match와 약간 비슷해보이지만, class 확률 값을 no-object 일 때도 계산한다는 점, log를 사용해 cross entropy같은 성질이 추가되었다는 점이 다르다.
클래스가 no_object일 때 앞의 항의 loss를 1/10으로 줄여 class imbalance를 조절했다고 한다.</p>

<p>마지막으로 bounding box loss를 살펴보자. 다른 detector들은 미리 정해놓은 앵커 박스 candidate들을 얼마나 움직일지에 대한 <strong>델타</strong>를 학습했다. 그러나 DETR에서는 바운딩 박스를 directly 예측한다. L1 Loss를 사용하는데, L1 loss의 단점은 바운딩 박스가 크면 작은 거에 비해 loss가 더 큼. (단순히 좌표의차이만을 고려하니까)</p>

<p>이 단점을 보완하기 위해 Generalized IoU loss를 L1 Loss에 linear combination 했다.</p>

<p><img src="https://user-images.githubusercontent.com/48315997/99262815-c0695780-2861-11eb-8170-8b6271d35ddd.png" alt="image" /></p>

<h2 id="detr-architecture">DETR Architecture</h2>

<p><img src="https://user-images.githubusercontent.com/48315997/99263078-11794b80-2862-11eb-9452-ca8b498d812c.png" alt="image" /></p>

<p>[요약]</p>
<ul>
  <li>CNN으로 feature map 생성</li>
  <li>트랜스포머 인코더에 들어가기 위해서 positional encoding 더함</li>
  <li>트랜스포머 인코더의 출력은 디코더에 들어감
    <ul>
      <li>이 값들이 <strong>key, value</strong> 역할을 함.</li>
    </ul>
  </li>
  <li>디코더의 input으로는 N개의 object <strong>query</strong>가 들어간다.
    <ul>
      <li>이 쿼리도 학습하게 됨. 처음에는 랜덤값으로 채우지만, 점점 학습하는 것</li>
      <li>일종의 positional encoding 역할을 함 (어느 부분을 관심있게 볼 것인지)</li>
    </ul>
  </li>
  <li>각각 FFN을 통해서 N개를 예측하게 된다.</li>
</ul>

<p><br /></p>

<p>DETR의 전체적인 구조는 위 Figure과 같다. 크게 3가지 컴포넌트로 구성된다.</p>

<ol>
  <li>
    <p>CNN backbone : CNN을 이용해 compact feature representation을 추출한다.(feature map)</p>
  </li>
  <li>
    <p>Encoder-Decoder Transformer</p>
  </li>
  <li>
    <p>A simple Feed Forward Network(FFN) : 결과값 출력</p>
  </li>
</ol>

<p>DETR의 구조는 매우 간단해서 베이스라인 모델을 파이토치로 구현하면 50줄정도이다! (글 하단부에 첨부하겠음.)</p>

<h3 id="backbone">Backbone</h3>

<p>실험에서는 ResNet을 사용함. H, W는 5번 정도의 down-scale을 했다.(H0/32, W0/32)
최종 C = 2048로 사용(ResNet 모델의 마지막 레이어가 2048이기 때문)</p>

<p><img width="609" alt="스크린샷 2020-11-17 오전 12 10 58" src="https://user-images.githubusercontent.com/48315997/99269155-61a7dc00-2869-11eb-9ee9-9d13ef280c23.png" /></p>

<h3 id="transformer-encoder">Transformer encoder</h3>

<p>우선 1x1 conv.를 통해 채널을 $d$ dimension으로 줄인다.</p>

<p>또 인코더에 들어가기 위해선 벡터로 바뀌어야 하니까 3차원을 2차원으로 바꿔야 한다. 
H,W를 다 합쳐서 spatial dimensions of d x HW로 만들어준다.
이 때 HW는 시퀀스의 개수가 되고, 각 시퀀스 벡터의 사이즈가 d가 되는 것이다.</p>

<p>트랜스포머는 attention기반이기 때문에 permutation-invariant하다. 즉, 순서를 무시한다는 것이다.</p>

<p>때문에, 순서를 부여하기 위해 fixed positional encoding을 input of each attention layer에 추가한다. 
<em>(참고) x, y축 따로 d/2씩 해서 인코딩해서 concat하는 식으로 positional encoding을 해준다.</em></p>

<h3 id="transformer-decoder">Transformer decoder</h3>

<p>transformer의 스탠다드 아키텍쳐를 따랐다고 한다.</p>

<p>다만 original과의 차이점은 각 디코더 레이어에서 N개의 객체를 <strong>parallel하게 디코딩</strong>한다는 것이다.</p>

<p>디코더를 통과하게 되면 N개의 오브젝트가 parallel하게 나오는데, 이 때 디코더의입력으로 들어가는 것은 object queries이다.</p>

<p>디코더 역시 <strong>permutation-invariant</strong> 하기 때문에 일종의 positional encoding이 필요하다. (입력으로 들어가는 것들이 다 달라야 다른 결과를 뽑아줄 수 있기 때문이다)</p>

<p>여기서 object query가 positional encoding 역할을 한다.
이 쿼리는 학습의 대상이 되며 each attention layer의 인풋으로 추가된다.</p>

<p>이것들은 <strong>independently FFN을 지나</strong> 박스 좌표, 클래스 라벨로 디코드된다. (그렇게 N개의 final prediction을 얻게 된다.)</p>

<p>개인적으로 가장 중요한 부분이라고 생각하는게, 이러한 self- and encoder-decoder attention 모델은 image를 <strong>global 추론할 수 있게 해준다.</strong> 즉 use the whole image as context로 사용할 수 있는 것이다!!</p>

<h3 id="prediction-feed-forward-networks-ffns">Prediction feed-forward networks (FFNs)</h3>

<p>3-layer 퍼셉트론 with ReLU 구조이다.</p>

<p>이 FFN은 bounding box의 normalized center coordinates, height, width를 예측하며, softmax function을 통해 class label을 예측한다.</p>

<p>no object 클래스는 background role을 하기도 한다.</p>

<p><br /></p>

<h1 id="experiments">Experiments</h1>

<p><br /></p>

<p>다는 살펴보지 않고, 몇 개만 살펴볼 것임.</p>

<h2 id="comparison-with-faster-r-cnn">Comparison with Faster R-CNN</h2>

<p><img src="https://user-images.githubusercontent.com/48315997/99273109-eb58a900-286b-11eb-9c47-c2bbeae303b1.png" alt="image" /></p>

<p>AP_S : Small scale images</p>

<p>AP_L : Large scale images</p>

<p>CNN은 local 특성을 잘 반영하므로 small img.들에 DETR보다 더 효과적이다.</p>

<p>하지만 DETR은 Attention 기반이기 때문에 모든 position을 볼 수 있고, 때문에 Large img.에 매우 효과적이다.</p>

<p><em>그러나 최근 나온 논문 Deformable DETR에서 AP_S도 Faster R-CNN보다 높은 성과를 거두었다! (다음 논문은 이걸 읽어보려고 한다.)</em></p>

<p><em>(Attention이 global한 reason이 된다는 장점이 있기 때문에 panoptic segmentation에 잘 맞지 않을까하는 생각이 든다…)</em></p>

<h2 id="number-of-encoder-layers">Number of encoder layers</h2>

<p><img width="644" alt="스크린샷 2020-11-17 오전 12 33 56" src="https://user-images.githubusercontent.com/48315997/99273597-95383580-286c-11eb-9501-87a86806a63f.png" /></p>

<p>인코더의 블럭수가 많을수록 AP는 올라간다.</p>

<p>또한 <strong>Encoder는 disentangling</strong>(이미지 분해, 해체) 역할에 아주중요한 역할을 한다는 것을 알 수 있었다고 한다.</p>

<p><img src="https://user-images.githubusercontent.com/48315997/99273849-e3e5cf80-286c-11eb-8f92-c330bddc9e51.png" alt="image" /></p>

<p>image disentanglement 란 위의 사진과 같이 객체별로(인스탄스별로) 잘 분리가 됐음을 표현하는 듯하다.</p>

<p>이렇게 객체별로 attention이 잘 나누어진다면 디코더에서 객체의 bounding box, class를 예측하는 것은 매우 쉽다고 한다.</p>

<h2 id="number-of-decoder-layers">Number of decoder layers</h2>

<p><img src="https://user-images.githubusercontent.com/48315997/99274139-4dfe7480-286d-11eb-9d6d-e06ab83853f3.png" alt="image" /></p>

<p>이것은 decoder layer의 개수가 어느정도 되면, NMS를 쓸 때와 성능상 별 차이가 없다는 결과이다.</p>

<p><img src="https://user-images.githubusercontent.com/48315997/99274340-9322a680-286d-11eb-811d-ae3aeb96712f.png" alt="image" /></p>

<p>개인적으로 정말 놀랐던 결과이다. 객체의 head, edge를 정말 잘 attention하고 있음을 알 수 있다. 
<strong>인코더는 global attention을 통해 인스턴스들을 분리한다면, 디코더는 클래스와 객체의 바운더리(가장자리)를 추출한다고 한다</strong>.</p>

<h2 id="panoptic-segmentation">Panoptic Segmentation</h2>

<p><img src="https://user-images.githubusercontent.com/48315997/99275057-60c57900-286e-11eb-87fa-4c29646eb60c.png" alt="image" /></p>

<p><br /></p>

<h1 id="conclusion">Conclusion</h1>

<p><br /></p>

<p>DETR은 object detection 문제를 direct set prediction으로 보았고, 이를 Transformer와 bipartite matching을 통한 end-to-end 방식으로 풀어냈다. (많은 연구자들이 모든 딥러닝 모델의 최종 지향점은 end-to-end라고 한다.)</p>

<p>transformer 특성상, DETR 또한 architecture를 flexible 하게 확장시킬 수 있다.(Panoptic segmentation처럼)</p>

<hr />

<h1 id="code">Code</h1>

<p><img src="https://user-images.githubusercontent.com/48315997/99277842-ab94c000-2871-11eb-803f-d34e1bc3406b.png" alt="image" /></p>

<p><br /></p>

<h1 id="additional-studies">Additional studies</h1>
<p>(If you have some parts that cannot understand, you have to do additional studies for them. It’s optional.)</p>

<p>Deformable DETR</p>

<p><br /></p>

<h1 id="references">References</h1>
<p>(References for your additional studies)</p>

<ul>
  <li><a href="https://keyog.tistory.com/32">인간지능이 인공지능을 공부하는 장소</a></li>
  <li><a href="https://kp1994.tistory.com/15">KP’s blog</a></li>
  <li><a href="https://www.youtube.com/watch?v=lXpBcW_I54U&amp;feature=youtu.be&amp;fbclid=IwAR25dYNnKxCsN5apneKrmPus-umovk7fziMedDQMqBfhg28eaBj6u-tRxzI&amp;ab_channel=JinWonLee">TF 논문 읽기 모임 PR-284</a></li>
</ul>


      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            
            <a href="/tag/#/Deep%20Learning" rel="tag"># Deep Learning</a>
          
            
            <a href="/tag/#/Computer%20Vision" rel="tag"># Computer Vision</a>
          
            
            <a href="/tag/#/Object%20Detection" rel="tag"># Object Detection</a>
          
            
            <a href="/tag/#/Encoder-Decoder" rel="tag"># Encoder-Decoder</a>
          
            
            <a href="/tag/#/Transformer" rel="tag"># Transformer</a>
          
            
            <a href="/tag/#/Panoptic%20Segmentation" rel="tag"># Panoptic Segmentation</a>
          
            
            <a href="/tag/#/DETR" rel="tag"># DETR</a>
          
            
            <a href="/tag/#/ViT" rel="tag"># ViT</a>
          
        </div>
      

      
      
      
      
      

      
      
        <div class="post-nav" id="post-nav-id">
          <div class="post-nav-next post-nav-item">
            
              <a href="/data%20analysis/2020/11/19/ddareung/" rel="next" title="따릉이 데이터 가져오기 (서울 열린데이터 광장)">
                <i class="fa fa-chevron-left"></i> 따릉이 데이터 가져오기 (서울 열린데이터 광장)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/deep%20learning/computer%20vision/2020/11/03/mmdetection-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/" rel="prev" title="MMDetection 사용하기">
                MMDetection 사용하기 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      
      

      
    </footer>
  </article>

  <div class="post-spread">
    
  </div>
</div>


<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
    </script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          

  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        
        
        







      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/assets/images/avatar.gif"
               alt="Yeonsoo Kim" />
          <p class="site-author-name" itemprop="name">Yeonsoo Kim</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">22</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/">
                <span class="site-state-item-count">41</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
        
        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              
              
              <span class="links-of-author-item">
                <a href="https://github.com/yskim0" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github-square"></i>
                  
                  GitHub
                </a>
              </span>
            
              
              
              <span class="links-of-author-item">
                <a href="" target="_blank" title="wx12348@gmail.com">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  wx12348@gmail.com
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            








            
              <div class="post-toc-content">
    <ol class=nav>
      <li class="nav-item nav-level-1"> <a class="nav-link" href="#abstract"> <span class="nav-number">1</span> <span class="nav-text">Abstract</span> </a> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#introduction"> <span class="nav-number">2</span> <span class="nav-text">Introduction</span> </a> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#related-work"> <span class="nav-number">3</span> <span class="nav-text">Related Work</span> </a> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#the-detr-model"> <span class="nav-number">4</span> <span class="nav-text">The DETR model</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-2"> <a class="nav-link" href="#object-detection-set-prediction-loss"> <span class="nav-number">4.1</span> <span class="nav-text">Object detection set prediction loss</span> </a> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#detr-architecture"> <span class="nav-number">4.2</span> <span class="nav-text">DETR Architecture</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-3"> <a class="nav-link" href="#backbone"> <span class="nav-number">4.2.1</span> <span class="nav-text">Backbone</span> </a> </li> <li class="nav-item nav-level-3"> <a class="nav-link" href="#transformer-encoder"> <span class="nav-number">4.2.2</span> <span class="nav-text">Transformer encoder</span> </a> </li> <li class="nav-item nav-level-3"> <a class="nav-link" href="#transformer-decoder"> <span class="nav-number">4.2.3</span> <span class="nav-text">Transformer decoder</span> </a> </li> <li class="nav-item nav-level-3"> <a class="nav-link" href="#prediction-feed-forward-networks-ffns"> <span class="nav-number">4.2.4</span> <span class="nav-text">Prediction feed-forward networks (FFNs)</span> </a> </li> </ol> </li> </ol> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#experiments"> <span class="nav-number">5</span> <span class="nav-text">Experiments</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-2"> <a class="nav-link" href="#comparison-with-faster-r-cnn"> <span class="nav-number">5.1</span> <span class="nav-text">Comparison with Faster R-CNN</span> </a> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#number-of-encoder-layers"> <span class="nav-number">5.2</span> <span class="nav-text">Number of encoder layers</span> </a> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#number-of-decoder-layers"> <span class="nav-number">5.3</span> <span class="nav-text">Number of decoder layers</span> </a> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#panoptic-segmentation"> <span class="nav-number">5.4</span> <span class="nav-text">Panoptic Segmentation</span> </a> </li> </ol> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#conclusion"> <span class="nav-number">6</span> <span class="nav-text">Conclusion</span> </a> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#code"> <span class="nav-number">7</span> <span class="nav-text">Code</span> </a> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#additional-studies"> <span class="nav-number">8</span> <span class="nav-text">Additional studies</span> </a> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#references"> <span class="nav-number">9</span> <span class="nav-text">References</span> </a> </li>
    </ol>
  </div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>

        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yeonsoo Kim</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://jekyllrb.com">Jekyll</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/simpleyyt/jekyll-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>





















  
   
  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery/index.js?v=2.1.3"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/assets/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/assets/js/src/motion.js?v=5.1.1"></script>



  
  

  <script type="text/javascript" src="/assets/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/assets/js/src/post-details.js?v=5.1.1"></script>


  


  <script type="text/javascript" src="/assets/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  











  




  

    

  







  






  

  

  
  


  

  

  

</body>
</html>

