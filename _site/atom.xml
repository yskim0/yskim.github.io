<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-03-23T02:15:30+09:00</updated><id>http://localhost:4000/atom.xml</id><title type="html">Yeonsoo Kimâ€™s blog</title><author><name>Yeonsoo Kim</name></author><entry><title type="html">Stanford CS231n Lec 02. Image Classification</title><link href="http://localhost:4000/cs231n/2021/03/21/cs231n_lec02/" rel="alternate" type="text/html" title="Stanford CS231n Lec 02. Image Classification" /><published>2021-03-21T00:00:00+09:00</published><updated>2021-03-21T00:00:00+09:00</updated><id>http://localhost:4000/cs231n/2021/03/21/cs231n_lec02</id><content type="html" xml:base="http://localhost:4000/cs231n/2021/03/21/cs231n_lec02/">&lt;p&gt;Stanford CS231n 2017 ê°•ì˜ë¥¼ ë“£ê³  ê°œì¸ì ìœ¼ë¡œ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;lecture-2--image-classification-pipeline&quot;&gt;Lecture 2 : Image Classification pipeline&lt;/h1&gt;
&lt;h2 id=&quot;image-classification&quot;&gt;Image Classification&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Computer Vision Task&lt;/li&gt;
  &lt;li&gt;Problem is â€¦
    &lt;ul&gt;
      &lt;li&gt;Semantic Gap : between image and pixels (what the computer sees)
        &lt;ul&gt;
          &lt;li&gt;Computer understands the image as a big grid of numbers (800,600,3)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Challenges (algorithm should be robust to these challenges)
    &lt;ul&gt;
      &lt;li&gt;Viewpoint variation
        &lt;ul&gt;
          &lt;li&gt;all pixels change when the viewpoint is changed&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Illumination
        &lt;ul&gt;
          &lt;li&gt;different light condition&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Deformation
        &lt;ul&gt;
          &lt;li&gt;Example : catâ€¦&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Occlusion
        &lt;ul&gt;
          &lt;li&gt;The image shows just â€œpartâ€ of a cat&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Background Cluttuer&lt;/li&gt;
      &lt;li&gt;I track as Variation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;image-classifier&quot;&gt;Image Classifier&lt;/h2&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;classify_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;# some magic!
&lt;/span&gt;	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_label&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;Attempts have been made
    &lt;ul&gt;
      &lt;li&gt;find edges and corners&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data-Driven Approach&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Collect a dataset of images and labels&lt;/li&gt;
      &lt;li&gt;Use ML to train a classifier&lt;/li&gt;
      &lt;li&gt;Evaluate the classifier on new images
        &lt;h2 id=&quot;first-classifier--nearest-neighbor&quot;&gt;First Classifier : &lt;strong&gt;Nearest Neighbor&lt;/strong&gt;&lt;/h2&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;train : &lt;strong&gt;memorize all training data&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;O(1)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Predict : predict &lt;strong&gt;the label of most similar training image&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;O(N)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;But we want classifier that are fast at prediction; slow for training is OK.&lt;/strong&gt;**&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;K-Nearest Nighbors&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Take &lt;strong&gt;majority vote&lt;/strong&gt; from K closest points
  &lt;img src=&quot;https://user-images.githubusercontent.com/48315997/112023051-36fec480-8b76-11eb-819a-447974d99b0c.png&quot; alt=&quot;image&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Distance Metric (to compare images)
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/112022917-12a2e800-8b76-11eb-93f5-c1a1dd4cc39d.png&quot; alt=&quot;image&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;L1 distance(Manhattan distance)
        &lt;ul&gt;
          &lt;li&gt;Calculate the difference of image&lt;/li&gt;
          &lt;li&gt;Depends on &lt;strong&gt;choice of coordinate system&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;Use when individual vector is meaningful&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;L2 distance(Euclidean distance)
        &lt;ul&gt;
          &lt;li&gt;Use when &lt;strong&gt;generic vector&lt;/strong&gt; in some space&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;kNN on images never used&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Very slow at test time&lt;/li&gt;
      &lt;li&gt;Distance metrics on pixels are not informative
        &lt;ul&gt;
          &lt;li&gt;couldnâ€™t reflected â€œperceptional distanceâ€&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Curse of dimensionality
  &lt;img src=&quot;https://user-images.githubusercontent.com/48315997/112023009-2f3f2000-8b76-11eb-85b2-5ad0eba72979.png&quot; alt=&quot;image&quot; /&gt;
        &lt;ul&gt;
          &lt;li&gt;If dimensions are increased in image, data points must densely cover to these dimensions&lt;/li&gt;
          &lt;li&gt;Training examples are exponentially needed.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hyperparameters--pipeline&quot;&gt;Hyperparameters &amp;amp; Pipeline&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Problem-dependent
    &lt;ul&gt;
      &lt;li&gt;try them all out and see what works best â€¦&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Split data into &lt;strong&gt;train, val, and test&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;underlying : the same probability distribution&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cross-Validation
    &lt;ul&gt;
      &lt;li&gt;Split data into &lt;strong&gt;folds&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;We can know which hyperparameters are going to perform more &lt;strong&gt;robustly&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Useful to small datasets -&amp;gt; not used too frequently in deep learning&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;linear-classification&quot;&gt;Linear Classification&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Parametric Approach : summarize knowledge of training examples &amp;amp; stick all that knowledge into W.&lt;/li&gt;
  &lt;li&gt;Image -&amp;gt; f(x,W) -&amp;gt; N numbers giving class scores
    &lt;ul&gt;
      &lt;li&gt;W : parameters or weights&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;f(x,W) = Wx + b (# of classes = 10, input dimension = 3072)
    &lt;ul&gt;
      &lt;li&gt;f(x,W) : 10x1&lt;/li&gt;
      &lt;li&gt;W should be 10 x 3072&lt;/li&gt;
      &lt;li&gt;x : 3072x1&lt;/li&gt;
      &lt;li&gt;b : 10x1&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Wx&lt;/code&gt; gives classesâ€™ scores&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bias
    &lt;ul&gt;
      &lt;li&gt;constant vector&lt;/li&gt;
      &lt;li&gt;Not interact with training set&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;data independent&lt;/strong&gt;, preferences for some classes&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Overview
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/112023440-98bf2e80-8b76-11eb-837b-fb2bc8758a44.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Interpretation of linear classifiers as &lt;strong&gt;template matching&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;1 class : 1 template (driven from training data)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hard cases for a linear classifier&lt;/li&gt;
  &lt;li&gt;Question
    &lt;ul&gt;
      &lt;li&gt;how can we tell &lt;strong&gt;whether this W is good or bad?&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Yeonsoo Kim</name></author><category term="cs231n" /><category term="Deep Learning" /><category term="lecture note" /><category term="Computer Vision" /><summary type="html">Stanford CS231n 2017 ê°•ì˜ë¥¼ ë“£ê³  ê°œì¸ì ìœ¼ë¡œ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.</summary></entry><entry><title type="html">ì§€ë‚œ í•œ ë‹¬ì„ ëŒì•„ë³´ë©°, 2021ë…„ 2ì›” íšŒê³ </title><link href="http://localhost:4000/logs/2021/03/14/2021_February/" rel="alternate" type="text/html" title="ì§€ë‚œ í•œ ë‹¬ì„ ëŒì•„ë³´ë©°, 2021ë…„ 2ì›” íšŒê³ " /><published>2021-03-14T00:00:00+09:00</published><updated>2021-03-14T00:00:00+09:00</updated><id>http://localhost:4000/logs/2021/03/14/2021_February</id><content type="html" xml:base="http://localhost:4000/logs/2021/03/14/2021_February/">&lt;p&gt;2021ë…„ 2ì›” íšŒê³  ê¸€ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ëª©ì°¨&quot;&gt;ëª©ì°¨&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;ETRI ì¸í„´ ì¢…ë£Œ&lt;/li&gt;
  &lt;li&gt;ì´í™”ë³´ì´ìŠ¤ ì¸í„°ë·°&lt;/li&gt;
  &lt;li&gt;AI/ë°ì´í„°ë¶„ì„ ë™ì•„ë¦¬ ê°œì„¤&lt;/li&gt;
  &lt;li&gt;3ì›”ì˜ ê°ì˜¤&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;etri-ì¸í„´-ì¢…ë£Œ&quot;&gt;ETRI ì¸í„´ ì¢…ë£Œ&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/111064641-7edb7700-84f8-11eb-9dfb-1e5add8fa87d.jpeg&quot; alt=&quot;DD64C628-9482-43AE-B258-D6D83EF86E7A_1_105_c&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ë²Œì¨ ë‘ ë‹¬ì´ ì§€ë‚˜ ì—°êµ¬ì—°ìˆ˜ìƒ ê¸°ê°„ì´ ëë‚¬ë‹¤. ì‹œê°„ì€ ë‚´ ìƒê°ë³´ë‹¤ë„ ë” ìœì‚´ê°™ì´ í˜ëŸ¬ê°„ë‹¤ëŠ” ê±¸ ëª¸ì†Œ ëŠë‚„ ìˆ˜ ìˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ê²°ë¡ ì ìœ¼ë¡œ ë§í•˜ë©´ ETRI ì¸í„´ì„ í•˜ê¸¸ ì°¸ ì˜í–ˆë‹¤.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ì¢‹ì€ ë™ê¸°ë“¤, ë©‹ìˆëŠ” ë°•ì‚¬ë‹˜ë“¤ê³¼ ì„ ë°°ë‹˜ë“¤, ì´  ëª¨ë‘ì™€ í•¨ê»˜ í•  ìˆ˜ ìˆì–´ ì˜ê´‘ì´ì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë˜ ê·¸ë™ì•ˆ ì˜ ëª°ëê¸°ì— ê´€ì‹¬ ì—†ë˜ ë¶„ì•¼ì— ëŒ€í•´ ìƒˆë¡­ê²Œ ì•Œê²Œ ë˜ëŠ” ì¾Œê°ì„ ëŠë‚„ ìˆ˜ ìˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;íŠ¹í—ˆëŠ” ì‘ì„±í–ˆê³  ë…¼ë¬¸ì€ ì‘ì„±í• ì§€ ì•ˆí• ì§€ ë¯¸ì§€ìˆ˜ì¸ ìƒíƒœë¡œ ë– ë‚¬ë‹¤. ë…¼ë¬¸ì„ ë‹¹ì—°íˆ ì¨ì•¼ëœë‹¤ê³  ìƒê°í–ˆì§€ë§Œ ì´ê²ƒì €ê²ƒ ìš°ë ¤ë˜ëŠ” ë¶€ë¶„ë“¤ì´ ìˆì–´ì„œ ì§€ê¸ˆë„ ê³ ë¯¼ ì¤‘ì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ë™ê¸°ë“¤í•œí…Œ íŠ¹íˆë‚˜ ê³ ë§ˆì› ë‹¤. ë¯¸ìˆ™í•˜ê³  íˆ´íˆ´ê±°ë¦¬ëŠ” ë‚´ ì„±ê²©ì„ ì¬ë°Œê²Œ ì˜ ë°›ì•„ì£¼ê³  ë˜ ì„œë¡œ ì—´ì •ì ì´ë¼ ëˆ„êµ¬ í•˜ë‚˜ ë‚™ì˜¤ë˜ì§€ ì•Šê³  ì •ë§ ì—´ì‹¬íˆ ì¼í•  ìˆ˜ ìˆì—ˆë‹¤. ë‚´ê°€ ì•„ëŠ” ETRI ì¸í„´ë“¤, ë‹¤ë¥¸ ë© ì—°êµ¬ì—°ìˆ˜ìƒë“¤ ì¤‘ì— ìš°ë¦¬ê°€ ê°€ì¥ ë°”ì˜ê²Œ ì¼í•˜ì§€ ì•Šì•˜ì„ê¹Œ ì‹¶ë‹¤. ì•¼ê·¼ê³¼ ì£¼ë§ ì¶œê·¼ì„ ìì£¼ í–ˆìœ¼ë‹ˆâ€¦ (ìš°ë¦¬ë¼ë¦¬ ë‹¤ìŒ ê¸°ìˆ˜ ì¸í„´ë“¤ì´ ë¶ˆìŒí•˜ë‹¤ê³  ê³„ì† ë§í–ˆìŒã…‹ã…‹)&lt;/p&gt;

&lt;p&gt;íŠ¹í—ˆë‚˜ ë…¼ë¬¸ì„ ë‚´ê¸°ì— ë‘ ë‹¬ì´ë¼ëŠ” ì‹œê°„ì€ ë§¤ìš° ì§§ì€ ì‹œê°„ì´ë¼ê³  ì—¬ê²¨ì¡Œë‹¤. ê·¸ë˜ì„œ ì‚¬ì‹¤ â€˜ì•„, ëª»í•´ë„ ê·¸ë§Œì´ì§€! ë°°ìš´ ê²Œ ë§ìœ¼ë‹ˆê¹Œâ€™ ì´ëŸ° ë¥˜ì˜ ìƒê°ì„ í–ˆì—ˆëŠ”ë° &lt;strong&gt;ìƒê°ë³´ë‹¤ í•  ë§Œí•˜ë‹¤.&lt;/strong&gt; ë°•ì‚¬ë‹˜ë“¤ê»˜ì„œ ì •ë§ ë§ì´ ë„ì™€ì£¼ì‹œê³  ì¸í”„ë¼ë„ ë¹µë¹µí•˜ë‹ˆ ë³¸ì¸ì˜ ì˜ì§€ë§Œ ìˆë‹¤ë©´ ëª» í•  ê¸°ê°„ì´ ì ˆëŒ€ ì•„ë‹ˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ETRI ì¸í„´ì— ëŒ€í•œ í›„ê¸°ëŠ” ì•„ì˜ˆ ë‹¤ë¥¸ ê¸€ë¡œ íŒŒì„œ ì“°ë ¤ê³  í•œë‹¤. ì–´ì°Œëë“  ë‚˜ëŠ” ETRI ì¸í„´ì„ ì ê·¹ ì¶”ì²œí•˜ëŠ” ì…ì¥ì´ë‹¤. ì´ ì •ë„ì˜ í™˜ê²½ê³¼ ì‚¬ëŒì„ ì¶©ì¡±ì‹œí‚¤ëŠ” íšŒì‚¬ê°€ ë§ì§€ ì•Šì„ ê±°ë¼ ìƒê°ë˜ê¸° ë•Œë¬¸ì´ë‹¤. ì‚¬ëŒë„ ì¢‹ê³  ì¼ë„ ì¢‹ë‹¤ë©´ ë§ˆë‹¤í•  ì´ìœ ê°€ ìˆì„ê¹Œ?&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;ì´í™”ë³´ì´ìŠ¤-ì¸í„°ë·°&quot;&gt;ì´í™”ë³´ì´ìŠ¤ ì¸í„°ë·°&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/111064661-9e729f80-84f8-11eb-8f2a-c0f4458f93b5.png&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-03-14 á„‹á…©á„’á…® 7 08 09&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ìš°ì—°ì°®ì€ ê¸°íšŒë¡œ ì´í™”ë³´ì´ìŠ¤ì— ì¸í„°ë·°ë¥¼ í•˜ê²Œ ë˜ì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;í˜„ì¬ ë‚˜ëŠ” ì•„ëŠ” ë™ìƒì´ë‘ ì´í™”ì—¬ëŒ€ AI/ë°ì´í„°ë¶„ì„ ë¶„ì•¼ ì˜¤ì¹´ë°©ê³¼ ë””ìŠ¤ì½”ë“œë¥¼ ê°™ì´ ìš´ì˜í•˜ê³  ìˆëŠ”ë° ì—¬ê¸°ì— ê³„ì‹  ì´í™”ë³´ì´ìŠ¤ ê¸°ìë‹˜ê»˜ì„œ ì½”ë¡œë‚˜ì‹œëŒ€ ë„¤íŠ¸ì›Œí‚¹ì— ëŒ€í•œ ì£¼ì œë¡œ ì¸í„°ë·°ë¥¼ ìš”ì²­í•´ì£¼ì…¨ë‹¤.&lt;/p&gt;

&lt;p&gt;êµ‰ì¥íˆ ì˜ê´‘ì´ì—ˆê³  ì‚¬ì‹¤ ë‚˜ëŠ” ë”±íˆ í•œ ì¼ì´ ì—†ëŠ”ë° ì–´ë–¤ ë‹µë³€ì„ ë“œë ¤ì•¼ í• ê¹Œ ë§ì€ ê³ ë¯¼ì„ í–ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë˜ ì´í™”ë³´ì´ìŠ¤ëŠ” í•™êµ ê³µì‹ ì˜ì ì‹ ë¬¸ì¸ì§€ë¼ ê½¤ ë¶€ë‹´ì´ ëœ ê²ƒë„ ì‚¬ì‹¤ì´ì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;í•˜ì§€ë§Œ ê¸°ìë²—ê»˜ì„œ êµ‰ì¥íˆ ë¶„ìœ„ê¸°ë¥¼ ì˜ í’€ì–´ì£¼ì…¨ê³ , ìš°ë¦¬ê°€ ë‹µë³€í•  ìˆ˜ ìˆì„ ì •ë„ì˜ ì¢‹ì€ ì§ˆë¬¸ë“¤ì„ ì£¼ì…”ì„œ ì¬ë°ŒëŠ” ì¸í„°ë·°ê°€ ê°€ëŠ¥í–ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ìš°ë¦¬ í•™êµ ë„¤íŠ¸ì›Œí‚¹ì˜ ì¥ì„ ì¡°ê¸ˆì´ë¼ë„ ë„“íˆê³  ì‹¶ì—ˆë˜ ë‚˜ì˜ ì‘ì€ ë°”ëŒì´ ì ì°¨ ë§ì€ ì´í™”ì¸ì—ê²Œ ë‹¿ëŠ” ê²ƒ ê°™ì•„ ë¿Œë“¯í–ˆë‹¤. ë˜ ë” ì—´ì‹¬íˆ (ê³µë¶€)í•´ì•¼ ê² ë‹¤ëŠ” ë™ê¸°ë¶€ì—¬ë„ í™•ì‹¤íˆ ëë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ë„¤íŠ¸ì›Œí‚¹ì˜ ì¥ì´ ë³„ íƒˆì—†ì´, ë¶€ë”” ì˜¤ë˜ ê°ˆ ìˆ˜ ìˆìœ¼ë©´ ì¢‹ê² ë‹¤.&lt;/p&gt;

&lt;p&gt;ê¸°ì‚¬ì˜ ì „ë¬¸ì€ &lt;a href=&quot;https://evoice.ewha.ac.kr/news/articleView.html?idxno=10596&quot;&gt;ì—¬ê¸°&lt;/a&gt;ì„œ ë³¼ ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;aië°ì´í„°ë¶„ì„-ë™ì•„ë¦¬-ê°œì„¤&quot;&gt;AI/ë°ì´í„°ë¶„ì„ ë™ì•„ë¦¬ ê°œì„¤&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/111064679-b813e700-84f8-11eb-929f-9024599f1417.png&quot; width=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì‘ë…„ë¶€í„° ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ë¶„ì•¼ í•™íšŒë¥¼ í•˜ë‚˜ ë§Œë“¤ê¹Œ ê³ ë¯¼í•˜ê¸´ í–ˆìœ¼ë‚˜, ì¡¸í”„ ë“± ì‚¬ì • ìƒ ë¶€ë‹´ì´ ë§ì´ ë˜ëŠ” ì¼ì€ ì‚¬ì‹¤ì¸ì§€ë¼ ê°€ëŠ¥í•˜ë©´ í”¼í•˜ë ¤ê³  í–ˆë‹¤. í•˜ì§€ë§Œ ê²°êµ­ ë§Œë“¤ê²Œ ë˜ì—ˆë‹¤â€¦ ã…‹ã…‹ã…‹ã…‹ ì‹¬ì§€ì–´ ì¡¸í”„ ë©”ì´íŠ¸ê¹Œì§€ ê¼¬ì…”ì„œ ê°™ì´~&lt;/p&gt;

&lt;p&gt;ìš°ë¦¬ í•™êµ ì‚¬ëŒë“¤ì´ ì´ ë¶„ì•¼ì— ë” ë§ì´ ì§„ì¶œí•˜ê³ , ë” ë§ì´ ê¿ˆì„ ê¿¨ìœ¼ë©´ ì¢‹ê² ë‹¤ëŠ” ìƒê°ì€ í•­ìƒ ê°–ê³  ìˆì—ˆê¸° ë•Œë¬¸ì— ì´ ë™ì•„ë¦¬ë¥¼ ë°˜ë“œì‹œ ì˜ í‚¤ìš°ê³  ì‹¶ë‹¤. ì‚¬ì‹¤ ì–´ë ¤ìš¸ ê²ƒì´ ì—†ëŠ” ê²Œ ë‚˜í•œí…ŒëŠ” ë“ ë“ í•œ ì„ì›ì§„ë“¤ë„ ìˆê³ , ë˜ ì—´ì • ìˆëŠ” ë¶€ì›ë“¤ê¹Œì§€ ìˆë‹¤. ë‚´ê°€ ë°©í–¥ì„±ë§Œ ìƒì§€ ì•Šìœ¼ë©´ ì¶©ë¶„íˆ ëœë‹¤.&lt;/p&gt;

&lt;p&gt;ë‚´ê°€ ì–´ì—¿í•œ ì‚¬íšŒì¸ì´ ë˜ì–´ í›„ë°°ë‹˜ë“¤ì„ ë„ì™€ì¤„ ìˆ˜ ìˆëŠ” ìœ„ì¹˜ì— ê°ˆ ë•Œê¹Œì§€ ì´ ë™ì•„ë¦¬ê°€ ì­‰ ì´ì–´ì ¸ë‚˜ê°”ìœ¼ë©´ ì¢‹ê² ë‹¤.&lt;/p&gt;

&lt;p&gt;êµ‰ì¥íˆ ë¹¡ì„¼ ì»¤ë¦¬í˜ëŸ¼ìœ¼ë¡œ ì§„í–‰í•˜ëŠ”ë°, íƒˆì£¼ì ì—†ì´ ëª¨ë‘ê°€ ì„±ì¥í•  ìˆ˜ ìˆëŠ” í•œ í•´ê°€ ë˜ê¸¸!&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;3ì›”ì˜-ê°ì˜¤&quot;&gt;3ì›”ì˜ ê°ì˜¤&lt;/h3&gt;

&lt;p&gt;ì‚¬ì‹¤ ì´ ê¸€ì„ ì“°ëŠ” ì‹œì ì´ 3/14ì¼ì´ê¸´ í•œë°â€¦ 3ì›”ì˜ í•  ì¼ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ì¡¸ì—… í”„ë¡œì íŠ¸ ì£¼ì œ í™•ì •&lt;/li&gt;
  &lt;li&gt;ê°•ì˜ ì—´ì‹¬íˆ ë“£ê¸°, ê³¼ì œ ì˜ í•˜ê¸°&lt;/li&gt;
  &lt;li&gt;ë™ì•„ë¦¬ ê³µë¶€ ì˜ í•˜ê¸°&lt;/li&gt;
  &lt;li&gt;ì´êµìˆ˜ë‹˜ ê°•ì˜, ë…¼ë¬¸ ë”°ë¼ ê°€ê¸°&lt;/li&gt;
  &lt;li&gt;ë…¼ë¬¸ ìŠ¤í„°ë””&lt;/li&gt;
  &lt;li&gt;ê±´ê°• ì±™ê¸°ê¸°&lt;/li&gt;
  &lt;li&gt;(ETRI ë…¼ë¬¸ ì‘ì„±?) -&amp;gt; ì™„ì „ ë¯¸ì •.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Yeonsoo Kim</name></author><category term="ì›”ê°„ íšŒê³ " /><summary type="html">2021ë…„ 2ì›” íšŒê³  ê¸€ì…ë‹ˆë‹¤.</summary></entry><entry><title type="html">ì§€ë‚œ í•œ ë‹¬ì„ ëŒì•„ë³´ë©°, 2021ë…„ 1ì›” íšŒê³ </title><link href="http://localhost:4000/logs/2021/02/14/2021_January/" rel="alternate" type="text/html" title="ì§€ë‚œ í•œ ë‹¬ì„ ëŒì•„ë³´ë©°, 2021ë…„ 1ì›” íšŒê³ " /><published>2021-02-14T00:00:00+09:00</published><updated>2021-02-14T00:00:00+09:00</updated><id>http://localhost:4000/logs/2021/02/14/2021_January</id><content type="html" xml:base="http://localhost:4000/logs/2021/02/14/2021_January/">&lt;p&gt;2021ë…„ 1ì›” íšŒê³  ê¸€ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ëª©ì°¨&quot;&gt;ëª©ì°¨&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;ETRI 1ê°œì›” ì°¨&lt;/li&gt;
  &lt;li&gt;ë°ì´í„° ë¶„ì„ ìŠ¤í„°ë”” ì¢…ë£Œ&lt;/li&gt;
  &lt;li&gt;ê¸°íƒ€&lt;/li&gt;
  &lt;li&gt;í•œ ë‹¬ ë™ì•ˆ í•œ ê³µë¶€&lt;/li&gt;
  &lt;li&gt;ë‚¨ì€ ë°©í•™ ë™ì•ˆ í•  ì¼&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;1ï¸âƒ£-etri-1ê°œì›”-ì°¨&quot;&gt;1ï¸âƒ£ ETRI 1ê°œì›” ì°¨&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/107854608-48123280-6e60-11eb-9221-aeba67c94e38.jpeg&quot; alt=&quot;E11D4A80-51E2-4D70-8452-DDB5C3B6B70D_1_105_c&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì–´ëŠìƒˆ ETRI ì¸í„´ í•œ ë‹¬ì´ ì§€ë‚¬ë‹¤. (ì§€ê¸ˆì€ ì•½ 2ì£¼ì •ë„ë°–ì— ì•ˆë‚¨ì•˜ì§€ë§Œâ€¦)
í•œ ë‹¬ê°„ í•œ ì¼ì„ ì •ë¦¬í•´ë³´ìë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Active Learning ê°œë… ê³µë¶€ ë° ë…¼ë¬¸ ë¦¬ë”©&lt;/li&gt;
  &lt;li&gt;Active Learning - Uncertainty Sampling Implementation&lt;/li&gt;
  &lt;li&gt;ì‹¤í—˜ì— í•„ìš”í•œ ë°ì´í„°ë“¤ ë¼ë²¨ë§&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ì´ì „ê¹Œì§€ ë‚˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ ìì²´ì— ê´€ì‹¬ì´ ìˆì—ˆë˜ì§€ë¼ Active Learningì´ë‘ Human in the Loop ê°œë…ì„ ì´ë²ˆì— ìƒˆë¡œ ì•Œì•˜ë‹¤.
Active Learningì€ ìš”ì•½í•˜ìë©´ ì ì€ ë°ì´í„° ìˆ˜ë¡œ ë†’ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆëŠ” ê²ƒì´ ëª©ì ì¸ë°, ì´ ë•Œ &lt;strong&gt;ê·¸ ì ì€ ë°ì´í„°ë“¤ì„ ë¬´ìŠ¨ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìƒ˜í”Œë§í•˜ëŠ”ê°€&lt;/strong&gt;ì— ê´€í•œ ì´ì•¼ê¸°ì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ì±…ì„ë‹˜ê»˜ì„œ ë ˆí¼ëŸ°ìŠ¤í•  ë§Œí•œ ë…¼ë¬¸, ì•„í‹°í´ì„ ì£¼ì…”ì„œ ì‹¤í—˜ì˜ ê°ˆí”¼ë¥¼ ë¹ ë¥´ê²Œ ì¡ì„ ìˆ˜ ìˆì—ˆë‹¤.
ë˜ ë°ì´í„°ë¥¼ ë°›ê¸°ê¹Œì§€ ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë ¤ì„œ ê·¸ ë™ì•ˆ Uncertainty Samplingì„ êµ¬í˜„í•˜ê³  ì˜¤í”ˆ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹¤í—˜í•´ë³´ì•˜ë‹¤.&lt;/p&gt;

&lt;p&gt;1ì›”ì´ ê°€ì¥ í˜ë“¤ì—ˆë˜ ì´ìœ ëŠ” ë¼ë²¨ë§^_^â€¦ ì¸ë°â€¦
ë‚˜ëŠ” ì´ìª½ì˜ ëª¨ë“  ì¼ì„ ì°¸ì—¬í•˜ê¸° ì „ì— ë¼ë²¨ë§ ì¼ì„ í•˜ëŠ”ì§€ ì•ˆí•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ë¼ë²¨ë§ ì—…ë¬´ê°€ ë‚€ë‹¤ë©´ ê·¸ëƒ¥ ì•ˆí•œë‹¤^^â€¦
ê·¸ë˜ì„œ ETRI ì§€ì›í•  ë•Œë„ ë¼ë²¨ë§í•´ì•¼í•  ê²ƒ ê°™ì€ ë¶€ì„œëŠ” ë‹¤ ì œì™¸í•˜ê³  ìƒê°í–ˆëŠ”ë° ã… _ã…  ë‚´ê°€ ì§€ì›í•œ ê³³ì—ì„œ ê°‘ìê¸° ë¼ë²¨ë§ì„ ì‹œí‚¤ì‹¤ ì¤„ì€ ëª°ëë‹¤..!(ì–˜ê¸° ì—†ì—ˆì–ì•„ìš”!!)&lt;/p&gt;

&lt;p&gt;ì•„ë¬´íŠ¼ 2ì£¼ê°„ ë¼ë²¨ë§ì„ í•˜ê³ ,, ë˜ 112 ë°ì´í„°ë¼ ê·¸ëŸ°ì§€ ì •ì‹  í”¼íí•´ì§ˆ ë§Œí•œ ë‚´ìš©ì´ ë§ì•˜ë‹¤ã…‹ã…‹ã…‹ ë‚´ê°€ ë‘”í•˜ê³  ë©˜íƒˆì´ ê´œì°®ì€ í¸ì´ë¼ ë‹¤í–‰ì´ì—ˆì§€, ê°ì •ì´ì… ì˜í•˜ëŠ” ì‚¬ëŒì´ ë´¤ìœ¼ë©´ í˜ë“¤ì—ˆì„ ê²ƒ ê°™ë‹¤.&lt;/p&gt;

&lt;p&gt;2ì›”ë¶€í„°ëŠ” ì‹¤í—˜ì„ ì‹œì‘í–ˆëŠ”ë°, ê·¸ê±´ 2ì›” íšŒê³ ì— ê¸°ë¡í•  ê²ƒ.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;2ï¸âƒ£ë°ì´í„°-ë¶„ì„-ìŠ¤í„°ë””-ì¢…ë£Œ&quot;&gt;2ï¸âƒ£ë°ì´í„° ë¶„ì„ ìŠ¤í„°ë”” ì¢…ë£Œ&lt;/h3&gt;

&lt;p&gt;10ì›”ì— ëª¨ì§‘í•˜ì—¬ ì§„í–‰í–ˆë˜ ë°ì´í„° ë¶„ì„ ìŠ¤í„°ë””ê°€ ë“œë””ì–´ ë§ˆë¬´ë¦¬ ëë‹¤!
í›„ë°˜ë¶€ì—ëŠ” ë‚´ê°€ ì •ì‹ ì´ ì—†ì–´ì„œ ê³µë¶€ë¥¼ ë§ì´ ëª» í–ˆì§€ë§Œã… ã…  ê·¸ë˜ë„ ì¢‹ì€ ë²—ë“¤ì„ ë§Œë‚˜ì„œ ë„ˆë¬´ ê¸°ë¶„ì´ ì¢‹ì•˜ë‹¤ :)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/107866777-7a02b380-6eb7-11eb-9dc2-135c04404f49.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;â€˜íŒŒì´ì¬ ë¨¸ì‹ ëŸ¬ë‹ ì™„ë²½ ê°€ì´ë“œâ€™ ë¼ëŠ” ì±…ì€ ë‚´ê°€ ì´ì „ì— í•œ ë²ˆ ì½ì€ ì±…ì´ê¸´ í•˜ì§€ë§Œ, ì´ë ‡ê²Œ ë²—ë“¤ì´ë‘ ë‹¤ì‹œ ì„¸ë¯¸ë‚˜ í˜•íƒœë¡œ ê³µë¶€í•˜ë‹ˆê¹Œ ë˜ ìƒˆë¡­ê²Œ ì™€ë‹¿ì•˜ë‹¤. ê³µë¶€ëŠ” ì—­ì‹œ í•  ë•Œë§ˆë‹¤ ìƒˆë¡œìš´ ê±´ê°€?
ì´ì „ì—ëŠ” ì•™ìƒë¸”, ë¶€ìŠ¤íŒ… ê¸°ë²•ì„ ê¹Šê²Œ ìƒê°í•˜ì§€ ì•Šê³  ê³µë¶€í–ˆëŠ”ë° ì‹¤ì œ ìºê¸€ì´ë‚˜ ë°ì´ì½˜ê³¼ ê°™ì€ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ì»´í”¼í‹°ì…˜ì—ì„œëŠ” ë§¤ìš° ì˜ ì“°ì´ëŠ” ê¸°ë²•ë“¤ì´ë‹¤. ì•„ë¬´íŠ¼ ì´ëŸ¬í•œ ë‚´ìš©ë“¤ì„ ì„¸ë¯¸ë‚˜ë¥¼ ì¤€ë¹„í•˜ë©´ì„œ ê³µë¶€í•  ìˆ˜ ìˆì–´ì„œ ì¢‹ì•˜ë‹¤.&lt;/p&gt;

&lt;p&gt;ìš°ë¦¬ í•™êµ ë²—ë“¤ì´ ë°ì´í„° ë¶„ì„ê³¼ ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì— ë§ì´ ë§ì´ ì§„ì…í–ˆìœ¼ë©´ ì¢‹ê² ë‹¤ :)&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;3ï¸âƒ£-ê¸°íƒ€&quot;&gt;3ï¸âƒ£ ê¸°íƒ€&lt;/h3&gt;

&lt;p&gt;ì²« ìì·¨ ìƒí™œë¡œ ì¸í•´ ëª¸ê³¼ ë§ˆìŒì´ ì¡°ê¸ˆ í˜ë“¤ì—ˆì—ˆë‹¤ ã… ã… &lt;/p&gt;

&lt;p&gt;ê·¸ë˜ì„œ 1ì›”ì—ë§Œ í˜¸ìº‰ìŠ¤ë¥¼ ë‘ ë²ˆ í–ˆë‹¤!&lt;/p&gt;

&lt;p&gt;ì²« ë²ˆì§¸ í˜¸ìº‰ìŠ¤ëŠ” ì›Œì»¤íì´ë‹¤. ì•„ë¹ ê°€ ì›Œì»¤í ìª½ì—ì„œ ë°”ìš°ì²˜ë‘ ì¹´ë“œë“¤ì„ ë°›ì•„ì„œ ì›Œì»¤í ìŠ¤ìœ„íŠ¸ë£¸ì—ì„œ ë¬µì„ ìˆ˜ ìˆì—ˆë‹¤! ì—„ë§ˆì•„ë¹  // ë‚˜ ì´ë ‡ê²Œ í•´ì„œ ê°ê° ë°© 1ê°œì”©ì„ ì¼ë‹¤. ë‚˜ í˜¼ì ìŠ¤ìœ„íŠ¸ë£¸ ì“´ ì ì€ ì²˜ìŒì´ë‹¤ ã…ã…ã…&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/107870217-cd85f900-6ed9-11eb-9bc6-1374187ccc5b.jpeg&quot; alt=&quot;90B06C1A-7396-41AC-8EF6-A23F6D707C44_1_105_c&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/107870215-c6f78180-6ed9-11eb-9975-a4bc47ed7582.jpeg&quot; alt=&quot;FE0403FB-98D0-4BD6-8DF9-B343FF2D1FCD_1_105_c&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/107870223-dd054200-6ed9-11eb-9666-b3682e317ec1.jpeg&quot; alt=&quot;E001E8C5-7F44-4A72-9A27-56E05590520B_1_105_c&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/107870251-e8586d80-6ed9-11eb-897a-82fcea7590cb.jpeg&quot; alt=&quot;30019A7C-B51E-467C-945C-2EC7F62D30C1_1_105_c&quot; /&gt;&lt;/p&gt;

&lt;p&gt;í•œê°•ì´ ë°”ë¡œ ë³´ì´ëŠ” ê²ƒë„ ë§ˆìŒì— ë“¤ì—ˆê³ , 4ì¸µì— ìŠ¤ì¹´ì´ì•¼ë“œë„ êµ‰ì¥íˆ ì¢‹ì•˜ë‹¤. ì˜¤í”ˆ ì‹œê°„ì— ë°”ë¡œ ê°„ ê±°ë¼ ì¡±ìš•ë„ í–ˆë‹¤!&lt;/p&gt;

&lt;p&gt;ë‘ ë²ˆì§¸ í˜¸ìº‰ìŠ¤ëŠ” ì—„ë§ˆê°€ ëŒ€ì „ì— ì™”ì„ ë•Œ íœ´ê°€ë‚´ê³  ê°„ â€˜ëŒ€ì „ ë¡¯ë°ì‹œí‹°í˜¸í…”â€™ì´ë‹¤. ì´ ë•Œ ì •ë§ ì„œìš¸ ê³µí™”êµ­ì´ë¼ëŠ” ê²ƒì„ ëŠê¼ˆëŠ”ë°, ëŒ€ì „ì€ ì œì¼ ì¢‹ì€ í˜¸í…”ì´ 4ì„±ê¸‰ì´ë‹¤ã…œã…œ ì•„ë¬´íŠ¼ ì´ ë•Œì¯¤ì— í˜ë“¤ì—ˆë˜ ì¼ë“¤ì´ ë§ì•˜ì–´ì„œ íœ´ê°€ë¥¼ ë‚´ê³  í˜¸ìº‰ìŠ¤ë¥¼ ê°”ë‹¤. ê²°ê³¼ì ìœ¼ë¡œëŠ” ë°¤ì— ì¼ì„ í•˜ê¸´ í–ˆì§€ë§Œ â€¦^^&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ëŠ” í•œê°•ë·°ëŠ” ì•„ë‹ˆê³  ê°‘ì²œ?ë·° ã…‹ã…‹ã…‹ã…‹ ë˜ê²Œ ê¹”ë”í–ˆê³ , ê°€ì„±ë¹„ ìˆëŠ” í˜¸í…”ì´ì—ˆë‹¤!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/107870334-982ddb00-6eda-11eb-9aa1-bd2c23f6b77b.jpeg&quot; alt=&quot;B635E2B2-B96E-479A-8CD4-6C709BBA2C70_1_105_c&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/107870332-96fcae00-6eda-11eb-9b28-514afb771b8b.jpeg&quot; alt=&quot;B9009AFF-7402-49E0-B58E-E85AABF755D1_1_105_c&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê·¸ë¦¬ê³  ë°”ë¡œ ë§ì€ í¸ì— ì„±ì‹¬ë‹¹ì´ ìˆì–´ì„œ ë°”ë¡œ ë‹¬ë ¤ê°”ë‹¤. ë‚˜ë‘ ìš°ë¦¬ ì—„ë§ˆëŠ” ë¹µì„ ë§¤ìš° ì¢‹ì•„í•˜ê¸° ë•Œë¬¸ì—â€¦ ì‚¬ê³  ì‹¶ì€ ë¹µë“¤ì´ ë¬´ì²™ì´ë‚˜ ë§ì•˜ì§€ë§Œ ë‚˜ë¦„ ì ˆì œí•˜ë©° ê³¨ëë‹¤ ã…‹ã…‹ ì´ˆì½” íŠ€ê¹€ ì†Œë³´ë¡œë¥¼ ë¨¹ì—ˆëŠ”ë° ìƒê°ë³´ë‹¤ íŒ¥ë§›ì´ ë§ì´ ë‚˜ì„œ ì•„ì‰¬ì› ë‹¤ã… ã…  ëª…ë¬¼ì´ë¼ëŠ” ëª…ë€ ë°”ê²ŒíŠ¸ëŠ” ì €ë…ì´ë‘ ì•„ì¹¨ ëª¨ë‘ sold outâ€¦&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/107870326-8cdaaf80-6eda-11eb-8e15-6d41c70f971d.jpeg&quot; alt=&quot;576C4EBC-F28D-4ECE-9432-A16B8C44D9A8_1_105_c&quot; /&gt;&lt;/p&gt;

&lt;p&gt;íœ´ê°€ ë‚ ì—ëŠ” ëŒ€ì „ í˜„ëŒ€í”„ë¦¬ë¯¸ì—„ì•„ìš¸ë ›ë„ ê°”ë‹¤! ìƒê¸´ì§€ ì–¼ë§ˆ ì•ˆëœ ê³³ì´ë¼ êµ‰ì¥íˆ ê¹”ë”í–ˆë‹¤. ë˜ í‰ì¼ ë‚®ì´ë¼ ê·¸ëŸ°ê°€ ì‚¬ëŒë“¤ì´ ë³„ë¡œ ì—†ì–´ì„œ ë§¤ìš° ì¢‹ì•˜ë‹¤!
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/107870367-24400280-6edb-11eb-9495-41ffbae82b11.jpeg&quot; alt=&quot;45D7BCF6-C915-4251-A660-7882422F783E_1_105_c&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì•„ë¬´íŠ¼ 1ì›” ì¤‘ìˆœë¶€í„°ëŠ” ê°€ì¡±ë“¤ì´ ë‚´ ê¸°ë¶„ì„ í’€ì–´ì£¼ë ¤ê³  ì •ë§ ë§ì´ ë„ì™€ì¤¬ë‹¤. ì—­ì‹œ ê°€ì¡±ì´ ìµœê³ ì•¼ &amp;lt;3
(ì¹œêµ¬ë“¤ë„ ìµœê³ ì•¼)&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;4ï¸âƒ£í•œ-ë‹¬-ë™ì•ˆ-í•œ-ê³µë¶€&quot;&gt;4ï¸âƒ£í•œ ë‹¬ ë™ì•ˆ í•œ ê³µë¶€&lt;/h3&gt;

&lt;p&gt;1ì›” ë™ì•ˆ í•œ ê³µë¶€ë¥¼ ì •ë¦¬í•´ë³´ìë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Active Learning (ì¸í„´ ì—…ë¬´)&lt;/li&gt;
  &lt;li&gt;ë…¼ë¬¸ ìŠ¤í„°ë””(Transformer, GAN, BERT, StarGAN, GPT-1)&lt;/li&gt;
  &lt;li&gt;â€¦&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ë”±íˆ ê³µë¶€ë¥¼ í•œ ê±´ ë³„ë¡œ ì—†êµ¬ë‚˜. ë°˜ì„±â€¦
ì§ì¥ì„ ë‹¤ë‹ˆë©´ì„œ ê³µë¶€í•˜ëŠ” ì‚¬ëŒë“¤ì´ ì •ë§ ëŒ€ë‹¨í•˜ê²Œ ë³´ì¸ë‹¤. ë‚˜ëŠ” ì¸í„´ì¼ ë¿ì¸ë°ë„ í‡´ê·¼í•˜ê³  ì˜¤ë©´ ë»—ê¸° ì¼ìˆ˜ì´ë‹¤ ã… ã…  ì²´ë ¥ì„ ê¸¸ëŸ¬ì•¼ í•  ê²ƒ ê°™ë‹¤&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;5ï¸âƒ£ë‚¨ì€-ë°©í•™-ë™ì•ˆ-í• -ì¼&quot;&gt;5ï¸âƒ£ë‚¨ì€ ë°©í•™ ë™ì•ˆ í•  ì¼&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;AI/ë°ì´í„°ë¶„ì„ ë™ì•„ë¦¬ ëª¨ì§‘ ë° ì„ ë°œ&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ì›ë˜ ë§Œë“¤ê¹Œ ë§ê¹Œ ê³ ë¯¼í–ˆëŠ”ë° ì–´ì°Œì €ì°Œ ë§Œë“¤ê²Œ ëë‹¤(í˜„ì¬ 2ì›” ìƒí™©)
ì´ë¯¸ í•˜ê²Œ ëœ ê±°, ì±…ì„ê° ìˆê³  ì´í™”ì˜ ì—­ì‚¬ì— í•œ ì¤„ì„ ê¸‹ëŠ” ë™ì•„ë¦¬ê°€ ë˜ë„ë¡ ì—´ì‹¬íˆ ë…¸ë ¥í•  ê²ƒì´ë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ë…¼ë¬¸ ìŠ¤í„°ë””&lt;/li&gt;
  &lt;li&gt;íŠ¹í—ˆ ì‘ì„±&lt;/li&gt;
  &lt;li&gt;ë…¼ë¬¸ ì‘ì„±&lt;/li&gt;
  &lt;li&gt;ì—¬ìœ ê°€ ëœë‹¤ë©´, Pix2Pix êµ¬í˜„&lt;/li&gt;
  &lt;li&gt;ê±´ê°•í•œ ìŒì‹ ë¨¹ê¸°(ì‹ë‹¨ ê´€ë¦¬) &amp;amp; ìì£¼ ê±·ê¸°&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;íŠ¹í—ˆ ì‘ì„±ê³¼ ë…¼ë¬¸ ì‘ì„±ì´ ê°€ì¥ ì£¼ê°€ ë  ë“¯ í•˜ë‹¤. ê³¼ì—° 2ì›”ì•ˆì— ë‹¤ í•  ìˆ˜ ìˆì„ê¹Œ? í•´ì•¼ë§Œ í•œë‹¤ã… &lt;/p&gt;</content><author><name>Yeonsoo Kim</name></author><category term="ì›”ê°„ íšŒê³ " /><summary type="html">2021ë…„ 1ì›” íšŒê³  ê¸€ì…ë‹ˆë‹¤.</summary></entry><entry><title type="html">Ubuntu 18.04 clean, ***/*** files, ***/*** blocks ë¬¸ì œí•´ê²°</title><link href="http://localhost:4000/troubleshooting/2021/01/26/Ubuntu-clean-files-blocks-trouble/" rel="alternate" type="text/html" title="Ubuntu 18.04 clean, ***/*** files, ***/*** blocks ë¬¸ì œí•´ê²°" /><published>2021-01-26T00:00:00+09:00</published><updated>2021-01-26T00:00:00+09:00</updated><id>http://localhost:4000/troubleshooting/2021/01/26/Ubuntu-clean-files-blocks-trouble</id><content type="html" xml:base="http://localhost:4000/troubleshooting/2021/01/26/Ubuntu-clean-files-blocks-trouble/">&lt;p&gt;Ubuntu 18.04ì—ì„œ clean, ***/*** files, ***/*** blocks ì—ëŸ¬ê°€ ë–´ì„ ë•Œ ê³ ì¹˜ëŠ” ë°©ë²•ì„ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ì¡ì†Œë¦¬&quot;&gt;ì¡ì†Œë¦¬&lt;/h2&gt;

&lt;p&gt;ì˜¤ëŠ˜ ì—°êµ¬ì‹¤ì—ì„œ ì •ë§ ë‹¹í™©í•œ ì—ëŸ¬ë¥¼ ë§ˆì£¼ì³¤ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì‚¬ê±´ì˜ ì—­ì‹œë‚˜ CUDAì—ì„œ ì‹œì‘â€¦ ì €ë²ˆì£¼ê¹Œì§€ë§Œ í•´ë„ ì˜ ëë˜ gpuì‚¬ìš©ì´ ì˜¤ëŠ˜ í•˜ë ¤ë‹ˆ ê°‘ìê¸° ì°¾ì„ ìˆ˜ ì—†ë‹¤(?)ëŠ” ì—ëŸ¬ê°€ ë–´ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì¹¨ì°©í•˜ê²Œ ê·¸ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ êµ¬ê¸€ë§í•´ì„œ ìŠ¤íƒì˜¤ë²„í”Œë¡œìš°ì—ì„œ í•˜ë¼ëŠ” ëŒ€ë¡œ í•˜ê³  ì¬ë¶€íŒ…í–ˆëŠ”ë° ì•„ë˜ì™€ ê°™ì€ ì—ëŸ¬ê°€ ëœ¨ê³  ë¬´í•œ ë¸”ë™ìŠ¤í¬ë¦°ì´ì—ˆìŠµë‹ˆë‹¤ ã…œã…œ.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.stack.imgur.com/fBYUJ.jpg&quot; alt=&quot;&quot; /&gt; &lt;a href=&quot;https://askubuntu.com/questions/1222496/system-wont-boot-stuck-at-dev-sda5-clean-xxxx-xxxx-files-yyyy-yyyy-blocks&quot;&gt;ì´ë¯¸ì§€ ì¶œì²˜&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ì§„ì‹¬ ì €ê±° ë´¤ì„ ë•Œ ëˆˆë¬¼ì´ ì°”ë” ë‚˜ì˜¬ ë»” í–ˆëŠ”ë°ìš” ..ã…‹ã…‹ã…‹ ìŠ¤íƒì˜¤ë²„í”Œë¡œìš°ë³´ë‹ˆê¹Œ ì•„ì˜ˆ ìš°ë¶„íˆ¬ë¥¼ ì¬ì„¤ì¹˜ í•´ì•¼ í•  ìˆ˜ë„ ìˆë‹¤ëŠ” ê¸€ì„ ë³´ê³ â€¦ ì§„ì§œ ì˜¨ëª¸ì´ ì˜¤ì‹¹í•´ì¡ŒìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;ìš°ì„  ë‹¤ì‹œ ë¶€íŒ…í•˜ê³  recovery mode (safe mode) ë¡œ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤. ë¶€íŒ…ë  ë•Œ ë¬´í•œ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Shift&lt;/code&gt; ëˆ„ë¥´ì‹­ì‹œì˜¤. (ìš°ë¶„íˆ¬ 18.04 ê¸°ì¤€)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Advanced options for Ubuntu&lt;/code&gt; ë¥¼ í´ë¦­í•˜ê³ , &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;recovery mode&lt;/code&gt;ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤.
ì œê°€ ìº¡ì³í•  ìƒí™©ì€ ì•„ë‹ˆì—ˆë˜ì§€ë¼ ë‹¤ ì¸í„°ë„·ì—ì„œ ë“¤ê³  ì˜¤ëŠ” ì  ì´í•´ ë¶€íƒë“œë¦½ë‹ˆë‹¤^^; &lt;a href=&quot;https://askubuntu.com/questions/92556/how-do-i-boot-into-a-root-shell&quot;&gt;ì¶œì²˜&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://i.stack.imgur.com/01e8n.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://i.stack.imgur.com/UP5j7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ì´ì œ ë¦¬ì»¤ë²„ë¦¬ ëª¨ë“œì— ë“¤ì–´ì™”ëŠ”ë°ìš”. ì—¬ê¸°ì„œ ë°©í–¥í‚¤ë¥¼ ì‚¬ìš©í•´ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;root&lt;/code&gt;ë¡œ ì´ë™í•˜ê³  Enterí•©ë‹ˆë‹¤. ì´ì œ í„°ë¯¸ë„ì„ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤! 
&lt;img src=&quot;https://i.stack.imgur.com/tHkmh.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ì´ì œ í„°ë¯¸ë„ì—ì„œ&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo apt-get purge nvidia*&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;ë¥¼ ì¹˜ë©´ ë©ë‹ˆë‹¤ë§Œ, ì—¬ê¸°ì„œ ì €ëŠ”&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dpkg was interrupted, you must manually run 'sudo dpkg --configure -a' to correct the problem
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ë¼ëŠ” ì—ëŸ¬ê°€ ë˜ ëœ¹ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ ì œ ë¶€íŒ… ì‹¤íŒ¨ì˜ ì›ì¸ì„ ìœ ì¶”í•´ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì¬ë¶€íŒ… ì „ì— í–ˆë˜ ë™ì‘ë“¤ì—ì„œ ë­”ê°€ë¥¼ ê±´ë“œë ¸ê³  ê·¸ ê²°ê³¼ dpkg íŒ¨í‚¤ì§€ê°€ ì œëŒ€ë¡œ êµ¬ì„±ë˜ì§€ ì•Šì•˜ë˜ ê²ë‹ˆë‹¤.(maybeâ€¦.)&lt;/p&gt;

&lt;p&gt;ì•„ë¬´íŠ¼ ì´ ì—ëŸ¬ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì‰½ê²Œ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì—ëŸ¬ ë©”ì‹œì§€ëŒ€ë¡œ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo dpkg --configure -a&lt;/code&gt; ë¥¼ í•´ì£¼ë©´ ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ì œ ë‹¤ì‹œ&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo apt-get purge nvidia*&lt;/code&gt;
ë¥¼ í•˜ê²Œ ë˜ë©´ ì˜ ì„¤ì¹˜ ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reboot&lt;/code&gt; ë¥¼ ì¨ì„œ ì¬ë¶€íŒ…í•©ë‹ˆë‹¤ -&amp;gt; ì„±ê³µ!&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;ì´ ì¼ì€ ì €ì—ê²Œ ìˆì–´ ì •ë§ ë”ì°í–ˆë˜ ìˆœê°„ì´ì—ˆìŠµë‹ˆë‹¤. í‡´ì‚¬í•´ì•¼í•˜ë‚˜ ìƒê°ë„ í–ˆì–´ìš” ã…‹ã…‹ã…‹ ì•„ë¬´íŠ¼ ë¹ ë¥´ê²Œ ê³ ì¹˜ê³  í‡´ê·¼í–ˆìŠµë‹ˆë‹¤^^.. í˜¹ì‹œ êµ¬ê¸€ë§í•˜ë‹¤ ì €ì™€ ê°™ì€ ì—ëŸ¬ë¥¼ ë°œê²¬í•˜ì‹œê²Œ ëœë‹¤ë©´, ìœ„ ê³¼ì •ì„ í†µí•´ ê³ ì¹˜ê¸¸ ë°”ë¼ê² ìŠµë‹ˆë‹¤.&lt;/p&gt;</content><author><name>Yeonsoo Kim</name></author><category term="Ubuntu" /><category term="Troubleshooting" /><summary type="html">Ubuntu 18.04ì—ì„œ clean, ***/*** files, ***/*** blocks ì—ëŸ¬ê°€ ë–´ì„ ë•Œ ê³ ì¹˜ëŠ” ë°©ë²•ì„ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.</summary></entry><entry><title type="html">Pre-training of Deep Bidirectional Transformers for Language Understanding(BERT)</title><link href="http://localhost:4000/paper%20review/2021/01/25/BERT/" rel="alternate" type="text/html" title="Pre-training of Deep Bidirectional Transformers for Language Understanding(BERT)" /><published>2021-01-25T00:00:00+09:00</published><updated>2021-01-25T00:00:00+09:00</updated><id>http://localhost:4000/paper%20review/2021/01/25/BERT</id><content type="html" xml:base="http://localhost:4000/paper%20review/2021/01/25/BERT/">&lt;p&gt;Pre-training of Deep Bidirectional Transformers for Language Understanding(BERT) ì„ ì½ê³  ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;bidirectional&lt;/strong&gt;ì´ë¼ëŠ” ì ì´ ì´ì „ ì—°êµ¬ë“¤ê³¼ì˜ ê°€ì¥ í° ì°¨ì´ì ì´ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create SOTA ~...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;fine-tuningì´ ë§¤ìš° ìš©ì´í•œ ëª¨ë¸ì´ë‹¤&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ì—¬ëŸ¬ ê°€ì§€ taskì—ì„œ SOTAë¥¼ ê¸°ë¡í–ˆìŒ.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Applying pre-trained language representations to downstream tasks&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature-based&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;ELMo&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fine-tuning&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;GPT&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;limitation-of-unidirectional-approach&quot;&gt;Limitation of Unidirectional approach&lt;/h3&gt;

&lt;p&gt;ë‘ ì ‘ê·¼ë²• ëª¨ë‘ &lt;strong&gt;unidirectional&lt;/strong&gt; ë°©ë²•ì„ ì‚¬ìš©í•¨.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;But, unidirectional ë°©ë²•ì€ í•œê³„ì ì´ ëšœë ·í•¨.&lt;/li&gt;
  &lt;li&gt;GPT(1)ì²˜ëŸ¼ left-to-right architectureë¥¼ ì‚¬ìš©í•˜ê²Œ ë˜ë©´, ëª¨ë“  tokenë“¤ì€ ì´ì „ì˜ tokenë“¤ì—ë§Œ self-attentioní•  ìˆ˜ ìˆê²Œ ëœë‹¤.
    &lt;ul&gt;
      &lt;li&gt;ì´ëŠ” token-level task (ì˜ˆë¥¼ ë“¤ì–´ QA)ë“¤ì— ë¶€ì í•©í•˜ë‹¤. ì´ëŸ¬í•œ íƒœìŠ¤í¬ë“¤ì€ ì–‘ ë°©í–¥ì„ ë´ì„œ &lt;strong&gt;context&lt;/strong&gt;ë¥¼ ì½ì–´ì•¼í•˜ê¸° ë•Œë¬¸.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;masked-langauge-modelmlm&quot;&gt;Masked Langauge Model(MLM)&lt;/h3&gt;

&lt;p&gt;BERTì—ì„œëŠ” pre-training í•  ë•Œ, ìœ„ì—ì„œ ì–¸ê¸‰í•œ unidirectionality constraintë¥¼ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Masked Language Model(MLM)&lt;/code&gt; ìœ¼ë¡œ ì™„í™”(?)í–ˆìŒ.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MLMì€ input í† í°ë“¤ë¡œë¶€í„° &lt;strong&gt;randomly mask&lt;/strong&gt;í•¨.
    &lt;ul&gt;
      &lt;li&gt;ì´ê²ƒì˜ ëª©ì ì€, &lt;strong&gt;ì˜¤ì§ contextë§Œ ê°€ì§€ê³ &lt;/strong&gt; maskëœ original vocab.ì„ ë§ì¶”ëŠ” ê²ƒ.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Left-to-right LM pre-trainingê³¼ ë‹¬ë¦¬, MLMì˜ ëª©ì  í•¨ìˆ˜ëŠ” ì–‘ ë°©í–¥ì˜ representationsë¥¼ ì´í•´í•  ìˆ˜ ìˆë‹¤.
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  which allows us to pre-train a deep bidirectional Transformer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;next-sentence-prediction&quot;&gt;Next Sentence Prediction&lt;/h3&gt;

&lt;p&gt;jointly pre-train text-pair representation&lt;/p&gt;

&lt;h2 id=&quot;bert&quot;&gt;BERT&lt;/h2&gt;

&lt;p&gt;&lt;img width=&quot;766&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-01-25 á„‹á…©á„’á…® 9 09 09&quot; src=&quot;https://user-images.githubusercontent.com/48315997/105704076-91eab580-5f51-11eb-8b52-16c48146bd50.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;pre-training&quot;&gt;Pre-training&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;During pre-training, the model is trained on unlabeled data over different pre-training tasks.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Pre-training ë‹¨ê³„ì—ì„œ ëª¨ë¸ì€ &lt;strong&gt;unlabeled data&lt;/strong&gt;ë¥¼ ê°€ì§€ê³  í•™ìŠµëœë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TWO Unsupervised taskë¥¼ ì‚¬ìš©í•¨.&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;task-1-masked-lm&quot;&gt;Task #1. Masked LM&lt;/h4&gt;

&lt;p&gt;deep bidirectional representationì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´, input tokenì—ì„œ ëœë¤ìœ¼ë¡œ ëª‡ %ì •ë„ë¥¼ maskingí•˜ê³  ì´ masked tokenë“¤ì„ predictí•˜ë„ë¡ í•™ìŠµì‹œí‚´.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;[MASK]&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Random&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Unchanged&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;80%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;task-2-next-sentence-prediction-nsp&quot;&gt;Task #2. Next Sentence Prediction (NSP)&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;ë‘ ë¬¸ì¥ ì‚¬ì´ì˜ ê´€ê³„(relationship)ë¥¼ ì´í•´&lt;/strong&gt;í•˜ê¸° ìœ„í•´ í•™ìŠµí•˜ëŠ” taskì´ë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IsNext&lt;/code&gt;ì¸ì§€ ì•„ë‹Œì§€(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NotNext&lt;/code&gt;) ë¶„ë¥˜í•˜ëŠ” binary classification ë¬¸ì œì„.&lt;/p&gt;

&lt;h3 id=&quot;fine-tuning-bert&quot;&gt;Fine-tuning BERT&lt;/h3&gt;

&lt;p&gt;ì ì ˆí•œ Inputê³¼ Outputì„ ë„£ìœ¼ë©´, single textë‚˜ text pair ëª¨ë‘ ê°€ëŠ¥.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;BERT instead uses the self-attention mechanism to unify these two stages, as encoding a concatenated text pair with self-attention effectively includes bidirectional cross attention between two sentences.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Yeonsoo Kim</name></author><category term="Deep Learning" /><category term="BERT" /><category term="Attention" /><category term="Transformer" /><summary type="html">Pre-training of Deep Bidirectional Transformers for Language Understanding(BERT) ì„ ì½ê³  ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.</summary></entry><entry><title type="html">2020ë…„ì„ ëŒì•„ë³´ë©°, 2020 YEAR in REVIEW</title><link href="http://localhost:4000/logs/2020/12/31/2020_YEAR_in_REVIEW/" rel="alternate" type="text/html" title="2020ë…„ì„ ëŒì•„ë³´ë©°, 2020 YEAR in REVIEW" /><published>2020-12-31T00:00:00+09:00</published><updated>2020-12-31T00:00:00+09:00</updated><id>http://localhost:4000/logs/2020/12/31/2020_YEAR_in_REVIEW</id><content type="html" xml:base="http://localhost:4000/logs/2020/12/31/2020_YEAR_in_REVIEW/">&lt;p&gt;2020ë…„ ì €ì—ê²Œ ìˆì—ˆë˜ ì¼ì„ ì§§ê²Œ íšŒê³ í•˜ëŠ” ê¸€ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ëª©ì°¨&quot;&gt;ëª©ì°¨&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;ìˆ˜í™”ì¸ì‹ ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ í”„ë¡œì íŠ¸ ì™„ì„±&lt;/li&gt;
  &lt;li&gt;ë°ì´í„° ë¶„ì„ ê³µë¶€&lt;/li&gt;
  &lt;li&gt;SKT AI Fellowship 2ê¸° ì§€ì›ê³¼ íƒˆë½&lt;/li&gt;
  &lt;li&gt;ë…¼ë¬¸ ìŠ¤í„°ë””&lt;/li&gt;
  &lt;li&gt;HAICON 2020 ì…ì„ &lt;/li&gt;
  &lt;li&gt;1,2í•™ê¸° ëª¨ë‘ 4ì ëŒ€ë¡œ ë§ˆë¬´ë¦¬&lt;/li&gt;
  &lt;li&gt;2021ë…„ ëª©í‘œ&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;1ï¸âƒ£-ìˆ˜í™”ì¸ì‹-ì›¹-ì–´í”Œë¦¬ì¼€ì´ì…˜-í”„ë¡œì íŠ¸-ì™„ì„±&quot;&gt;1ï¸âƒ£ ìˆ˜í™”ì¸ì‹ ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ í”„ë¡œì íŠ¸ ì™„ì„±&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/103408719-15112980-4ba7-11eb-8161-5ec2c9fbcbb4.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DSC Ewhaì—ì„œ ìš°ë¦¬íŒ€ì´ ì§„í–‰í•˜ë˜ í”„ë¡œì íŠ¸ëŠ” &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ìˆ˜í™” ì¸ì‹&lt;/code&gt;ê³¼ ê´€ë ¨ëœ í”„ë¡œì íŠ¸ì˜€ë‹¤.&lt;/p&gt;

&lt;p&gt;ì •í™•íˆëŠ” â€œë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì´ìš©í•œ ìˆ˜í™” êµìœ¡ ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜â€.&lt;/p&gt;

&lt;p&gt;ì‰½ì§€ ì•Šì€ í”„ë¡œì íŠ¸ì˜€ê¸°ì— êµ‰ì¥íˆ ë‹¤ì‚¬ë‹¤ë‚œí–ˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë”¥ëŸ¬ë‹ì„ ì•„ì§ ìì£¼ ë‹¤ë£¨ì§€ ì•Šì€ íŒ€ì›ë“¤ì´ ë§ì•˜ê¸°ì—(ë‚˜ í¬í•¨) ì²˜ìŒë¶€í„° ì´ë¡  ê³µë¶€ë„ í•´ë³´ê³ , ìˆ˜í™” ì¸ì‹ ê´€ë ¨ ë…¼ë¬¸ë„ ì½ì–´ë³´ê³ , ê´€ë ¨ í”„ë¡œì íŠ¸ë“¤ë„ ë§ì´ ì¡°ì‚¬í–ˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;í”„ë¡œì íŠ¸ ì´ˆê¸°ì— ì´ë ‡ê²Œ ë§ì´ ê³ ìƒí–ˆê¸° ë•Œë¬¸ì— ìƒëŒ€ì ìœ¼ë¡œ ìš°ë¦¬ íŒ€ì€ ì¤‘í•˜ë°˜ë¶€í„°ëŠ” í•  ì¼ì´ ì—†ì—ˆë‹¤ :)&lt;/p&gt;

&lt;p&gt;íŒ€ì›ë“¤ì´ ì—´ì •, ëˆê¸°, ì˜ì§€, ì‹¤ë ¥ê¹Œì§€ ìˆì–´ì„œ ë•ë¶„ì— ì´ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜ì›”í•˜ê²Œ(?) ì™„ìˆ˜í•  ìˆ˜ ìˆì—ˆë˜ ê²ƒ ê°™ë‹¤.&lt;/p&gt;

&lt;p&gt;êµ‰ì¥íˆ ë‹¤ì‚¬ë‹¤ë‚œí•œ ì¼ì´ ë§ì•˜ì§€ë§Œâ€¦^^ ê·¸ ì´ì•¼ê¸°ë“¤ì€ ì„œë¡œì˜ ê°€ìŠ´ ì†ì— ë¬»ì–´ë‘ê¸°ë¡œ í•˜ê³  ã…‹ã…‹ã…‹&lt;/p&gt;

&lt;p&gt;ìš°ë¦¬ë§Œì˜ ìˆ˜í™” ì¸ì‹ ëª¨ë¸ì„ ë§Œë“œëŠë¼ ê°€ì¥ ë§ì€ ì‹œê°„ì„ ìŸì•„ ë¶€ì—ˆì—ˆë‹¤. í•˜ì§€ë§Œ ì´ë•ë¶„ì— ë‚˜ëŠ” Object Detectionì— ëŒ€í•œ ê³µë¶€ì™€ ê´€ë ¨ ê²½í—˜ì„ ìŒ“ì„ ìˆ˜ ìˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;YOLO ë“± ì—¬ëŸ¬ ëª¨ë¸ë“¤ì„ ì§ì ‘ ëŒë ¤ë³´ê¸°ë„ í•˜ê³ , ì§ì ‘ ë§Œë“¤ì–´ë³´ê¸°ë„ í•˜ì˜€ë‹¤. ê²°ê³¼ì ìœ¼ë¡œëŠ” ìš°ë¦¬ íŒ€ì˜ ã…ˆã…‡ì–¸ë‹ˆê°€ ë§Œë“  ëª¨ë¸ì„ ì¼ì§€ë§Œ ğŸ˜†&lt;/p&gt;

&lt;p&gt;ì•„ë¬´íŠ¼ ì´ í”„ë¡œì íŠ¸ë¡œ ì¸í•´ ë‚˜ëŠ” &lt;strong&gt;ì¢‹ì€ ì‚¬ëŒë“¤ë„ ì–»ì—ˆê³ , ë”¥ëŸ¬ë‹ì— ëŒ€í•œ í˜¸ê°ê³¼ í¥ë¯¸, ìì‹ ê° ë“±ì„ ëª¨ë‘ ì–»ì„ ìˆ˜ ìˆì—ˆë‹¤.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;í™•ì‹¤íˆ í”„ë¡œì íŠ¸ë¥¼ í•œë²ˆ í•˜ê³  ë‚˜ë©´ ë§ì€ ì„±ì¥ì„ ì´ë£¨ëŠ” ê²ƒ ê°™ë‹¤. ë‚´ë…„ì˜ ë‚˜ëŠ” ì¡¸ì—… í”„ë¡œì íŠ¸ë¥¼ í†µí•´ í›¨ì”¬ ë” ì„±ì¥í•  ìˆ˜ ìˆê¸°ë¥¼.&lt;/p&gt;

&lt;h3 id=&quot;2ï¸âƒ£-ë°ì´í„°-ë¶„ì„-ê³µë¶€&quot;&gt;2ï¸âƒ£ ë°ì´í„° ë¶„ì„ ê³µë¶€&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/103408999-23137a00-4ba8-11eb-888e-4532bc570e1e.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ë°ì´í„° ë¶„ì„ ê³µë¶€ë¥¼ í•˜ê²Œ ëœ ê³„ê¸°ëŠ” ì¢€ ì†ë¬¼ì ì´ë‹¤.&lt;/p&gt;

&lt;p&gt;AI ë¦¬ì„œì³/ì—”ì§€ë‹ˆì–´ ì§êµ°ì„ ëª¨ì§‘í•  ë•Œ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ìš°ëŒ€ì‚¬í•­&lt;/code&gt;ì— ìºê¸€ê³¼ ê°™ì€ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ì»´í”¼í‹°ì…˜ê³¼ ê´€ë ¨ëœ ìˆ˜ìƒ ê²½í—˜ì„ ì ì–´ë†¨ê¸° ë•Œë¬¸ ^^;;&lt;/p&gt;

&lt;p&gt;ìºê¸€ê°™ì€ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ëŒ€íšŒ ìƒê¸ˆë„ ì–´ë§ˆì–´ë§ˆí•˜ê³  ë§ì´ë‹¤ã…‹ã…‹ã…‹.&lt;/p&gt;

&lt;p&gt;ìºê¸€ëŸ¬ë“¤ì˜ ì¶”ì²œì„ ë°›ì•„ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;íŒŒì´ì¬ ë¨¸ì‹ ëŸ¬ë‹ ì™„ë²½ ê°€ì´ë“œ&lt;/code&gt; (ë¶€ì œ: ê³µë£¡ì±…)ì„ ê³µë¶€í•˜ê¸° ì‹œì‘í–ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì¸í”„ëŸ°ì—ì„œ ê°•ì˜ ë“¤ìœ¼ë©´ì„œ í—ˆê²ì§€ê² ì§„ë„ë¥¼ ëºë˜ ê¸°ì–µì´ ë‚œë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ë•Œ ì½”ë¡œë‚˜ê°€ ë§‰ ìœ í–‰í•˜ê¸° ì‹œì‘ì¸ ë•Œë¼ ì¹œêµ¬ë‘ ê³µë¶€ë‚˜ í•˜ìëŠ” ìƒê°ìœ¼ë¡œ ì‹œì‘í–ˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì†ë¬¼ì ìœ¼ë¡œ ì‹œì‘í•œ ê³µë¶€ì´ì§€ë§Œ, ë‚˜ëŠ” ë”¥ëŸ¬ë‹ì„ í¬í•¨í•œ ì¸ê³µì§€ëŠ¥ì— ê´€ì‹¬ì´ ë§ì•˜ê¸° ë•Œë¬¸ì— ì‹¤ìƒí™œ ë°ì´í„°ì— ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©ì‹œí‚¤ëŠ” ê²ƒì´ ë‚˜ì—ê²Œ í° í¥ë¯¸ë¡œ ë‹¤ê°€ì™”ë‹¤.&lt;/p&gt;

&lt;p&gt;ì§€ê¸ˆì€ ë¬¼ë¡  ë°ì´í„° ë¶„ì„ì´ ì´ëŠ” ì „ë¶€ëŠ” ì•„ë‹ˆë¼ëŠ” ê²ƒì€ ì•Œê³  ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì–´ì¨Œë“  ì´ ëŠë‚Œ? ì´ ìƒê° ë•ë¶„ì— ê³µë¶€ë¥¼ ìˆ˜ì›”í•˜ê²Œ í•  ìˆ˜ ìˆì—ˆê³ , ìºê¸€ í•„ì‚¬ ì»¤ë¦¬í˜ëŸ¼ì„ ë”°ë¼ ê°€ë©´ì„œ(ì™„ì „ ì¡°ê¸ˆ ë”°ë¼ê°”ë‹¤ ã…‹ã…‹ã…‹ ê·¸ë•Œê°€ ê°œê°•í•  ë•Œ ì¯¤ ë˜ì–´ì„œ..) ë‚˜ì¤‘ì— ê¼­ ìºê¸€ì— ì°¸ê°€í•´ì„œ ìƒì„ ë°›ê³  ì‹¶ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ëŠ” ì¢€ ì´ë”° ì„œìˆ í•  HAICONì— ì…ìƒí•  ìˆ˜ ìˆê²Œ ëœ ê³„ê¸°ê°€ ëœë‹¤ã…ã…&lt;/p&gt;

&lt;h3 id=&quot;3ï¸âƒ£-skt-ai-fellowship-2ê¸°-ì§€ì›ê³¼-íƒˆë½&quot;&gt;3ï¸âƒ£ SKT AI Fellowship 2ê¸° ì§€ì›ê³¼ íƒˆë½&lt;/h3&gt;

&lt;!-- ![image](https://user-images.githubusercontent.com/48315997/103409204-00359580-4ba9-11eb-8ed6-6fa981f29d59.png) --&gt;
&lt;p&gt;&lt;img width=&quot;550&quot; src=&quot;https://user-images.githubusercontent.com/48315997/103409204-00359580-4ba9-11eb-8ed6-6fa981f29d59.png&quot; /&gt;
ì„œë¥˜ í•©ê²© ğŸ˜†
&lt;!-- ![image](https://user-images.githubusercontent.com/48315997/103409209-088dd080-4ba9-11eb-8f5a-787e4b3e0068.png) --&gt;
&lt;img width=&quot;550&quot; src=&quot;https://user-images.githubusercontent.com/48315997/103409209-088dd080-4ba9-11eb-8f5a-787e4b3e0068.png&quot; /&gt;
ë©´ì ‘ íƒˆë½ ğŸ˜‚&lt;/p&gt;

&lt;p&gt;======&lt;/p&gt;

&lt;p&gt;ì–´ì©Œë‹¤ ì•Œê²Œ ëœ SKT AI Fellowship.&lt;/p&gt;

&lt;p&gt;SKTì—ì„œ ê³µëŒ€ ëŒ€í•™(ì›)ìƒì—ê²Œ ì¸ê³µì§€ëŠ¥ê³¼ ê´€ë ¨ëœ ëª‡ëª‡ í”„ë¡œì íŠ¸ë¥¼ ì œì‹œí•˜ê³ , í° ê·œëª¨ë¡œ ì§€ì›í•´ì£¼ëŠ” í”„ë¡œê·¸ë¨ì´ì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ìˆ˜í™”ì¸ì‹ í”„ë¡œì íŠ¸ë¥¼ ê°™ì´í•œ íŒ€ì›ë“¤ì—ê²Œ ë¬¼ì–´ë³¸ í›„, ê°™ì´ ì¤€ë¹„í•˜ê¸°ë¡œ í–ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì£¼ì œëŠ” ë‚´ê°€ ì¢‹ì•„í•˜ëŠ”(ã…‹ã…‹ã…‹) ë¦¬ê·¸ì˜¤ë¸Œë ˆì „ë“œì˜ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;í•˜ì´ë¼ì´íŠ¸ ìë™ ì¶”ì¶œ&lt;/code&gt; ì—°êµ¬ í”„ë¡œì íŠ¸ì˜€ë‹¤.&lt;/p&gt;

&lt;p&gt;ë¦¬ê·¸ì˜¤ë¸Œë ˆì „ë“œë¼ ë”± ì§€ì¹­í•˜ì§€ëŠ” ì•Šê³ , ìŠ¤í¬ì¸ ë¼ê³  ë§í–ˆì§€ë§Œ ë‚´ê°€ ì›Œë‚™ ë¡¤ì„ ì¦ê²¨ë³´ê¸° ë•Œë¬¸ì— ì´ ì£¼ì œë¡œ ì–´í•„ì„ ê°•í•˜ê²Œ í–ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ê´€ë ¨ ì—°êµ¬ ë…¼ë¬¸ë“¤, ë‹¤ë¥¸ ìŠ¤í¬ì¸ ë“¤(ex.ì•¼êµ¬)ì— ì ìš©ëœ í•˜ì´ë¼ì´íŠ¸AI ê¸°ìˆ  ë“±ì„ ì¡°ì‚¬í•˜ì—¬ ìš°ë¦¬ë„ ì•„ì´ë””ì–´ë¥¼ ëƒˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ë•ŒëŠ” ì •ë§ ë³„ ê¸°ëŒ€ ì•ˆí–ˆëŠ”ë°, ë©´ì ‘ê¹Œì§€ ì˜¬ë¼ê°”ë‹¤! ë©´ì ‘ì€ ê° ì£¼ì œë‹¹ ìµœì¢… 3íŒ€(ìš°ë¦¬ ì£¼ì œëŠ” ê·¸ë¬ëŠ”ë° í™•ì‹¤í•˜ì§„ ì•Šë‹¤)ì´ ì˜¬ë¼ê°€ë©°, ì´ ì¤‘ 1íŒ€ì´ ìµœì¢… íŒ€ìœ¼ë¡œ ì„ ì •ëœë‹¤.&lt;/p&gt;

&lt;p&gt;ìƒê°ì§€ë„ ëª»í•œ ê²°ê³¼ì— ìš°ë¦¬ëŠ” ë¹ ë¥´ê²Œ ë©´ì ‘ ëŒ€ë¹„ë¥¼ í–ˆë‹¤. ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì˜ˆìƒ ì§ˆë¬¸ê³¼ ê·¸ì— ëŒ€í•œ ë‹µë³€ë“¤ì„ ëª¨ë‘ ì¤€ë¹„í–ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë˜ í”„ë¡œì íŠ¸ë¥¼ ì–´ë–»ê²Œ ì§„í–‰í•  ê²ƒì¸ì§€ ë°œí‘œí•´ì•¼ í–ˆëŠ”ë° ì´ëŠ” ë‚´ê°€ ë§¡ì•˜ì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì½”ë¡œë‚˜ë¡œ ì¸í•´ ì‹¤ì œ ë©´ì ‘ì€ Zoomìœ¼ë¡œ ì§„í–‰ë˜ì—ˆë‹¤. ë©´ì ‘ê´€ì€ 3ëª…ì´ì—ˆê³  ì¹œì ˆí•˜ê³  í¸í•˜ê²Œ í•´ì£¼ì…¨ë‹¤. ë¬¼ë¡  ê¸°ìˆ ì ì¸ ì–˜ê¸°ì— ëŒ€í•´ì„œëŠ” ë‚ ì¹´ë¡­ê³  ì˜ˆë¦¬í•œ ì§ˆë¬¸, ë¹„íŒë“¤ì„ í•´ì£¼ì…¨ë‹¤.&lt;/p&gt;

&lt;p&gt;ì‚¬ì‹¤ ë©´ì ‘ ë¶„ìœ„ê¸°ê°€ êµ‰ì¥íˆ ì¢‹ì•˜ê³ , ìš°ë¦¬ê°€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì˜ í–ˆê¸°ì— ê¸°ëŒ€ë¥¼ í•˜ê³  ìˆë˜ ìƒíƒœì˜€ë‹¤ã… ã… &lt;/p&gt;

&lt;p&gt;í•˜ì§€ë§Œ ì•„ì‰½ê²Œë„ íƒˆë½ í†µë³´ë¥¼ ë°›ì•˜ë‹¤.&lt;/p&gt;

&lt;p&gt;ì§€ê¸ˆ ì™€ì„œ ê¸ì •ì ìœ¼ë¡œ ìƒê°í•´ë³´ìë©´, ìš°ë¦¬ê°€ ê·¸ ê¸°ìˆ ì„ ì •ë§ êµ¬í˜„í–ˆì„ ìˆ˜ ìˆëŠ” ê¸°ìˆ  ìˆ˜ì¤€ì´ì—ˆëŠ”ì§€ëŠ” ëª¨ë¥´ê² ë‹¤. ê½¤ ì–´ë ¤ìš´ ë‚œì´ë„ë¥¼ ê°€ì§„ ì—°êµ¬ë¶„ì•¼/ê¸°ìˆ ì´ê¸° ë•Œë¬¸ì´ë‹¤.
ë¬¼ë¡  ì§„ì§œ ëë‹¤ë©´ ì •ë§ ì—´ì‹¬íˆ ê³µë¶€í•˜ê³  ë…¸ë ¥í•´ì„œ ì™„ì„±í•˜ë„ë¡ ë§Œë“¤ì—ˆê² ì§€ë§Œâ€¦ ê¸ì • íšŒë¡œë¥¼ ëŒë¦°ë‹¤ë©´ ã…‹ã…‹ã…‹ ì•„ì§ ë‚´ê°€ ë¶€ì¡±í•˜ë‹¤ëŠ” ì´ì•¼ê¸°ë‹ˆê¹Œâ€¦&lt;/p&gt;

&lt;p&gt;ê·¸ë˜ë„ ì´ ë•ë¶„ì—, ì—­ì‹œ ë‚´ íŒ€ì›ë“¤ì´ ì •ë§ ì¢‹ì€ ì‚¬ëŒì´ì ìš°ìˆ˜í•œ ì‚¬ëŒë“¤ì´ì—ˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë‚´ê°€ ì•„ì§ ë§ì´ ë¶€ì¡±í•´ì„œ ì´ë ‡ê²Œ ëœ ê²°ê³¼ë¼ëŠ” ê²ƒì„ ì¸ì •í•˜ê³ , ì•ìœ¼ë¡œ ë” ì—´ì‹¬íˆ ê³µë¶€í•˜ê³  ë…¸ë ¥í•´ì•¼ê² ë‹¤ëŠ” ë§ˆìŒê°€ì§ì„ ë‹¤ì‹œê¸ˆ ê°€ì§ˆ ìˆ˜ ìˆì—ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;4ï¸âƒ£-ë…¼ë¬¸-ìŠ¤í„°ë””&quot;&gt;4ï¸âƒ£ ë…¼ë¬¸ ìŠ¤í„°ë””&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/103409526-a209b200-4baa-11eb-9057-7f390de142a8.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì˜¬í•´ ê°€ì¥ í° ìˆ˜í™• ì¤‘ í•˜ë‚˜ëŠ” ì¡¸í”„ ë©”ì´íŠ¸ë¥¼ ì°¾ì€ ê²ƒì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ê³¼ì— ì•„ëŠ” ì‚¬ëŒë“¤ì´ ë§ì§€ ì•Šê¸°ë„ í•´ì„œ í˜¼ì í•´ì•¼ í•˜ë‚˜ ë§ì´ ê±±ì •í–ˆëŠ”ë° ë¨¼ì € ì œì•ˆí•´ì¤€ ê²ƒì´ êµ‰ì¥íˆ ê³ ë§ˆì› ë‹¤ ã…ã…&lt;/p&gt;

&lt;p&gt;ë¹„ìŠ·í•œ ëª©í‘œë¥¼ ê°€ì§€ê³  ìˆê³  ì„œë¡œ ì—´ì •, ì˜ì§€ë„ ê°€ë“í•˜ê¸° ë•Œë¬¸ì— ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆìœ¼ë¦¬ë¼ í™•ì‹ í•œë‹¤.&lt;/p&gt;

&lt;p&gt;ì•„ë¬´íŠ¼, ì´ ì¹œêµ¬ì™€ 7ì›”ë§ë¶€í„° &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ë…¼ë¬¸ ì½ê¸° ìŠ¤í„°ë””&lt;/code&gt;ë¥¼ ì‹œì‘í–ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì²˜ìŒ ì‹œì‘í•  ë•ŒëŠ” ë…¼ë¬¸ì´ë¼ëŠ” ê²ƒì´ êµ‰ì¥íˆ ë¶€ë‹´ìŠ¤ëŸ½ê²Œ ë‹¤ê°€ì™”ëŠ”ë°, ì´ì œëŠ” ì•„~ì£¼ ì¡°ê¸ˆì€ ìµìˆ™í•´ì ¸ì„œ í¬ê²Œ ê±°ë¶€ê°ì´ë‚˜ ë¶€ë‹´ê°ì€ ë“¤ì§€ ì•Šì•„ì¡Œë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ê²ƒë§Œ í•´ë„ êµ‰ì¥í•œ ë°œì „ ì•„ë‹Œê°€? ã…‹ã…‹ã…‹&lt;/p&gt;

&lt;p&gt;ì´ ë…¼ë¬¸ ìŠ¤í„°ë””ë¥¼ í†µí•´ ë‚´ê°€ ì–»ê²Œ ëœ ê²ƒì´ ìˆë‹¤ë©´, â€˜ë‚´ê°€ ì´ ë¶„ì•¼ë¥¼ ì˜¤ë«ë™ì•ˆ ì¢‹ì•„í•  ìˆ˜ ìˆê² êµ¬ë‚˜â€™ë¼ëŠ” ìƒê°ì´ì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ê³µë¶€ê°€ ì§€ê²¹ì§€ê°€ ì•Šê³ , ë‚´ê°€ í•´ì•¼ í•  ê²ƒì´ ì‚°ë”ë¯¸ë¼ëŠ” ê²ƒì„ ì•Œì§€ë§Œ ê·¸ê²ƒì´ ë‘ë µê±°ë‚˜ ë¶ˆì•ˆí•˜ì§€ ì•Šì•˜ë‹¤.&lt;/p&gt;

&lt;p&gt;ê·¸ë˜ë„ ë‚˜ëŠ” ì•„ì§ ë§ì´ ë¶€ì¡±í•˜ë‹¤! í•˜ë£¨ì— ë…¼ë¬¸ í•œí¸ì”© ë§¤ì¼ë§ˆë‹¤ ë¿Œì…”ë„ ì•„ì§ ëª¨ìë¼ë‹¤.&lt;/p&gt;

&lt;p&gt;ì§€ê¸ˆì€ ìš°ë¦¬ ë‘˜ ë‹¤ Domain Adaptation, GAN ìª½ ì—°êµ¬ì— ê´€ì‹¬ì„ ê°€ì§€ê²Œ ë˜ì–´ ê·¸ ìª½ ë…¼ë¬¸ë“¤ì„ ì½ì–´ë³´ê³  êµ¬í˜„í•˜ê³  ìˆë‹¤. (ì•„ì§ ë§ì´ëŠ” ëª»í–ˆì§€ë§Œ ã…‹ã…‹)&lt;/p&gt;

&lt;h3 id=&quot;5ï¸âƒ£-haicon-2020-ì…ì„ &quot;&gt;5ï¸âƒ£ HAICON 2020 ì…ì„ &lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/103409708-5c011e00-4bab-11eb-9f49-86fcfd219ff2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì•„ê¹Œ ì˜¬í•´ ì´ˆì— ë°ì´í„°ë¶„ì„ ê³µë¶€ë¥¼ í–ˆë‹¤ê³  í–ˆëŠ”ë°, ì´ ë•Œ ê°™ì´ í•œ ì¹œêµ¬ì™€ ëŒ€íšŒë¥¼ ë‚˜ê°€ê¸°ë¡œ í–ˆë‹¤.&lt;/p&gt;

&lt;p&gt;êµ­ë‚´ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ì»´í”¼í‹°ì…˜ì„ ëª¨ì•„ë†“ì€ í”Œë«í¼ì¸ ë°ì´ì½˜ì—ì„œ í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ëŒ€íšŒì—ì„œ ê°€ì¥ ë§ì€ ìƒê¸ˆì„ ë¿Œë¦¬ëŠ” ëŒ€íšŒë¥¼ ê³¨ëë‹¤ ã…‹ã…‹ã…‹.&lt;/p&gt;

&lt;p&gt;ê¸ˆì•¡ë„ ê·¸ë ‡ì§€ë§Œ, êµ­ê°€ì •ë³´ì›ê³¼ êµ­ê°€ë³´ì•ˆê¸°ìˆ ì—°êµ¬ì†Œê°€ ì§„í–‰í•œë‹¤ëŠ” ì ì—ì„œë„ í° í¥ë¯¸?ë¥¼ ëŒì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì²« ì°¸ê°€í•˜ëŠ” ëŒ€íšŒì´ë‹ˆ ë§Œí¼ ì •ë§ ë§ì€ ì‹œë„ë“¤ì„ í•´ë³´ì•˜ë‹¤. ì‚¬ì‹¤ 1ë“±ê¹Œì§€ëŠ” í¬ê²Œ ë°”ë¼ì§€ëŠ” ì•Šì•˜ì§€ë§Œ ìˆ˜ìƒ ìš•ì‹¬ì€ ë¶„ëª…íˆ ìˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ëŒ€íšŒ ì´ˆì—ëŠ” ìˆ˜ìƒê¶Œì— ìˆì—ˆì§€ë§Œ ì¤‘í›„ë°˜ë¶€ë¡œ ë“¤ë©´ì„œ ê³ ìˆ˜ë“¤ì´ ë§ì´ ì°¸ê°€í–ˆëŠ”ì§€ ì¡°ê¸ˆì”© ì¡°ê¸ˆì”© ë°€ë ¤ë‚¬ê³ , ê²°ê³¼ì ìœ¼ë¡œ ëŒ€íšŒ ë§ˆì§€ë§‰ ì¦ˆìŒì—” ìˆ˜ìƒê¶Œì—ì„œ ê½¤ ë©€ì–´ì¡Œì—ˆë‹¤ã… ã…  (Public score ê¸°ì¤€)&lt;/p&gt;

&lt;p&gt;ê·¼ë° ì´ê²Œ ë¬´ìŠ¨ ì¼ì¸ì§€, ì „ì²´ í…ŒìŠ¤íŠ¸ ì…‹ìœ¼ë¡œ ìµœì¢… ê²°ê³¼ë¥¼ ëŒë¦° Private scoreì—ì„œ 12ìœ„ê°€ ë‚˜ì˜¨ ê²ƒì´ë‹¤! 10ìœ„ê¹Œì§€ê°€ ìˆ˜ìƒê¶Œì´ë¼ ì•„ ì´ê±° ì§„ì§œ ì•„ê¹ë‹¤, ì¡°ê¸ˆë§Œ ë” ë…¸ë ¥í•  ê±¸ ì°°ë‚˜ í›„íšŒí•˜ê¸´ í–ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ê·¸ë˜ë„ ë‚˜ë‘ ë‚´ ì¹œêµ¬ëŠ” ì •ë§ ìµœëŒ€í•œì˜ ë…¸ë ¥ì„ í–ˆê³ , ì •ë§ ë§ì€ ì‹¤í—˜ì„ ê±°ì³¤ê¸° ë•Œë¬¸ì— í° ìƒìŠ¹ì€ ì—†ì—ˆì„ì§€ë„ ëª¨ë¥¸ë‹¤. (ì²˜ìŒì´ë‹¤ ë³´ë‹ˆ ì–‘ìœ¼ë¡œ ìŠ¹ë¶€í–ˆì—ˆë‹¤)&lt;/p&gt;

&lt;p&gt;ê·¸ë˜ë„ ì¡°ê¸ˆ ê¸°ëŒ€ë¥¼ í’ˆê³ , ë³´ê³ ì„œì™€ ìµœì¢… ì œì¶œë³¸ì„ ì œì¶œí•œ ê²°ê³¼ ë‚´ ìœ„ì— 2ëª…ì´ ê·œì¹™ ìœ„ë°˜ í˜¹ì€ ë­ê°€ ë¶€ì¡±í–ˆëŠ”ì§€ ìš°ë¦¬ê°€ í„±ê±¸ì´ë¡œ ì…ì„ ì„ í•˜ê²Œ ëœ ê²ƒì´ë‹¤!! ì§„ì§œ ê¸°ë»¤ë‹¤ ì´ë•Œ ã…ã…&lt;/p&gt;

&lt;p&gt;í›„ê¸°ë¥¼ ìì„¸íˆ í’€ê³  ì‹¶ì§€ë§Œ ì™¸ë¶€ì— ë°œì„¤í•˜ì§€ ë§ë¼ëŠ” ì‚¬í•­ì´ ë§ì•˜ì–´ì„œ ì´ì— ëŒ€í•œ í›„ê¸°ëŠ” ì´ê²Œ ë!! ì •ë§ ë©‹ì§„ ì‚¬ëŒë“¤ë„ ë§ì´ ë´¤ê³ , í•™ë¶€ìƒì€ ë‚˜ë‘ í•œ íŒ€ë°–ì— ì—†ì—ˆë˜ ê²ƒ ê°™ì€ë° êµ‰ì¥íˆ ì˜ê´‘ì´ì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë‚˜ì¤‘ì—ëŠ” ë  ìˆ˜ ìˆìœ¼ë©´ ìºê¸€ ëŒ€íšŒì— ì…ìƒí•˜ê³  ì‹¶ë‹¤ ã…ã…&lt;/p&gt;

&lt;h3 id=&quot;6ï¸âƒ£-12í•™ê¸°-ëª¨ë‘-4ì ëŒ€ë¡œ-ë§ˆë¬´ë¦¬&quot;&gt;6ï¸âƒ£ 1,2í•™ê¸° ëª¨ë‘ 4ì ëŒ€ë¡œ ë§ˆë¬´ë¦¬&lt;/h3&gt;

&lt;p&gt;ì˜¬í•´ 1í•™ê¸°ëŠ” ì •ë§ í˜ë“¤ì—ˆë‹¤. ê½¤ ë¹¡ì„¼ ê³¼ëª©ë“¤ì„ ë“£ê¸°ë„ í–ˆê³ , ì½”ë¡œë‚˜ê°€ í„°ì§€ê³  ì²« ë¹„ëŒ€ë©´ ìˆ˜ì—…ì´ë¼ ì´ë¦¬ì €ë¦¬ ì •ì‹ ì—†ì—ˆë˜ ê²ƒ ê°™ë‹¤.&lt;/p&gt;

&lt;p&gt;ë•Œë¬¸ì— 1í•™ê¸°ì—ëŠ” ì •ë§ í•™ê¸° ê³µë¶€ ì™¸ì—ëŠ” ë‹¤ë¥¸ ê³µë¶€ë¥¼ í•  ìˆ˜ê°€ ì—†ì—ˆë‹¤ ã… ã… &lt;/p&gt;

&lt;p&gt;ë‹¤ë¥¸ í•™êµë‚˜ íƒ€ê³¼ë“¤ì€ í•™ì  ì˜ ë¿Œë ¤ì£¼ë˜ë° ã…ã…â€¦ ë‚´ê°€ ë“¤ì€ ìˆ˜ì—…ë“¤ì€ ë‹¤ ì½”ë¡œë‚˜ ì´ì „ì´ë‘ ë¹„ìŠ·í•˜ê±°ë‚˜ ì˜¤íˆë ¤ ë” ì§œê¸°ë„ ^^..&lt;/p&gt;

&lt;p&gt;1í•™ê¸°ëŠ” 6ì „ê³µ 1êµì–‘ 21í•™ì  ì´ìˆ˜, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4.09/4.3&lt;/code&gt;ì´ì—ˆê³ &lt;/p&gt;

&lt;p&gt;2í•™ê¸°ëŠ” 6ì „ê³µ 1êµì–‘ 19í•™ì  ì´ìˆ˜, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4.2/4.3&lt;/code&gt;ì´ì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;2í•™ê¸°ì— ë“¤ì€ êµì–‘ìˆ˜ì—…ì€ 2017ë…„ì— ë“¤ì—ˆë˜ ê³¼ëª© í•˜ë‚˜ë¥¼ ì¬ìˆ˜ê°•í•œ ê²ƒì´ë¼ 1-2ë“± ì ìˆ˜ì˜€ì„í…ë° ì¬ìˆ˜ê°• ìµœëŒ€ í•™ì ì¸ A-ë¥¼ ë°›ì•„ì„œ ê°œì¸ì ìœ¼ë¡œ ì•„ì‰¬ì› ë‹¤.
ê·¸ë¦¬ê³  2í•™ê¸°ëŠ” ê±°ì˜ ëª¨ë“  ê³¼ëª©ì„ 1ë“±, 2ë“± ì•„ë‹ˆë©´ ëª»í•´ë„ 5ë“± ì •ë„ í–ˆê¸° ë•Œë¬¸ì— ê°œì¸ì ìœ¼ë¡œ ë§˜ì— ë“œëŠ” í•™ê¸°ì˜€ë‹¤.&lt;/p&gt;

&lt;p&gt;ì‚¬ì‹¤ 2í•™ê¸°ì— ë“¤ì€ ê°•ì˜ë“¤ì´ ì‰½ë‹¤ê³  ëŠê¼ˆì„ ë•Œê°€ ì¢…ì¢… ìˆì—ˆë‹¤. ë‚´ê°€ ì˜¬í•´ ë§ì€ ì„±ì¥ì„ í–ˆë‹¤ëŠ” ê²Œ ëŠê»´ì ¸ì„œ ë¿Œë“¯í–ˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;í•™ê¸°ëŠ” ì•„ì§ ê½¤ ë‚¨ì•˜ì§€ë§Œ, ë‚¨ì€ ì´ìˆ˜ í•™ì ì€ ê·¸ë ‡ê²Œ ë§ì§€ ì•Šë‹¤. ë‚¨ì€ í•™ì ë“¤ë„ ëª¨ë‘ A+ì„ ë°›ì•„ì„œ ìµœìš°ë“±ì¡¸ì—…ì„ í•  ìˆ˜ ìˆê²Œ ë˜ë©´ ì¢‹ê² ë‹¤!&lt;/p&gt;

&lt;h3 id=&quot;7ï¸âƒ£-2021ë…„-ëª©í‘œ&quot;&gt;7ï¸âƒ£ 2021ë…„ ëª©í‘œ&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://images.unsplash.com/photo-1546074177-31bfa593f731?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;amp;ixlib=rb-1.2.1&amp;amp;auto=format&amp;amp;fit=crop&amp;amp;w=1267&amp;amp;q=80&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì˜¬ í•œ í•´ë¥¼ ë˜ëŒì•„ë³´ë‹ˆ ì •ë§ ë§ì€ ì¼ì´ ìˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì½”ë¡œë‚˜ë•Œë¬¸ì— ì‚¬ëŒë“¤ì„ ë§ì´ ëª» ë§Œë‚¬ì§€ë§Œ, ì´ê²Œ ë‚˜ì—ê²Œ ê¸ì •ì ìœ¼ë¡œ ì‘ìš©ë  ìˆ˜ ìˆì—ˆë˜ ì ì€ ë¶„ëª…íˆ ìˆì—ˆë‹¤.&lt;/p&gt;

&lt;p&gt;í˜¼ì ê³µë¶€í•  ì‹œê°„ì´ ëŠ˜ì–´ë‚˜ ì „ë³´ë‹¤ ê½¤ ë§ì´ ì„±ì¥í–ˆë‹¤ëŠ” ì ì´ ë°”ë¡œ ê·¸ê²ƒì´ë‹¤.&lt;/p&gt;

&lt;p&gt;12ì›” ì´ˆì— ì¢‹ì€ ì†Œì‹ìœ¼ë¡œëŠ” &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ETRI&lt;/code&gt; (í•œêµ­ì „ìí†µì‹ ì—°êµ¬ì›) ë™ê³„ ì—°êµ¬ì—°ìˆ˜ìƒì— í•©ê²©í–ˆë‹¤ëŠ” ê²ƒì´ë‹¤!&lt;/p&gt;

&lt;p&gt;ë‹¤ìŒì£¼ 1/2ì¼ë¶€í„° 2/26ê¹Œì§€ ëŒ€ì „ì—ì„œ ì¼ì„ í•˜ê²Œ ë˜ì—ˆëŠ”ë° êµ‰ì¥íˆ ì„¤ë Œë‹¤.&lt;/p&gt;

&lt;p&gt;ì¸í„´ê¸‰ì´ê¸° ë•Œë¬¸ì— ë§ì€ ì¼ì„ ì‹œí‚¤ì§€ ì•Šì„ ê²ƒ ê°™ì§€ë§Œ, ë‚˜ ìŠ¤ìŠ¤ë¡œ ë§ì´ ë°°ìš°ë ¤ ë…¸ë ¥í•˜ê³  ë˜ í•œ ë‹¨ê³„ ì„±ì¥í•˜ëŠ” ê³„ê¸°ê°€ ë˜ì—ˆìœ¼ë©´ ì¢‹ê² ë‹¤.&lt;/p&gt;

&lt;p&gt;ì¼ë‹¨ 2021ë…„ ëª©í‘œëŠ” í¬ê²Œ 2ê°€ì§€ì´ë‹¤.&lt;/p&gt;

&lt;h4 id=&quot;ì¡¸ì—…-í”„ë¡œì íŠ¸-ì„±ê³µì --í•´ì™¸-íƒ‘-ì»¨í¼ëŸ°ìŠ¤ì—-ë…¼ë¬¸-accept-ë˜ê¸°&quot;&gt;ì¡¸ì—… í”„ë¡œì íŠ¸ ì„±ê³µì  == í•´ì™¸ íƒ‘ ì»¨í¼ëŸ°ìŠ¤ì— ë…¼ë¬¸ Accept ë˜ê¸°&lt;/h4&gt;

&lt;p&gt;ë‚˜ì—ê²Œ ìˆì–´ 2021ë…„ì€ ê°€ì¥ ì¤‘ìš”í•œ í•œ í•´ì´ë‹¤.
ì‚¬ì‹¤ìƒ ì´ë¥¼ ìœ„í•´ ì§€ê¸ˆê¹Œì§€ ì¤€ë¹„ë¥¼ í–ˆë‹¤ê³  ë´ë„ ê³¼ì–¸ì´ ì•„ë‹ˆë‹¤. ì¡¸í”„ ì‹œì‘ì„ í•œ í•™ê¸° ë¯¸ë£¬ ê²ƒë„ ì´ë¥¼ ìœ„í•´ ê³µë¶€í•˜ê¸° ìœ„í•´ì„œì˜€ë‹¤.&lt;/p&gt;

&lt;p&gt;ë§ˆì¹¨ ì¢‹ì€ ë©”ì´íŠ¸ê°€ ìˆê³ , ë‚˜ì™€ ë¹„ìŠ·í•˜ê²Œ ì•¼ë§ë„ í¬ê¸°ì— ìš°ë¦¬ ëª©í‘œëŠ” ìƒë‹¹íˆ ë†’ê²Œ ì¡ì•˜ë‹¤.&lt;/p&gt;

&lt;p&gt;ì‚¬ì‹¤ ì €ê²ƒë³´ë‹¤ í¬ë‹¤. Best Student Paper ìƒì„ ë°›ê³  ì‹¶ë‹¤!!!!!&lt;/p&gt;

&lt;p&gt;ëˆ„êµ¬ë³´ë‹¤ ì—´ì‹¬íˆ ê³µë¶€í•˜ê³ , ëˆ„êµ¬ë³´ë‹¤ ì˜ í•´ì•¼ ëœë‹¤ëŠ” ê²ƒì„ ì•ˆë‹¤. 
ë‚˜ëŠ” ë¬´ì¡°ê±´ í›„íšŒì—†ëŠ” 1ë…„ì„ ë³´ë‚¼ ê²ƒì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ê¼­ ì´ ëª©í‘œê°€ ì„±ê³µí•  ìˆ˜ ìˆë„ë¡, ìµœì„ ì„ ë‹¤í•˜ê² ë‹¤.&lt;/p&gt;

&lt;h4 id=&quot;all-a&quot;&gt;All A+&lt;/h4&gt;

&lt;p&gt;ì•ì„  ëª©í‘œì— ë¹„í•˜ë©´ ì†Œì†Œí•˜ë‹¤.
ì¡¸í”„ ë•Œë¬¸ì— í•™ì ì€ 15~16 í•™ì  ì •ë„? ë§ì§€ ì•Šê²Œ, ë¶€ë‹´ì´ ë˜ì§€ ì•ŠëŠ” ì„ ê¹Œì§€ë§Œ ë“¤ì„ ê²ƒì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ëŒ€ì‹ ì— ë¬´ì¡°ê±´ ì˜¬ì—ì´ì !&lt;/p&gt;</content><author><name>Yeonsoo Kim</name></author><category term="íšŒê³ " /><category term="Year Review" /><summary type="html">2020ë…„ ì €ì—ê²Œ ìˆì—ˆë˜ ì¼ì„ ì§§ê²Œ íšŒê³ í•˜ëŠ” ê¸€ì…ë‹ˆë‹¤.</summary></entry><entry><title type="html">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</title><link href="http://localhost:4000/paper%20review/2020/12/30/CycleGAN/" rel="alternate" type="text/html" title="Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks" /><published>2020-12-30T00:00:00+09:00</published><updated>2020-12-30T00:00:00+09:00</updated><id>http://localhost:4000/paper%20review/2020/12/30/CycleGAN</id><content type="html" xml:base="http://localhost:4000/paper%20review/2020/12/30/CycleGAN/">&lt;p&gt;Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN) ì„ ì½ê³  ê°œì¸ì ìœ¼ë¡œ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ì•ì„œ ì‚´í´ë³¸ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DCGAN&lt;/code&gt;ì—°êµ¬ëŠ” í° ë°œì „ì„ ì´ë£¨ì—ˆì§€ë§Œ, ì´ ì—­ì‹œ unstableí•˜ì—¬ mode collapseê°€ ì¼ì–´ë‚  ìˆ˜ ìˆëŠ” í•œê³„ì ì´ ëšœë ·í–ˆìŠµë‹ˆë‹¤.&lt;/p&gt;</content><author><name>Yeonsoo Kim</name></author><category term="Deep Learning" /><category term="GAN" /><summary type="html">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN) ì„ ì½ê³  ê°œì¸ì ìœ¼ë¡œ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.</summary></entry><entry><title type="html">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)</title><link href="http://localhost:4000/paper%20review/2020/12/25/DCGAN/" rel="alternate" type="text/html" title="Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)" /><published>2020-12-25T00:00:00+09:00</published><updated>2020-12-25T00:00:00+09:00</updated><id>http://localhost:4000/paper%20review/2020/12/25/DCGAN</id><content type="html" xml:base="http://localhost:4000/paper%20review/2020/12/25/DCGAN/">&lt;p&gt;Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)ì„ ì½ê³  ê°œì¸ì ìœ¼ë¡œ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;unsupervised-representation-learning-with-deep-convolutional-generative-adversarial-networks-dcgan&quot;&gt;Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)&lt;/h1&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;GANì€ Representation Learningì— íš¨ê³¼ì ì´ë¼ê³  í•©ë‹ˆë‹¤. (ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ê²ƒì´ GANì˜ learning processì™€ ê´€ë ¨ì´ ìˆê³ , lack of heuristic cost function ë•ë¶„ì´ë¼ê³  ë§í•©ë‹ˆë‹¤.)&lt;/p&gt;

&lt;p&gt;ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ì²˜ìŒ ë‚˜ì˜¨ GANì€ í•™ìŠµí•˜ëŠ” ê²ƒì— ìˆì–´ ë§¤ìš° &lt;strong&gt;unstable&lt;/strong&gt;í•˜ë‹¤ëŠ” ë¬¸ì œì ì„ ê°€ì§€ê³  ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë³¸ ë…¼ë¬¸ì˜ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DCGAN&lt;/code&gt;ì€ í•´ë‹¹ ë¬¸ì œì  í•´ê²°ì„ í¬í•¨í•˜ì—¬ ì´ 4ê°€ì§€ì˜ Contributionsë¡œ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;DCGANì€ stable trainingì´ ê°€ëŠ¥í•˜ë‹¤&lt;/li&gt;
  &lt;li&gt;í•™ìŠµëœ DiscriminatorëŠ” image classification íƒœìŠ¤í¬ì— ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤. (ë‹¤ë¥¸ unsupervised ì•Œê³ ë¦¬ì¦˜ë“¤ê³¼ ë¹„êµí•  ê²ƒì„.)&lt;/li&gt;
  &lt;li&gt;GANì´ í•™ìŠµí•œ filtersë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆê³ , íŠ¹ì • ì˜¤ë¸Œì íŠ¸ì— ëŒ€í•´ íŠ¹ì • filterë¥¼ í•™ìŠµí–ˆë‹¤ëŠ” ì ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆë‹¤.&lt;/li&gt;
  &lt;li&gt;GeneratorëŠ” vector arithmetic propertiesë¥¼ ê°€ì§€ê³  ìˆë‹¤.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;approach-and-model-architecture&quot;&gt;APPROACH AND MODEL ARCHITECTURE&lt;/h2&gt;

&lt;p&gt;&lt;img width=&quot;705&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-25 á„‹á…©á„’á…® 5 31 03&quot; src=&quot;https://user-images.githubusercontent.com/48315997/103127996-f73f5280-46d6-11eb-9936-996a9ae0e84f.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ìš°ì„  DCGANì´ ê¸°ì¡´ì˜ GANê³¼ architecture ì¸¡ë©´ì—ì„œ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ì–´ë–»ê²Œ&lt;/code&gt; ë‹¬ëê¸°ì— í° ì„±ê³¼ë¥¼ ì´ë£° ìˆ˜ ìˆì—ˆëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;DCGANì´ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ì—ë„ CNNì„ ì´ìš©í•œ GANì„ ë§Œë“œëŠ” ì‹œë„ëŠ” ê³„ì† ìˆì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ì‹œë„ë“¤ì€ ëª¨ë‘ ì„±ê³µì ì´ì§€ ëª»í–ˆì£ .&lt;/p&gt;

&lt;p&gt;DCGANì€ &lt;strong&gt;CNN Architectureì—ì„œì˜ ìµœì‹  ë³€í™”(?) 3ê°€ì§€ë¥¼ ì ìš©&lt;/strong&gt;í•˜ì—¬ ì„±ê³µí•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;all-convolutional-net-ì‚¬ìš©&quot;&gt;All Convolutional Net ì‚¬ìš©&lt;/h3&gt;

&lt;p&gt;ìš°ì„  ê°€ì¥ í° ë³€í™”ì ì€ &lt;a href=&quot;https://arxiv.org/abs/1412.6806&quot;&gt;Striving for Simplicity: The All Convolutional Net&lt;/a&gt; ì„ ì°¸ê³ í•˜ì—¬ All Convoultional Netì„ ì‚¬ìš©í–ˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;All conv. netì€ &lt;strong&gt;pooling functions(ì˜ˆë¥¼ ë“¤ì–´, max pooling)ë¥¼ strided conv. ìœ¼ë¡œ ë°”ê¾¼ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°&lt;/strong&gt;ì…ë‹ˆë‹¤. Max poolingì€ ë¯¸ë¶„ë˜ì§€ ì•ŠëŠ” ì„±ì§ˆì„ ê°€ì§„ë‹¤ê³  í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ë¥¼ í†µí•´ Generatorì™€ Discriminator ëª¨ë‘ ìì‹ ë“¤ì˜ spatial downsamplingì„ í•™ìŠµí•˜ê¸°ì— ì í•©í•´ì§‘ë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;eliminating-fully-connected-layersfc-layers-on-top-of-convolutional-features&quot;&gt;Eliminating fully connected layers(FC layers) on top of convolutional features&lt;/h3&gt;

&lt;p&gt;ì´ ì‹œì  trendëŠ” ë§ˆì§€ë§‰ì— FC layerë¥¼ ì œê±°í•˜ê³ , &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;global average pooling&lt;/code&gt;ë¥¼ ì“°ëŠ” ë°©ì‹ì´ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë‹¤ë§Œ, ì´ global average poolingì€ &lt;strong&gt;ëª¨ë¸ì˜ ì•ˆì •ì„±ì€ ì˜¬ë¦¬ëŠ” ë°˜ë©´ì— convergence speedëŠ” ë–¨ì–´ëœ¨ë¦¬ëŠ”&lt;/strong&gt; trade-off ê´€ê³„ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;batch-norm--relu-activation&quot;&gt;Batch Norm &amp;amp; ReLU activation&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Batch Normalization&lt;/strong&gt;ëŠ” í•™ìŠµì„ ì•ˆì •í™”ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. (normalizing the input to each unit to have zero mean and unit variance)&lt;/p&gt;

&lt;p&gt;ì´ê²ƒì€ í•™ìŠµ ë¬¸ì œì  ì¤‘ í•˜ë‚˜ì¸ initializationê³¼ deep modelì˜ gradient flowì— í° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;í•˜ì§€ë§Œ, ëª¨ë“  layerì— BNì„ ì ìš©ì‹œí‚¤ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.&lt;/strong&gt; Generatorì˜ output layerì™€ Discriminatorì˜ input layerì—ëŠ” BNì„ ì ìš©ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë§ˆì§€ë§‰ìœ¼ë¡œ &lt;strong&gt;ReLUë¥¼ ì‚¬ìš©í–ˆë‹¤&lt;/strong&gt;ëŠ” ì ì´ ì–¸ê¸‰ë˜ì–´ ìˆëŠ”ë°, Generatorì™€ Discriminatorì— ì ìš©ë˜ëŠ” functionì´ ì•½ê°„ ë‹¤ë¦…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;Generatorì—ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ReLUë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, output layerì—ëŠ” ë”°ë¡œ ReLUê°€ ì•„ë‹Œ Tanh functionì„ ì ìš©ì‹œí‚µë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;Discriminatorì—ëŠ” Leaky ReLUë¥¼ ì ìš©í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;(ì—¬ëŸ¬ ì‹¤í—˜ ê²°ê³¼ ì´ functionsë“¤ì´ ì¢‹ì€ ì„±ëŠ¥ì„ ëƒˆê¸° ë•Œë¬¸ì´ê² ì£ ? í™•ì‹¤í•œ ì´ìœ , ë…¼ì¦ì€ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.)&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;details-of-adversarial-training&quot;&gt;DETAILS OF ADVERSARIAL TRAINING&lt;/h2&gt;

&lt;p&gt;DCGANì€ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LSUN, FACES, IMAGENET-1K&lt;/code&gt; ë°ì´í„°ì…‹ì— ëŒ€í•˜ì—¬ í•™ìŠµí•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;training setting(parameters, â€¦)ì— ëŒ€í•´ì„œëŠ” ë…¼ë¬¸ì„ ì°¸ê³ í•´ì£¼ì‹œê³ , ìœ„ ë°ì´í„°ì…‹ ì¤‘ LSUNì— ëŒ€í•´ì„œë§Œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤ :)&lt;/p&gt;

&lt;h3 id=&quot;lsun&quot;&gt;LSUN&lt;/h3&gt;

&lt;p&gt;LSUNì€ &lt;em&gt;Large-scale Scene Understanding&lt;/em&gt;ì˜ ì¤„ì„ë§ë¡œ, bedroom ì‚¬ì§„ë“¤ì„ ëª¨ì€ ë°ì´í„° ì…‹ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ë°ì´í„°ì…‹ì„ ê°€ì§€ê³  í•™ìŠµì‹œí‚¨ ëª¨ë¸ë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ëŠ” qualityê°€ ìƒë‹¹íˆ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;í•˜ì§€ë§Œ ì´ê²ƒì´ &lt;strong&gt;over-fittingì´ ë˜ì–´ ì´ë ‡ê²Œ ëœ ê²ƒì¸ì§€, í•™ìŠµ ë°ì´í„°ì…‹ì— ëŒ€í•˜ì—¬ ê¸°ì–µ(memorization)í•˜ì—¬ ë§Œë“¤ì–´ì§„ ê²ƒì¸ì§€&lt;/strong&gt;ì— ëŒ€í•´ íŒë³„í•´ë´ì•¼ í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;overfitting?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img width=&quot;700&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-25 á„‹á…©á„’á…® 5 45 38&quot; src=&quot;https://user-images.githubusercontent.com/48315997/103128506-00c9ba00-46d9-11eb-8b7a-e144208bbfe8.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ë³¸ ë…¼ë¬¸ì˜ Fig.2 ì™€ Fig.3ì„ í†µí•´ ëª¨ë¸ì´ ì˜¤íˆë ¤ &lt;strong&gt;underfitting&lt;/strong&gt; ë˜ì–´ìˆìŒì„ ì–˜ê¸°í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;underfittingì´ ì´ë£¨ì–´ì¡Œë‹¤ê³  ì—¬ê¸°ëŠ” ì´ìœ ëŠ” ì•„ì§ noise textureê°€ ëˆˆì— ë³´ì´ê¸° ë•Œë¬¸ì´ë¼ê³  í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(ì—„ì²­ ê°€ê¹Œì´ ë³´ì§€ ì•ŠëŠ” ì´ìƒì€ ì˜ ëŠë¼ì§€ ëª»í•˜ê² ëŠ”ë° ë§ì´ì£ .)&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;memorization?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ì‚¬ì‹¤ ì´ê²Œ ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œ generate í•˜ëŠ” imageê°€ ì‚¬ì‹¤ í•™ìŠµ ë°ì´í„°ì—ì„œ ê¸°ì–µ(memorize)í•˜ì—¬ ë§Œë“¤ì–´ì§„ ê²ƒì´ë¼ë©´, &lt;strong&gt;ì§„ì •í•œ ì˜ë¯¸ì˜ Generateê°€ ì•„ë‹ˆë‹ˆê¹ìš”.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ì´ì— ëŒ€í•´ì„œ ë³¸ ë…¼ë¬¸ì˜ ì €ìë“¤ì€ memorizeí•˜ëŠ” ê°€ëŠ¥ì„±ì„ ì¤„ì´ê¸° ìœ„í•´ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;image de-duplication process&lt;/code&gt;(ì¤‘ë³µ ì œê±° í”„ë¡œì„¸ìŠ¤)ë¥¼ ê±°ì¹©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;de-duplicationì„ í•˜ê¸° ìœ„í•´ autoencoderë¥¼ í•˜ë‚˜ ë§Œë“­ë‹ˆë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We fit a 3072-128-3072 de-noising dropout regularized RELU autoencoder on 32x32 downsampled center-crops of training examples.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;empirical-validation-of-dcgans-capabilities&quot;&gt;EMPIRICAL VALIDATION OF DCGANs CAPABILITIES&lt;/h2&gt;

&lt;p&gt;ë§¨ ì²˜ìŒì— ì´ ë…¼ë¬¸ì˜ contributions ì¤‘ í•˜ë‚˜ë¡œ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;í•™ìŠµëœ DiscriminatorëŠ” image classification íƒœìŠ¤í¬ì— ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤&lt;/code&gt; ë¼ê³  ì–˜ê¸°í–ˆì—ˆì£ ?&lt;/p&gt;

&lt;p&gt;ì´ ëª©ì°¨ì—ì„œëŠ” ì •ë§ DCGANì´ &lt;strong&gt;feature extractor&lt;/strong&gt;ë¡œì¨ì˜ ì—­í• ì´ ê°€ëŠ¥í•œê°€, ê·¸ë˜ì„œ CIFAR-10 ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œë„ &lt;strong&gt;classification task&lt;/strong&gt;ë¥¼ ì˜ ìˆ˜í–‰í•˜ëŠ”ê°€ë¥¼ í™•ì¸í•´ë´…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;696&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-25 á„‹á…©á„’á…® 6 03 36&quot; src=&quot;https://user-images.githubusercontent.com/48315997/103129277-8484a600-46db-11eb-9e0f-de26d03694d4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê²°ë¡ ì ìœ¼ë¡œ, ë‹¤ë¥¸ unsupervised ì•Œê³ ë¦¬ì¦˜ì€ K-means modelë“¤ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. (Exemplar CNN ëª¨ë¸ë³´ë‹¤ëŠ” ì¢€ ëª» ë¯¸ì¹˜ì§€ë§Œìš”.)&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;542&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-25 á„‹á…©á„’á…® 6 05 55&quot; src=&quot;https://user-images.githubusercontent.com/48315997/103129364-d6c5c700-46db-11eb-8f7b-388b5ae3128b.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì¶”ê°€ì ìœ¼ë¡œ SVHN Digits ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œë„ ì‹¤í—˜ì„ í•´ë³´ì•˜ìŠµë‹ˆë‹¤. test error ì¸¡ë©´ì—ì„œ SOTAë¥¼ ë‹¬ì„±í•˜ëŠ” ì¾Œê±°ë¥¼ ì´ë£¨ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;investigating-and-visualizing-the-internals-of-the-networks&quot;&gt;INVESTIGATING AND VISUALIZING THE INTERNALS Of THE NETWORKS&lt;/h2&gt;

&lt;p&gt;ë˜ ë‹¤ë¥¸ contributionsìœ¼ë¡œ  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GANì´ í•™ìŠµí•œ filtersë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆê³ , íŠ¹ì • ì˜¤ë¸Œì íŠ¸ì— ëŒ€í•´ íŠ¹ì • filterë¥¼ í•™ìŠµí–ˆë‹¤ëŠ” ì ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆë‹¤&lt;/code&gt; ì™€ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GeneratorëŠ” vector arithmetic propertiesë¥¼ ê°€ì§€ê³  ìˆë‹¤&lt;/code&gt; ê°€ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ëª©ì°¨ì—ì„œëŠ” ë‘ ë¶€ë¶„ì— ëŒ€í•´ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;walking-in-the-latent-space&quot;&gt;Walking in the Latent Space&lt;/h3&gt;

&lt;p&gt;latent spaceë¥¼ ë³€ê²½í–ˆì„ ë•Œ sharp transitions(ê¸‰ì‘ìŠ¤ëŸ¬ìš´ ë³€í™”)ê°€ ìˆìœ¼ë©´ ì´ëŠ” &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;memorization&lt;/code&gt;ì´ ì¼ì–´ë‚¬ë‹¤ëŠ” ì‹ í˜¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë°˜ëŒ€ë¡œ ë¶€ë“œëŸ¬ìš´ ë³€í™”ê°€ ì¼ì–´ë‚˜ë©´ memorizationì´ ëœ ê²ƒì´ ì•„ë‹ˆë¼ ì œëŒ€ë¡œ í•™ìŠµì´ ë˜ì—ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆì£ .&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/103134579-83607280-46f5-11eb-800b-b4d5ea21bdad.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ìœ„ì˜ ì‚¬ì§„ì„ ë³´ì‹œë©´ DCGANì˜ ê²½ìš° sharp transitionì´ ì•„ë‹Œ smoothí•œ ë³€í™”ê°€ ì´ë£¨ì–´ì¡ŒìŒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;visualizing-the-discriminator-features&quot;&gt;Visualizing the Discriminator Features&lt;/h3&gt;

&lt;p&gt;ì´ ë‚´ìš©ì—ì„œëŠ” Guided backpropagationì„ í†µí•´ GANì´ í•™ìŠµí•œ filtersë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;696&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-25 á„‹á…©á„’á…® 9 17 38&quot; src=&quot;https://user-images.githubusercontent.com/48315997/103134734-9f184880-46f6-11eb-9639-d0eb9878e74a.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;discriminatorê°€ featureë“¤ì„ í•™ìŠµí•´ì„œ, íŠ¹ì • íŒŒíŠ¸(bed, windows,â€¦)ë“¤ì— ëŒ€í•˜ì—¬ active í•˜ê³  ìˆìŒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;manipulating-the-generator-representation&quot;&gt;Manipulating the Generator Representation&lt;/h3&gt;

&lt;h4 id=&quot;forgetting-to-draw-certain-objects&quot;&gt;Forgetting to Draw Certain Objects&lt;/h4&gt;

&lt;p&gt;ì´ê±´ ë§¤ìš° ì¬ë¯¸ìˆëŠ” ì‹¤í—˜ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ê°„ë‹¨í•˜ê²Œ ìš”ì•½í•˜ìë©´, Generatorê°€ ë¬´ìŠ¨ representationì„ í•™ìŠµí–ˆëŠ”ì§€ ì•Œì•„ë³´ê¸° ìœ„í•˜ì—¬ íŠ¹ì • filter(ì—¬ê¸°ì„œëŠ” window filter)ë¥¼ ì‚­ì œí•´ë´…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì¦‰, Windowë¼ëŠ” objectë¥¼ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Forget&lt;/code&gt; í•˜ê²Œ ë˜ëŠ” ê²ƒì´ì£ .(ê¸°ìˆ ì ìœ¼ë¡œëŠ” window filterë¥¼ dropout ì‹œí‚¨ë‹¤ê³  ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)&lt;/p&gt;

&lt;p&gt;ê²°ê³¼ì ìœ¼ë¡œ ì´ ì‹¤í—˜ì—ì„œëŠ” ì°½ë¬¸ì´ ì•„ë‹Œ ë‹¤ë¥¸ representations, objectsê°€ ë“¤ì–´ê°€ê²Œ ë©ë‹ˆë‹¤!&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;684&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-25 á„‹á…©á„’á…® 9 22 03&quot; src=&quot;https://user-images.githubusercontent.com/48315997/103134811-3da4a980-46f7-11eb-8d95-b990a0a18601.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ìœ„ì˜ ê²°ê³¼ë¥¼ ë³´ë©´ ì•„ì‹œë‹¤ì‹œí”¼, ì°½ë¬¸ì´ì—ˆë˜ ê²ƒì´ ë¬¸ìœ¼ë¡œ ë°”ë€ŒëŠ” ë“± ë‹¤ë¥¸ objectë¥¼ ìƒì„±í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;h4 id=&quot;vector-arithmetic-on-face-samples&quot;&gt;Vector Arithmetic On Face Samples&lt;/h4&gt;

&lt;p&gt;ë§ì€ ë¶„ë“¤ì´ ê°€ì¥ ì¬ë°Œì–´í•˜ì‹¤(?) ë¶€ë¶„ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;word embedding ê´€ë ¨í•´ì„œ vector(â€œKingâ€) - vector(â€œManâ€) + vector(â€œWomanâ€)ê°€ vector(â€œQueenâ€)ì˜ ê²°ê³¼ê°€ ë‚˜ì˜¤ë“¯ì´, DCGANì—ì„œë„ ì´ì™€ ë¹„ìŠ·í•œ &lt;strong&gt;arithmeticí•œ ì—°ì‚°ì´ ê°€ëŠ¥í•˜ë‹¤&lt;/strong&gt;ê³  ë°í˜”ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;Generatorì˜ inputì¸ Z vectorì— ëŒ€í•œ arithmetic operationì„ í•˜ëŠ”ë°, single sampleë¡œëŠ” ë¶ˆì•ˆì •í•˜ì—¬ 3ê°œì˜ Z vectorë¥¼ í‰ê· í•œ ê°’ì„ ì‚¬ìš©í•œë‹¤ê³  í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;580&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-25 á„‹á…©á„’á…® 9 36 16&quot; src=&quot;https://user-images.githubusercontent.com/48315997/103135086-3a122200-46f9-11eb-931d-7d737e8c5ed1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;smiling woman - neutral woman + neutral man = smiling man ì´ë¯¸ì§€ê°€ ë§Œë“¤ì–´ì§€ëŠ” ë§ˆë²•ê°™ì€ ê¸°ìˆ ì„ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì•ì„œ ë§í–ˆë‹¤ì‹œí”¼ 3ê°œì˜ Z vectorë¥¼ averageí•˜ì—¬ ìƒˆë¡œìš´ Yë²¡í„°ë¥¼ ë§Œë“  ê²ƒë„ í™•ì¸í•´ë³¼ ìˆ˜ ìˆì£ .&lt;/p&gt;

&lt;p&gt;ì´ê²Œ ë‹¤ê°€ ì•„ë‹™ë‹ˆë‹¤. &lt;strong&gt;face pose&lt;/strong&gt; ë˜í•œ Z spaceì— ì„ í˜•ì ìœ¼ë¡œ ëª¨ë¸ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;557&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-25 á„‹á…©á„’á…® 9 38 01&quot; src=&quot;https://user-images.githubusercontent.com/48315997/103135120-780f4600-46f9-11eb-8d7e-8d723c10e439.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ë°”ë¡œ ì´ë ‡ê²Œ ë§ì´ì£ . 
ì´ë¯¸ ì´ì „ë¶€í„° scale, rotation, positionì— ëŒ€í•˜ì—¬ conditional generative modelì€ í•™ìŠµí•  ìˆ˜ ìˆë‹¤ê³  ì—°êµ¬ë˜ì–´ì™”ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ì—°êµ¬ëŠ” &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;purely unsupervised model&lt;/code&gt; ì´ë¼ëŠ” ì ì—ì„œ í° ë³€í™˜ì ì´ ëœ ê²ƒì´ì£ .&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;future-work&quot;&gt;FUTURE WORK&lt;/h2&gt;

&lt;p&gt;ì‚¬ì‹¤ stablityë¥¼ ì™„ì „íˆ í•´ê²°í•œ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;DCGANì„ ì˜¤ë«ë™ì•ˆ í•™ìŠµí•˜ê²Œ ë˜ë©´ collapse mode, oscillating modeê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ì§ë„ &lt;strong&gt;ë¶ˆì•ˆì •ì„±&lt;/strong&gt;ì´ ë‚¨ì€ ê²ƒì´ì£ .&lt;/p&gt;

&lt;p&gt;ê·¸ë˜ì„œ ì´ ë…¼ë¬¸ì—ì„œëŠ” í•´ë‹¹ ë¬¸ì œì ì„ Future workë¡œ ë‚¨ê¸°ê³  ë§ˆë¬´ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html_&quot;&gt;Jaejun Yooâ€™s Playground&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;DCGANë„ ì½ì—ˆìœ¼ë‹ˆ, êµ¬í˜„ë„ í•´ë³´ê³  í›„ì† ë…¼ë¬¸ë“¤ë„ ì°¬ì°¬íˆ ì½ì–´ë³´ë ¤ê³  í•©ë‹ˆë‹¤.
ê¸´ ê¸€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤ :)&lt;/p&gt;</content><author><name>Yeonsoo Kim</name></author><category term="Deep Learning" /><category term="GAN" /><summary type="html">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)ì„ ì½ê³  ê°œì¸ì ìœ¼ë¡œ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.</summary></entry><entry><title type="html">Unsupervised Intra-domain Adaptation for Semantic Segmentation</title><link href="http://localhost:4000/paper%20review/2020/12/22/intraDA/" rel="alternate" type="text/html" title="Unsupervised Intra-domain Adaptation for Semantic Segmentation" /><published>2020-12-22T00:00:00+09:00</published><updated>2020-12-22T00:00:00+09:00</updated><id>http://localhost:4000/paper%20review/2020/12/22/intraDA</id><content type="html" xml:base="http://localhost:4000/paper%20review/2020/12/22/intraDA/">&lt;p&gt;Unsupervised Intra-domain Adaptation for Semantic Segmentation ì„ ì½ê³  ê°„ëµí•˜ê²Œ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;unsupervised-intra-domain-adaptation-for-semantic-segmentation&quot;&gt;Unsupervised Intra-domain Adaptation for Semantic Segmentation&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;automatically annotated data&lt;/code&gt; has a problem.
    &lt;ul&gt;
      &lt;li&gt;synthetic data -&amp;gt; real data&lt;/li&gt;
      &lt;li&gt;directly adapting models from the source data to the unlabeled target data (to reduce the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;inter-domain gap&lt;/code&gt;)&lt;/li&gt;
      &lt;li&gt;But result? ==&amp;gt; bad :(
        &lt;ul&gt;
          &lt;li&gt;there is the large distribution gap among the target data itself(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;intra-domain gap&lt;/code&gt;)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;approach&quot;&gt;Approach&lt;/h2&gt;

&lt;p&gt;&lt;img width=&quot;300&quot; src=&quot;https://user-images.githubusercontent.com/48315997/102793576-7984f980-43ed-11eb-8cbe-ca0d2986d14e.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;595&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-22 á„‹á…©á„Œá…¥á†« 12 44 17&quot; src=&quot;https://user-images.githubusercontent.com/48315997/102794504-d3d28a00-43ee-11eb-9b61-4eb50fde5d1d.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;two-step self-supervised domain adaptation approach to minimize the inter-domain and intra-domain gap together.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;dl&gt;
      &lt;dt&gt;inter-domain gap&lt;/dt&gt;
      &lt;dd&gt;separate the target domain into an easy &amp;amp; hard split (using entropy-based ranking function)&lt;/dd&gt;
    &lt;/dl&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;dl&gt;
      &lt;dt&gt;intra-domain gap&lt;/dt&gt;
      &lt;dd&gt;self-supervised adaption from the easy to hard split&lt;/dd&gt;
    &lt;/dl&gt;
    &lt;ul&gt;
      &lt;li&gt;segmentation predictions of easy split data (from G_inter) =&amp;gt; pseudo labels ë¡œ ì‚¬ìš©&lt;/li&gt;
      &lt;li&gt;Given easy split data &amp;amp; pseudo labels, hard split data =&amp;gt; D_intraëŠ” easy? hard? íŒë³„&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;p&gt;&lt;img width=&quot;698&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-22 á„‹á…©á„Œá…¥á†« 12 46 37&quot; src=&quot;https://user-images.githubusercontent.com/48315997/102794749-26ac4180-43ef-11eb-853c-45c2e9a5cfd4.png&quot; /&gt;&lt;/p&gt;</content><author><name>Yeonsoo Kim</name></author><category term="Deep Learning" /><category term="Domain Adaptation" /><category term="GAN" /><category term="Semantic Segmentation" /><summary type="html">Unsupervised Intra-domain Adaptation for Semantic Segmentation ì„ ì½ê³  ê°„ëµí•˜ê²Œ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.</summary></entry><entry><title type="html">Multimodal Unsupervised Image-to-Image Translation (MUNIT)</title><link href="http://localhost:4000/paper%20review/2020/12/22/MUNIT/" rel="alternate" type="text/html" title="Multimodal Unsupervised Image-to-Image Translation (MUNIT)" /><published>2020-12-22T00:00:00+09:00</published><updated>2020-12-22T00:00:00+09:00</updated><id>http://localhost:4000/paper%20review/2020/12/22/MUNIT</id><content type="html" xml:base="http://localhost:4000/paper%20review/2020/12/22/MUNIT/">&lt;p&gt;Multimodal Unsupervised Image-to-Image Translation (MUNIT) ì„ ì½ê³  ê°„ëµí•˜ê²Œ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;multimodal-unsupervised-image-to-image-translation-munit&quot;&gt;Multimodal Unsupervised Image-to-Image Translation (MUNIT)&lt;/h1&gt;

&lt;h2 id=&quot;keywords--gan-image-to-image-translation-style-transfer&quot;&gt;Keywords : GAN, Image-to-Image translation, style transfer&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;image representation = content code + style code
    &lt;ul&gt;
      &lt;li&gt;content code : domain invariant&lt;/li&gt;
      &lt;li&gt;style code : domain specific&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img width=&quot;657&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-22 á„‹á…©á„Œá…¥á†« 12 14 37&quot; src=&quot;https://user-images.githubusercontent.com/48315997/102791653-adaaeb00-43ea-11eb-9dd6-fc7d4e6c6e6e.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Image Translation == Recombine its content code with a random style code
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;random style code&lt;/code&gt; : style space of the target domain&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img width=&quot;651&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-22 á„‹á…©á„Œá…¥á†« 12 14 23&quot; src=&quot;https://user-images.githubusercontent.com/48315997/102791642-a5eb4680-43ea-11eb-8ea5-8af9ebc97f17.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;auto-encoder-architecture&quot;&gt;Auto-encoder Architecture&lt;/h3&gt;

&lt;p&gt;&lt;img width=&quot;624&quot; alt=&quot;á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-12-22 á„‹á…©á„Œá…¥á†« 12 19 33&quot; src=&quot;https://user-images.githubusercontent.com/48315997/102792116-61ac7600-43eb-11eb-8a7b-3f4cc735c0f1.png&quot; /&gt;&lt;/p&gt;</content><author><name>Yeonsoo Kim</name></author><category term="Deep Learning" /><category term="GAN" /><category term="Domain Adaptation" /><category term="Style Transfer" /><category term="Image-to-Image Translation" /><summary type="html">Multimodal Unsupervised Image-to-Image Translation (MUNIT) ì„ ì½ê³  ê°„ëµí•˜ê²Œ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.</summary></entry></feed>