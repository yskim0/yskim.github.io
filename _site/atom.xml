<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-09-20T19:35:18+09:00</updated><id>http://localhost:4000/atom.xml</id><title type="html">Yeonsoo Kim’s blog</title><author><name>Yeonsoo Kim</name></author><entry><title type="html">StyleGAN:A Style-Based Generator Architecture for Generative Adversarial Networks</title><link href="http://localhost:4000/paper%20review/2020/09/20/StyleGAN/" rel="alternate" type="text/html" title="StyleGAN:A Style-Based Generator Architecture for Generative Adversarial Networks" /><published>2020-09-20T00:00:00+09:00</published><updated>2020-09-20T00:00:00+09:00</updated><id>http://localhost:4000/paper%20review/2020/09/20/StyleGAN</id><content type="html" xml:base="http://localhost:4000/paper%20review/2020/09/20/StyleGAN/">&lt;p&gt;StyleGAN : A Style-Based Generator Architecture for Generative Adversarial Networks 를 읽고 정리한 글입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;stylegan--a-style-based-generator-architecture-for-generative-adversarial-networks-cvpr-2019&quot;&gt;StyleGAN : A Style-Based Generator Architecture for Generative Adversarial Networks (CVPR 2019)&lt;/h1&gt;

&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;GAN의 generator 부분은 black box로 여겨져 이미지 생성 과정을 이해하기 어려웠음.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;style transfer&lt;/code&gt; 에서 기반한 generator 구조
    &lt;ul&gt;
      &lt;li&gt;각 레이어마다 style의 정보를 입힘. -&amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AdaIN&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;전체적인 스타일(머리 색, 인종, 성별 등), 세세한 부분(곱슬 등) 등까지 조정 가능 -&amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;noise&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;baseline : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;progressive GAN&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;latent vector로 부터 이미지 합성하고 점점 해상도를 올려서 high-resolution image 생성 =&amp;gt; scale-specific control&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;loss function, discriminator 등 수정하지 않고 오직 제너레이터에 대해서만 다룸.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;latent space의 interpolation quality 측정하는 measure 제안
    &lt;ul&gt;
      &lt;li&gt;perceptual path length&lt;/li&gt;
      &lt;li&gt;linear separability&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;FFHQ 데이터셋 오픈&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;related-work-basic-concepts&quot;&gt;Related work (Basic concepts)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Progressive GAN
    &lt;ul&gt;
      &lt;li&gt;GAN을 저해상도에서 고해상도로 점진적으로 학습&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;style transfer
    &lt;ul&gt;
      &lt;li&gt;content image &amp;amp; style image가 있을 때 content 이미지와 유사하게 style image에 입히는 것&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;methods&quot;&gt;Methods&lt;/h2&gt;
&lt;p&gt;(Explain one of the methods that the thesis used.)&lt;/p&gt;

&lt;h3 id=&quot;generator-architecture&quot;&gt;Generator Architecture&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/93662640-90d5e300-fa9c-11ea-9a36-7312a058879d.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;left : traditional generaotr : latent code &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z&lt;/code&gt;를 input layer에 바로 넣음.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;right : &lt;strong&gt;style-based generator&lt;/strong&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;first, map the input to an intermediate latent space &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;W&lt;/code&gt;.&lt;/li&gt;
      &lt;li&gt;then controls the generator through &lt;strong&gt;adaptive instance normalization (AdaIN)&lt;/strong&gt; at each conv. layer.&lt;/li&gt;
      &lt;li&gt;Gaussian noise is added after each conv.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;제안한 모델을 차근차근 뜯어보자면&lt;/p&gt;

&lt;h4 id=&quot;mapping-network&quot;&gt;Mapping Network&lt;/h4&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/0*6lEwRXKiA8WGRlEc.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;input vector &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z&lt;/code&gt;를 바로 input layer에 넣는 것이 아니라, mapping network를 거쳐 &lt;strong&gt;intermediate vector &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;w&lt;/code&gt;&lt;/strong&gt; 로 변환한 후 이미지를 생성한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;바로 인풋 레이어에 넣지 않는 이유 : 고정된 input distribution에 맞춰야 해서 non-linear하게 mapping이 되고, 이것은 머리 색등과 같은 attribute를 변경하기 힘들어지기 때문.&lt;/li&gt;
  &lt;li&gt;위처럼 intermediate vector를 사용하게 되면 유동적인 공간에 mapping 시킬 수 있기 때문에 visual attribute 조절이 쉬워진다. =&amp;gt; &lt;strong&gt;disentanglement&lt;/strong&gt; 하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;즉, 이 네트워크에서는 z로부터 만들어진 style &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;w&lt;/code&gt;를 구하고, 이를 affine transformation을 거친 A를 synthesis network에 넘겨주어 AdaIN operation을 통해 레이어에 스타일을 입힌다.&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;style-modules-adain&quot;&gt;Style Modules (AdaIN)&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/0*uqn4slMHrFYkFmjS.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/93665356-c4bb0380-fab0-11ea-844d-348f19fc4e2f.png&quot; alt=&quot;스크린샷 2020-09-19 오후 7 46 09&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;위에서 생성된 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;w&lt;/code&gt;는 style에 대한 정보를 가지고 있다.&lt;/li&gt;
  &lt;li&gt;Synthesis network는 학습가능한 constant tensor(4x4x512)를 &lt;strong&gt;upsampling, convolution&lt;/strong&gt;을 통해 1024x1024x3 이미지로 변환시킨다.&lt;/li&gt;
  &lt;li&gt;w의 affine transfomation을 통해 얻어진 A를 가지고 &lt;strong&gt;AdaIN operation&lt;/strong&gt;을 통해 스타일을 입힌다.
    &lt;ul&gt;
      &lt;li&gt;normalize하고, 이를 scale하고 bias를 더함. 이게 스타일을 입히는 효과를 낸다.&lt;/li&gt;
      &lt;li&gt;매 conv 레이어마다 하므로, 각각의 레이어마다 다른 스타일을 조정할 수 있다. 이 말은 곧, 각 레이어가 특정한 attribute만을 담당한다는 뜻.
        &lt;ul&gt;
          &lt;li&gt;세밀한 스타일 조정 가능해진다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;stochastic-variation&quot;&gt;Stochastic variation&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://bloglunit.files.wordpress.com/2019/02/1_gwchaliormc1xlj7bh0zmg.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*GwchALioRMC1xlj7Bh0ZMg.png&quot; alt=&quot;스크린샷 2020-09-19 오후 7 48 31&quot; /&gt;&lt;/p&gt;

&lt;p&gt;머리카락, 수염 등 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stochastic&lt;/code&gt;한 요소들은 사진의 디테일에 매우 중요함.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;위의 architecture에서 noise가 이에 대한 역할을 한다.&lt;/li&gt;
  &lt;li&gt;synthesis network에서 &lt;strong&gt;by adding per-pixel noise after each convolution.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;style-mixing&quot;&gt;Style Mixing&lt;/h3&gt;

&lt;p&gt;two random latent codes(w1,w2)를 사용하는 regularization 기법&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;하나의 w로 학습할 경우 여러 레이어에 대한 style이 correlate되는 문제점이 생길 수 있음.&lt;/li&gt;
  &lt;li&gt;ex. w1 스타일로 입혀놓지만, 랜덤으로 몇 개는 w2 스타일을 사용한다 …&lt;/li&gt;
  &lt;li&gt;위와 같은 방법을 통해 각 레이어가 담당하는 스타일을 명확하게 구분지을 수 있다.&lt;/li&gt;
  &lt;li&gt;(dropout과 비슷한 원리라고 함)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;disentanglement-studies&quot;&gt;Disentanglement studies&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;이 내용이 어려워서 제대로 이해하지 못함. 짧게 요약하겠음.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/93665682-7c511500-fab3-11ea-8333-be0512370654.png&quot; alt=&quot;스크린샷 2020-09-19 오후 8 05 35&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Disentanglment : latent space가 선형적인 구조를 가지게 되어, 하나의 factor가 움직였을 때 정해진 특성이 바뀌게 만드는 것.
    &lt;ul&gt;
      &lt;li&gt;예. z의 특정한 값을 바꿨을 때 생성되는 이미지의 하나의 특성(성별, 머리카락 길이 등)만 영향을 주게 되는 것&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;fixed distribution을 따르게 되면 억지로 끼워맞추게 되어 어색한 이미지가 만들어질 수 있음.&lt;/li&gt;
  &lt;li&gt;하지만 이 모델처럼 &lt;strong&gt;비선형 mapping function&lt;/strong&gt;을 가지게 될 경우, 고정된 분포를 따를 필요가 없음.
    &lt;ul&gt;
      &lt;li&gt;위 그림에서 (c)와 같은 형태가 됨. 어느정도 a와 생김새가 비슷하면서 자연스럽게 맞출 수 있게 된 것&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;A major beneﬁt of our generator architecture is that the intermediate latent space W does not have to support sam-pling according to any ﬁxed distribution; its sampling density is induced by the learned piecewise continuous mapping f(z).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;본 논문에서는 disentanglement를 학습할 수 있는 두 가지 평가 지표를 제안함.
    &lt;ul&gt;
      &lt;li&gt;Perceptual path length&lt;/li&gt;
      &lt;li&gt;Linear seperability&lt;/li&gt;
      &lt;li&gt;위의 내용을 자세히 알고 싶다면 이 곳을 참조
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://jayhey.github.io/deep%20learning/2019/01/16/style_based_GAN_2/#perceptual-path-length&quot;&gt;링크&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;our investigations to &lt;strong&gt;the separation of high-level attributes and stochastic effects&lt;/strong&gt;, as well as &lt;strong&gt;the linearity of the intermediate latent space&lt;/strong&gt; will prove fruitful in improving the understanding and controllability of GAN synthesis.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;appendix-truncation-trick-in-w&quot;&gt;Appendix. Truncation trick in W&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;트레이닝 중에 하는 게 아니고, generator가 만든 것 중에 더 나은 latent space 을 뽑는 법에 대한 trick&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;학습이 완료된 네트워크의 input을 제어하는 방법&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/93665586-81fa2b00-fab2-11ea-858c-69a2f3ea5026.png&quot; alt=&quot;스크린샷 2020-09-19 오후 7 58 35&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 수식을 통한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;w'&lt;/code&gt; vector를 뽑는다.&lt;/p&gt;

&lt;h2 id=&quot;additional-studies&quot;&gt;Additional studies&lt;/h2&gt;
&lt;p&gt;(If you have some parts that cannot understand, you have to do additional studies for them. It’s optional.)&lt;/p&gt;

&lt;p&gt;disentanglement에 대한 명확한 이해가 필요함.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;p&gt;(References for your additional studies)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;https://www.youtube.com/watch?v=TWzEbMrH59o&amp;amp;feature=youtu.be&lt;/li&gt;
  &lt;li&gt;https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431&lt;/li&gt;
  &lt;li&gt;https://jayhey.github.io/deep%20learning/2019/01/16/style_based_GAN_2/&lt;/li&gt;
  &lt;li&gt;https://blog.lunit.io/2019/02/25/a-style-based-generator-architecture-for-generative-adversarial-networks/&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Yeonsoo Kim</name></author><category term="Deep Learning" /><category term="Computer Vision" /><category term="GAN" /><category term="Generative Model" /><summary type="html">StyleGAN : A Style-Based Generator Architecture for Generative Adversarial Networks 를 읽고 정리한 글입니다.</summary></entry><entry><title type="html">HarDNet:A Low Memory Traffic network</title><link href="http://localhost:4000/paper%20review/2020/09/11/HarDNet/" rel="alternate" type="text/html" title="HarDNet:A Low Memory Traffic network" /><published>2020-09-11T00:00:00+09:00</published><updated>2020-09-11T00:00:00+09:00</updated><id>http://localhost:4000/paper%20review/2020/09/11/HarDNet</id><content type="html" xml:base="http://localhost:4000/paper%20review/2020/09/11/HarDNet/">&lt;p&gt;HarDNet : A Low Memory Traffic network 를 읽고 개인적으로 정리한 글입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;hardnet--a-low-memory-traffic-network-iccv-2019&quot;&gt;HarDNet : A Low Memory Traffic network (ICCV 2019)&lt;/h1&gt;

&lt;h2 id=&quot;key-idea&quot;&gt;Key Idea&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;기존의 metrics들에서의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;inference time&lt;/code&gt; 측정은 부정확하다.
    &lt;ul&gt;
      &lt;li&gt;새로운 metric =&amp;gt; &lt;strong&gt;memory traffic for accessing intermediate feature maps 측정&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;inference latency 측정에 유용할 것, especially in such tasks as &lt;em&gt;real-time object detection and semantic segmentation of high-resolution video.&lt;/em&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CIO&lt;/code&gt; : approximation of DRAM traffic이 될 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;computation, energy efficiency를 위해서는 fewer MACs, less DRAM이 좋은 것임&lt;/strong&gt; -&amp;gt; 연구 방향&lt;/li&gt;
  &lt;li&gt;각각의 레이어의 MoC에 soft constraint를 적용했음.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;low CIO network model&lt;/strong&gt; with a reasonable increase of MACs를 위해&lt;/li&gt;
      &lt;li&gt;방법 -&amp;gt; &lt;strong&gt;avoid&lt;/strong&gt; to employ a layer with a &lt;strong&gt;very low MoC such as a Conv1x1 layer&lt;/strong&gt; that has a &lt;strong&gt;very large input/output channel ratio.&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;input/output channel ratio가 크면 low MoC를 가진다는 사실을 알 수 있음.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Densely Connected Networks에 영감을 받아 모델 빌딩함.
    &lt;ol&gt;
      &lt;li&gt;DenseNet의 &lt;strong&gt;다수의 layer connections들을 줄였음.&lt;/strong&gt; =&amp;gt; concatenation cost를 줄이기 위해&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;balance the input/output channel ratio by increasing the channel width&lt;/strong&gt; of a layer according to its connections.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img width=&quot;659&quot; alt=&quot;스크린샷 2020-09-11 오후 9 30 55&quot; src=&quot;https://user-images.githubusercontent.com/48315997/92925832-14c51500-f476-11ea-93c3-6183adffd2e5.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;DRAM traffic&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;basic-concepts&quot;&gt;Basic Concepts&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;MAC : number of multiply-accumulate operations or floating point operations&lt;/li&gt;
  &lt;li&gt;DRAM : Dynamic Random-Access Memory
    &lt;ul&gt;
      &lt;li&gt;read/write model param. and feature maps&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CIO : Convolutional input/output
    &lt;ul&gt;
      &lt;li&gt;모든 conv layer에 대해 IN(C,W,H) X OUT(C,W,H) sum
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/92923605-b185b380-f472-11ea-81cc-a6d37d9bdd6c.png&quot; alt=&quot;image&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MoC : MACs over CIO of a layer = MACs/CIO&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;related-works&quot;&gt;Related Works&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;TREND : exploiting shortcuts&lt;/li&gt;
  &lt;li&gt;Highway networks, Residual Networks : add shortcuts to sum up a layer with multiple preceeding layers.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DenseNet&lt;/code&gt;&lt;/strong&gt; : &lt;strong&gt;concatenates all preceeding layers as a shortcut&lt;/strong&gt; achieving more efficent deep supervision.&lt;/li&gt;
  &lt;li&gt;그러나 shortcuts는 large memory usage, heavy DRAM traffic을 유발할 수 있다.
    &lt;ul&gt;
      &lt;li&gt;
        &lt;blockquote&gt;
          &lt;p&gt;Using shortcuts elongates the lifetime of a tensor, which may result in frequent data exchanges betwwen DRAM and cache.&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;DenseNet의 sparsified version : &lt;em&gt;LogDenseNet, SparseNet&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Sparse&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;The pros?&lt;/strong&gt; If you have a lot of zeros, &lt;strong&gt;you don’t have to compute some multiplications, and you don’t have to store them&lt;/strong&gt;. So you &lt;strong&gt;&lt;em&gt;may&lt;/em&gt;&lt;/strong&gt; gain on size and speed, for training and inference (more on this today).&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;The cons?&lt;/strong&gt; Of course, having all these zeros will probably have an impact on network accuracy/performance.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;increase the &lt;strong&gt;growth rate(output channel width) to recover the accuracy dropping from the connection pruning,&lt;/strong&gt; and the increase of growth rate &lt;strong&gt;can compromise the CIO reduction&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;즉 increase of growth rate는 좋게 작용된다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;harmonic-densenet&quot;&gt;Harmonic DenseNet&lt;/h2&gt;

&lt;h3 id=&quot;sparsification-and-weighting&quot;&gt;Sparsification and weighting&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;let layer &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt; connect to layer &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k-2^n&lt;/code&gt; if 2^n divides k, where n is a non-negative integer and&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt; k-2^n &amp;gt;= 0&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HarDBlock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_link&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_ch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;growth_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_ch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;growth_rate&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;dv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dv&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grmul&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_link&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_ch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;growth_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;2^n 개의 layer들이 이런 식으로 processed되면 layer [1 : 2^n -1]는 메모리에서 flush된다.&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;어떻게 flush 된다는 건지 잘 이해가 되지 않음.&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Power-of-two-th harmonic waves가 만들어짐. 그래서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Harmonic&lt;/code&gt; 이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img width=&quot;461&quot; alt=&quot;스크린샷 2020-09-11 오후 9 52 09&quot; src=&quot;https://user-images.githubusercontent.com/48315997/92927733-0cbaa480-f479-11ea-8194-3567f8ae83f1.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;이 방식은 concatenation cost를 눈에 띄게 감소시킨다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;layers with an index divided by a larger power of two are more influential&lt;/strong&gt; than those that divided by a smaller power of two.&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;많이 connection되니까 당연히 influential 하다.&lt;/li&gt;
      &lt;li&gt;In this model, they amplify these key layers by increasing their channels, &lt;strong&gt;which can balance the channel ratio between the input and output of a layer to avoid a low MoC.&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;이런 key layer들을 &lt;strong&gt;amplify&lt;/strong&gt; 했음(channel 수를 늘리면서)&lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;layer &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l&lt;/code&gt; has an initial growth rate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt;, we let its channel number to be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k * m^n&lt;/code&gt; , where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; is the max number satisfying that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l&lt;/code&gt; is divided by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2^n&lt;/code&gt;
&lt;img width=&quot;442&quot; alt=&quot;스크린샷 2020-09-11 오후 10 11 01&quot; src=&quot;https://user-images.githubusercontent.com/48315997/92929542-af742280-f47b-11ea-89b9-22e4e5e9331d.png&quot; /&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m&lt;/code&gt;  은 low-dimensional compression factor 역할을 한다.&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m&lt;/code&gt; 을 2보다 작게하면 input channel을 output channel보다 작게 할 수 있다.
            &lt;ul&gt;
              &lt;li&gt;Empirically, settin &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m&lt;/code&gt; between 1.6 and 1.9&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;transition-and-bottleneck-layers&quot;&gt;Transition and Bottleneck Layers&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HDB(Harmonic Dense Block)&lt;/code&gt; : the proposed connection pattern forms a group of layers
    &lt;ul&gt;
      &lt;li&gt;is followed by a Conv1x1 layer as a transition&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;HDB의 depth는 2의 제곱수로 설정
    &lt;ul&gt;
      &lt;li&gt;HDB의 마지막 레이어가 가장 큰 채널수를 가지도록 하기 위해서&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;DenseNet -&amp;gt; gradient할 때 모든 레이어를 다 pass함&lt;/li&gt;
  &lt;li&gt;논문의 HBD with depth L -&amp;gt; pass through at most &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log L layers&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;degradation을 완화시키기위해, depth-L HDB를 layer L과 all its preceeding &lt;strong&gt;odd numbered layers&lt;/strong&gt;  를 concatenation시킨다.&lt;/li&gt;
      &lt;li&gt;2~L-2의 all even layer들의 아웃풋은 HDB가 한번 끝날때마다 버려진다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bottleneck layer
    &lt;ul&gt;
      &lt;li&gt;DenseNet에서는 param. efficiency를 위해 매 Conv3x3 layer전에 bottleneck을 두었다.&lt;/li&gt;
      &lt;li&gt;하지만 HarDnet에서는 위에서 &lt;strong&gt;이미 channel ratio(매 레이어마다 input&amp;amp;output 사이의)의 균형을 잡았으므로 bottleneck layer는 쓸모없어진다.&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;그래서 HBD에서는 Bottleneck layer없이 &lt;strong&gt;Conv3x3 for all layers&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Transition layer
    &lt;ul&gt;
      &lt;li&gt;&lt;img width=&quot;492&quot; alt=&quot;스크린샷 2020-09-11 오후 10 26 18&quot; src=&quot;https://user-images.githubusercontent.com/48315997/92931026-d16ea480-f47d-11ea-96df-eff3717796b9.png&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;inverted trainsition module
        &lt;ul&gt;
          &lt;li&gt;maps input tensor to an additional max pooling function along with the original average pooling, followed by concatenation and Conv1x1.&lt;/li&gt;
          &lt;li&gt;50% of CIO를 감소시킴&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;p&gt;&lt;img width=&quot;483&quot; alt=&quot;스크린샷 2020-09-11 오후 10 27 05&quot; src=&quot;https://user-images.githubusercontent.com/48315997/92931109-ed724600-f47d-11ea-81a6-d3903463743b.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;CamVid Dataset&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;replace all the blocks in a FC-DenseNet with HDBs&lt;/li&gt;
      &lt;li&gt;the architecture of FC-DenseNet with an encoder-decoder structure and block level shortcuts to create models for sematic segmentation.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;p&gt;We propose FC-HarDNet84 as specified in Table 3 for comparing with FC-DenseNet103. &lt;strong&gt;The new network achieves CIO reduction by 41% and GPU inference time reduction by 35%.&lt;/strong&gt; A smaller version, FC-HarDNet68, also outperforms FC-DenseNet56 by a 65% less CIO and 52% less GPU inference time.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img width=&quot;1009&quot; alt=&quot;스크린샷 2020-09-11 오후 10 34 16&quot; src=&quot;https://user-images.githubusercontent.com/48315997/92931776-ee57a780-f47e-11ea-9201-93de47f4a12a.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ImageNet Datasets&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img width=&quot;1018&quot; alt=&quot;스크린샷 2020-09-11 오후 10 34 41&quot; src=&quot;https://user-images.githubusercontent.com/48315997/92931811-fca5c380-f47e-11ea-9c47-4b9738f47a92.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Object Detection
    &lt;ul&gt;
      &lt;li&gt;HarDNet-68 as &lt;strong&gt;a backbone model for a Single Shot Detector (SSD) and train it with PASCAL VOC 2007 and MS COCO datasets&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img width=&quot;479&quot; alt=&quot;스크린샷 2020-09-11 오후 10 35 26&quot; src=&quot;https://user-images.githubusercontent.com/48315997/92931875-1810ce80-f47f-11ea-9883-8d1d9ac87947.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;discussion&quot;&gt;Discussion&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;There is an assumption with the &lt;strong&gt;CIO&lt;/strong&gt;, which is &lt;strong&gt;a CNN model that is processed layer by layer without a fusion.&lt;/strong&gt; In contrast, &lt;strong&gt;fused-layer computation for multiple convolutional layers has been proposed.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CIO still failed&lt;/strong&gt; to predict the actual inference time &lt;strong&gt;such as comparing two network models with significantly differnent architectures&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;In some of the layers CIO may dominate, but for the other layers, MACs can still be the key factor if its computational density is relatively higher. To precisely predict the inference latency of a network, we need to breakdown to each of the layers and investigate its MoC to predict the inference latency of the layer.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;어쨌거나 &lt;strong&gt;DRAM traffic의 중요성&lt;/strong&gt;을 강조하고 싶어함.&lt;/li&gt;
  &lt;li&gt;traffic reduction을 위한 가장 좋은 방법은 &lt;strong&gt;MoC를 증가시키는 것&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;which might be counter-intuitive to the widely-accepted knowledge of that using more Conv1x1 achieves a higher efficiency.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Yeonsoo Kim</name></author><category term="Deep Learning" /><category term="Traffic" /><category term="Computer Vision" /><category term="Semantic Segmentation" /><category term="Network" /><summary type="html">HarDNet : A Low Memory Traffic network 를 읽고 개인적으로 정리한 글입니다.</summary></entry><entry><title type="html">딥러닝 모델을 이용한 수화 교육 웹 어플리케이션-Handlang(1)</title><link href="http://localhost:4000/project/2020/08/26/Handlang/" rel="alternate" type="text/html" title="딥러닝 모델을 이용한 수화 교육 웹 어플리케이션-Handlang(1)" /><published>2020-08-26T00:00:00+09:00</published><updated>2020-08-26T00:00:00+09:00</updated><id>http://localhost:4000/project/2020/08/26/Handlang</id><content type="html" xml:base="http://localhost:4000/project/2020/08/26/Handlang/">&lt;p&gt;DSC EWHA에서 2019.9~2020.8 까지 진행한 팀프로젝트로, 딥러닝 모델을 이용한 수화 학습 웹 어플리케이션입니다.
이 포스팅에서는 수화 인식 딥러닝 모델에 대해서만 다룹니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;handlang---aslamerican-sign-language-education-by-using-deep-learning-model&quot;&gt;Handlang - ASL(American Sign Language) Education by using deep learning model&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/90604151-60015480-e237-11ea-8092-65387889b31d.png&quot; alt=&quot;home-page&quot; /&gt;&lt;/p&gt;

&lt;p&gt;딥러닝으로 학습된 수화 인식 모델을 바탕으로 알파벳, 숫자에 해당되는 수화를 학습 및 연습 할 수 있는 웹 어플리케이션입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;모델-정확도-개선을-위한-여러-시도들&quot;&gt;모델 정확도 개선을 위한 여러 시도들&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;[About models]&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;yolo-darknet&quot;&gt;YOLO darknet&lt;/h4&gt;

&lt;p&gt;YOLO is the model with excellent performance in Object detection.
We used darkflow, not yolo darknet, to take advantage of tensorflow.&lt;/p&gt;

&lt;p&gt;https://github.com/thtrieu/darkflow&lt;/p&gt;

&lt;p&gt;The most attempts were made at darkflow.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;YOLO_experiment_1
    &lt;ul&gt;
      &lt;li&gt;[a~z] 600 images each. training 500 epochs&lt;/li&gt;
      &lt;li&gt;acc : 0.42&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Feedback -&amp;gt; Predict performance is poor.&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;YOLO_experiment_2
    &lt;ul&gt;
      &lt;li&gt;pretrained weight - hand tracking model (https://github.com/Abdul-Mukit/dope_with_hand_tracking)&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;excluding `j`&quot;&gt;a~y&lt;/a&gt; 600 images each. 140 epochs&lt;/li&gt;
      &lt;li&gt;acc : 0.47&lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;https://github.com/yskim0/GoogleSolutionChallenge_Handlang/raw/master/img/47.png&quot; alt=&quot;047&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;YOLO_experiment_3
    &lt;ul&gt;
      &lt;li&gt;pretrained weight - yolov2-tiny.weight(https://pjreddie.com/darknet/yolov2/)&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;excluding `j`&quot;&gt;a~y&lt;/a&gt; 600 images each. 220 epochs&lt;/li&gt;
      &lt;li&gt;acc : 0.56&lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;https://github.com/yskim0/GoogleSolutionChallenge_Handlang/raw/master/img/56.png&quot; alt=&quot;056&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Feedback -&amp;gt; It is still not a satisfactory performance.&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;inception-v3&quot;&gt;Inception-v3&lt;/h4&gt;

&lt;p&gt;We tried transfer learning by using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;inception-v3&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;excluding `j`&quot;&gt;a~y&lt;/a&gt; 600 images each. 1000 steps&lt;/li&gt;
  &lt;li&gt;test acc. : about 88%
    &lt;ul&gt;
      &lt;li&gt;but not that much at real-time…&lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;https://github.com/yskim0/GoogleSolutionChallenge_Handlang/raw/master/img/88.png&quot; alt=&quot;088&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;tensorflow-object-detection-api&quot;&gt;Tensorflow-Object-Detection-API&lt;/h4&gt;

&lt;p&gt;We tried transfer learning by using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fast r-cnn&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;excluding `j`&quot;&gt;a~y&lt;/a&gt; 600 images each. 6000 steps&lt;/li&gt;
  &lt;li&gt;test acc. : about 80%
    &lt;ul&gt;
      &lt;li&gt;not test by images, but test by webcam.
        &lt;ul&gt;
          &lt;li&gt;poor performance&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Self-feedback: It is still not a satisfactory performance.&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;finally-custom-cnn-modelour-current-model&quot;&gt;Finally Custom CNN model(our current model)!&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;handlang_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'adam'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;accuracy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Feedback : 위 모델을 사용하고, 웹 코드 내에서의 trick을 이용하여 조금 더 빠른 인식과 높은 정확도를 가질 수 있었음.&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;datasets&quot;&gt;Datasets&lt;/h2&gt;

&lt;p&gt;아래 데이터 셋들은 모델 트레이닝에 사용되었습니다.&lt;/p&gt;

&lt;p&gt;참고로, 우리 모델에서는 알파벳 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i,z&lt;/code&gt; 제외했습니다. (손동작이 포함되었기 때문에)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;https://www.kaggle.com/grassknoted/asl-alphabet
    &lt;ul&gt;
      &lt;li&gt;가장 성능이 좋은 모델에 사용된 데이터 셋입니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다른 모델에서는 아래의 데이터셋들을 사용했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/rajarshighoshal/asltestimages&quot;&gt;https://www.kaggle.com/rajarshighoshal/asltestimages&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/muhammadkhalid/sign-language-for-alphabets&quot;&gt;https://www.kaggle.com/muhammadkhalid/sign-language-for-alphabets&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/ayuraj/asl-dataset&quot;&gt;https://www.kaggle.com/ayuraj/asl-dataset&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;team-handlang&quot;&gt;Team Handlang&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/yskim0/Handlang&quot;&gt;Project Github Link&lt;/a&gt;&lt;/p&gt;</content><author><name>Yeonsoo Kim</name></author><category term="Deep Learning" /><category term="Object Detection" /><category term="Flask" /><category term="Education Application" /><summary type="html">DSC EWHA에서 2019.9~2020.8 까지 진행한 팀프로젝트로, 딥러닝 모델을 이용한 수화 학습 웹 어플리케이션입니다. 이 포스팅에서는 수화 인식 딥러닝 모델에 대해서만 다룹니다.</summary></entry><entry><title type="html">딥러닝 모델을 이용한 수화 교육 웹 어플리케이션-Handlang(2)</title><link href="http://localhost:4000/project/2020/08/26/Handlang2/" rel="alternate" type="text/html" title="딥러닝 모델을 이용한 수화 교육 웹 어플리케이션-Handlang(2)" /><published>2020-08-26T00:00:00+09:00</published><updated>2020-08-26T00:00:00+09:00</updated><id>http://localhost:4000/project/2020/08/26/Handlang2</id><content type="html" xml:base="http://localhost:4000/project/2020/08/26/Handlang2/">&lt;p&gt;DSC EWHA에서 2019.9~2020.8 까지 진행한 팀프로젝트로, 딥러닝 모델을 이용한 수화 학습 웹 어플리케이션입니다.
이 포스팅에서는 웹에 관련된 것을 다룹니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;handlang---aslamerican-sign-language-education-by-using-deep-learning-model&quot;&gt;Handlang - ASL(American Sign Language) Education by using deep learning model&lt;/h1&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;딥러닝으로 학습된 수화 인식 모델을 바탕으로 알파벳, 숫자에 해당되는 수화를 학습 및 연습 할 수 있는 웹 어플리케이션입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;wireframe---figma&quot;&gt;Wireframe - Figma&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fn8Hg1%2FbtqCPBw0VEs%2F6fRBkKw5iK71fcigASJIC0%2Fimg.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/93708908-f5fd0780-fb74-11ea-950e-adbd44260edd.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figma를 사용하여 팀원들과 홈페이지 와이어프레임을 구상하였습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;flask&quot;&gt;Flask&lt;/h2&gt;

&lt;p&gt;웹 개발 초보자에게 비교적 쉬운 Flask를 사용하여 구현하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;model-deploy&quot;&gt;Model Deploy&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;학습시킨 모델을 불러오는 법&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_model&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'model/handlang_model_4.h5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 지문자 모델
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'model/su_adamax.h5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 숫자 모델
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;ajax&quot;&gt;Ajax&lt;/h2&gt;

&lt;p&gt;웹캠으로 받은 이미지를 실시간으로 Detect해야하기 때문에 페이지를 새로 고치지 않아도 데이터를 로드할 수 있는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ajax&lt;/code&gt;를 사용하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;translation&quot;&gt;Translation&lt;/h2&gt;

&lt;p&gt;한글/영어 버전의 웹페이지를 구현하기 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flask_babel&lt;/code&gt;을 사용했습니다.&lt;/p&gt;

&lt;h2 id=&quot;study--quiz&quot;&gt;Study &amp;amp; Quiz&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/93709264-fa76ef80-fb77-11ea-99c2-33eccceb6f65.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/93709269-05ca1b00-fb78-11ea-85c1-ad523fd94f95.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/93709270-0cf12900-fb78-11ea-9d04-4dbf3a648ea3.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/48315997/93709273-12e70a00-fb78-11ea-999f-71a7f8876db6.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;team-handlang&quot;&gt;Team Handlang&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/yskim0/Handlang&quot;&gt;Project Github Link&lt;/a&gt;&lt;/p&gt;</content><author><name>Yeonsoo Kim</name></author><category term="Deep Learning" /><category term="Object Detection" /><category term="Flask" /><category term="Education Application" /><summary type="html">DSC EWHA에서 2019.9~2020.8 까지 진행한 팀프로젝트로, 딥러닝 모델을 이용한 수화 학습 웹 어플리케이션입니다. 이 포스팅에서는 웹에 관련된 것을 다룹니다.</summary></entry><entry><title type="html">Next Theme Tutorial</title><link href="http://localhost:4000/tutorial/2017/07/20/next-tutorial/" rel="alternate" type="text/html" title="Next Theme Tutorial" /><published>2017-07-20T00:00:00+09:00</published><updated>2017-07-20T00:00:00+09:00</updated><id>http://localhost:4000/tutorial/2017/07/20/next-tutorial</id><content type="html" xml:base="http://localhost:4000/tutorial/2017/07/20/next-tutorial/">&lt;blockquote&gt;
  &lt;p&gt;NexT is a high quality elegant &lt;a href=&quot;https://jekyllrb.com&quot;&gt;Jekyll&lt;/a&gt; theme ported from &lt;a href=&quot;https://github.com/iissnan/hexo-theme-next&quot;&gt;Hexo Next&lt;/a&gt;. It is crafted from scratch, with love.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;a href=&quot;http://simpleyyt.github.io/jekyll-theme-next/&quot;&gt;Live Preview&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;screenshots&quot;&gt;Screenshots&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Desktop
&lt;img src=&quot;http://iissnan.com/nexus/next/desktop-preview.png&quot; alt=&quot;Desktop Preview&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sidebar&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://iissnan.com/nexus/next/desktop-sidebar-preview.png&quot; alt=&quot;Desktop Sidebar Preview&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sidebar (Post details page)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://iissnan.com/nexus/next/desktop-sidebar-toc.png&quot; alt=&quot;Desktop Sidebar Preview&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mobile&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://iissnan.com/nexus/next/mobile.png&quot; alt=&quot;Mobile Preview&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;installation&quot;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Check whether you have &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ruby 2.1.0&lt;/code&gt; or higher installed:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ruby &lt;span class=&quot;nt&quot;&gt;--version&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Install &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Bundler&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gem &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;bundler
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Clone Jacman theme:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/Simpleyyt/jekyll-theme-next.git
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;jekyll-theme-next
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Install Jekyll and other dependencies from the GitHub Pages gem:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bundle &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Run your Jekyll site locally:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bundle &lt;span class=&quot;nb&quot;&gt;exec &lt;/span&gt;jekyll server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;More Details：&lt;a href=&quot;https://help.github.com/articles/setting-up-your-github-pages-site-locally-with-jekyll/&quot;&gt;Setting up your GitHub Pages site locally with Jekyll&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;features&quot;&gt;Features&lt;/h2&gt;

&lt;h3 id=&quot;multiple-languages-support-including-english--russian--french--german--simplified-chinese--traditional-chinese&quot;&gt;Multiple languages support, including: English / Russian / French / German / Simplified Chinese / Traditional Chinese.&lt;/h3&gt;

&lt;p&gt;Default language is English.&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;en&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# language: zh-Hans&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# language: fr-FR&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# language: zh-hk&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# language: zh-tw&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# language: ru&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# language: de&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;language&lt;/code&gt; field as following in site &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; to change to Chinese.&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;zh-Hans&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;comment-support&quot;&gt;Comment support.&lt;/h3&gt;

&lt;p&gt;NexT has native support for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DuoShuo&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Disqus&lt;/code&gt; comment systems.&lt;/p&gt;

&lt;p&gt;Add the following snippets to your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;duoshuo&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;enable&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;shortname&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-duoshuo-shortname&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;OR&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;disqus_shortname&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-disqus-shortname&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;social-media&quot;&gt;Social Media&lt;/h3&gt;

&lt;p&gt;NexT can automatically add links to your Social Media accounts:&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;social&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;GitHub&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-github-url&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;Twitter&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-twitter-url&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;Weibo&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-weibo-url&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;DouBan&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-douban-url&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;ZhiHu&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-zhihu-url&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;feed-link&quot;&gt;Feed link.&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Show a feed link.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rss&lt;/code&gt; field in theme’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt;, as the following value:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rss: false&lt;/code&gt; will totally disable feed link.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rss:  &lt;/code&gt; use sites’ feed link. This is the default option.&lt;/p&gt;

    &lt;p&gt;Follow the installation instruction in the plugin’s README. After the configuration is done for this plugin, the feed link is ready too.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rss: http://your-feed-url&lt;/code&gt; set specific feed link.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;up-to-5-code-highlight-themes-built-in&quot;&gt;Up to 5 code highlight themes built-in.&lt;/h3&gt;

&lt;p&gt;NexT uses &lt;a href=&quot;https://github.com/chriskempson/tomorrow-theme&quot;&gt;Tomorrow Theme&lt;/a&gt; with 5 themes for you to choose from.
Next use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;normal&lt;/code&gt; by default. Have a preview about &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;normal&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;night&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://iissnan.com/nexus/next/tomorrow-normal.png&quot; alt=&quot;Tomorrow Normal Preview&quot; /&gt;
&lt;img src=&quot;http://iissnan.com/nexus/next/tomorrow-night.png&quot; alt=&quot;Tomorrow Night Preview&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Head over to &lt;a href=&quot;https://github.com/chriskempson/tomorrow-theme&quot;&gt;Tomorrow Theme&lt;/a&gt; for more details.&lt;/p&gt;

&lt;h2 id=&quot;configuration&quot;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;NexT comes with few configurations.&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;c1&quot;&gt;# Menu configuration.&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;menu&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;archives&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/archives&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Favicon&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;favicon&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/favicon.ico&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Avatar (put the image into next/source/images/)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# can be any image format supported by web browsers (JPEG,PNG,GIF,SVG,..)&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;avatar&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/default_avatar.png&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Code highlight theme&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# available: normal | night | night eighties | night blue | night bright&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;highlight_theme&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;normal&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Fancybox for image gallery&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;fancybox&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Specify the date when the site was setup&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;since&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2013&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;browser-support&quot;&gt;Browser support&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://iissnan.com/nexus/next/browser-support.png&quot; alt=&quot;Browser support&quot; /&gt;&lt;/p&gt;</content><author><name>Yeonsoo Kim</name></author><summary type="html">NexT is a high quality elegant Jekyll theme ported from Hexo Next. It is crafted from scratch, with love. Live Preview Screenshots Desktop Sidebar Sidebar (Post details page) Mobile Installation Check whether you have Ruby 2.1.0 or higher installed: ruby --version Install Bundler: gem install bundler Clone Jacman theme: git clone https://github.com/Simpleyyt/jekyll-theme-next.git cd jekyll-theme-next Install Jekyll and other dependencies from the GitHub Pages gem: bundle install Run your Jekyll site locally: bundle exec jekyll server More Details：Setting up your GitHub Pages site locally with Jekyll Features Multiple languages support, including: English / Russian / French / German / Simplified Chinese / Traditional Chinese. Default language is English. language: en # language: zh-Hans # language: fr-FR # language: zh-hk # language: zh-tw # language: ru # language: de Set language field as following in site _config.yml to change to Chinese. language: zh-Hans Comment support. NexT has native support for DuoShuo and Disqus comment systems. Add the following snippets to your _config.yml: duoshuo: enable: true shortname: your-duoshuo-shortname OR disqus_shortname: your-disqus-shortname Social Media NexT can automatically add links to your Social Media accounts: social: GitHub: your-github-url Twitter: your-twitter-url Weibo: your-weibo-url DouBan: your-douban-url ZhiHu: your-zhihu-url Feed link. Show a feed link. Set rss field in theme’s _config.yml, as the following value: rss: false will totally disable feed link. rss: use sites’ feed link. This is the default option. Follow the installation instruction in the plugin’s README. After the configuration is done for this plugin, the feed link is ready too. rss: http://your-feed-url set specific feed link. Up to 5 code highlight themes built-in. NexT uses Tomorrow Theme with 5 themes for you to choose from. Next use normal by default. Have a preview about normal and night: Head over to Tomorrow Theme for more details. Configuration NexT comes with few configurations. # Menu configuration. menu: home: / archives: /archives # Favicon favicon: /favicon.ico # Avatar (put the image into next/source/images/) # can be any image format supported by web browsers (JPEG,PNG,GIF,SVG,..) avatar: /default_avatar.png # Code highlight theme # available: normal | night | night eighties | night blue | night bright highlight_theme: normal # Fancybox for image gallery fancybox: true # Specify the date when the site was setup since: 2013 Browser support</summary></entry><entry><title type="html">Gallery Post</title><link href="http://localhost:4000/photo/2014/11/19/gallery-post/" rel="alternate" type="text/html" title="Gallery Post" /><published>2014-11-19T00:45:20+09:00</published><updated>2014-11-19T00:45:20+09:00</updated><id>http://localhost:4000/photo/2014/11/19/gallery-post</id><content type="html" xml:base="http://localhost:4000/photo/2014/11/19/gallery-post/">&lt;p&gt;Nunc dignissim volutpat enim, non sollicitudin purus dignissim id. Nam sit amet urna eu velit lacinia eleifend. Proin auctor rhoncus ligula nec aliquet. Donec sodales molestie lacinia. Curabitur dictum faucibus urna at convallis. Aliquam in lectus at urna rutrum porta. In lacus arcu, molestie ut vestibulum ut, rhoncus sed eros. Sed et elit vitae risus pretium consectetur vel in mi. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi tempus turpis quis lectus rhoncus adipiscing. Proin pulvinar placerat suscipit. Maecenas imperdiet, quam vitae varius auctor, enim mauris vulputate sapien, nec laoreet neque diam non quam.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/81b78497jw1emfgts2pt4j21hc0u0k1c.jpg&quot; alt=&quot;Wallbase - dgnfly (wallbase.cc/wallpaper/1384450)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Etiam luctus mauris at mi sollicitudin quis malesuada nibh porttitor. Vestibulum non dapibus magna. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Proin feugiat hendrerit viverra. Phasellus sit amet nunc mauris, eu ultricies tellus. Sed a mi tortor, eleifend varius erat. Proin consectetur molestie tortor eu gravida. Cras placerat orci id arcu tristique ut rutrum justo pulvinar. Maecenas lacinia fringilla diam non bibendum. Aenean vel viverra turpis. Integer ut leo nisi. Pellentesque vehicula quam ut sapien convallis consequat. Aliquam ut arcu purus, eget tempor purus. Integer eu tellus quis erat tristique gravida eu vel lorem.&lt;/p&gt;</content><author><name>Yeonsoo Kim</name></author><category term="Photo" /><category term="consectetur" /><summary type="html">Nunc dignissim volutpat enim, non sollicitudin purus dignissim id. Nam sit amet urna eu velit lacinia eleifend. Proin auctor rhoncus ligula nec aliquet. Donec sodales molestie lacinia. Curabitur dictum faucibus urna at convallis. Aliquam in lectus at urna rutrum porta. In lacus arcu, molestie ut vestibulum ut, rhoncus sed eros. Sed et elit vitae risus pretium consectetur vel in mi. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi tempus turpis quis lectus rhoncus adipiscing. Proin pulvinar placerat suscipit. Maecenas imperdiet, quam vitae varius auctor, enim mauris vulputate sapien, nec laoreet neque diam non quam.</summary></entry><entry><title type="html">MathJax with Jekyll</title><link href="http://localhost:4000/opinion/2014/02/16/Mathjax-with-jekyll/" rel="alternate" type="text/html" title="MathJax with Jekyll" /><published>2014-02-16T00:00:00+09:00</published><updated>2014-02-16T00:00:00+09:00</updated><id>http://localhost:4000/opinion/2014/02/16/Mathjax-with-jekyll</id><content type="html" xml:base="http://localhost:4000/opinion/2014/02/16/Mathjax-with-jekyll/">&lt;p&gt;One of the rewards of switching my website to &lt;a href=&quot;http://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt; is the
ability to support &lt;strong&gt;MathJax&lt;/strong&gt;, which means I can write LaTeX-like equations that get
nicely displayed in a web browser, like this one \( \sqrt{\frac{n!}{k!(n-k)!}} \) or
this one \( x^2 + y^2 = r^2 \).&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;img class=&quot;centered&quot; src=&quot;https://www.mathjax.org/badge/mj-logo.svg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;whats-mathjax&quot;&gt;What’s MathJax?&lt;/h3&gt;

&lt;p&gt;If you check MathJax website &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;(www.mathjax.org)&lt;/a&gt; you’ll see
that it &lt;em&gt;is an open source JavaScript display engine for mathematics that works in all
browsers&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;how-to-implement-mathjax-with-jekyll&quot;&gt;How to implement MathJax with Jekyll&lt;/h3&gt;

&lt;p&gt;I followed the instructions described by Dason Kurkiewicz for
&lt;a href=&quot;http://dasonk.github.io/blog/2012/10/09/Using-Jekyll-and-Mathjax/&quot;&gt;using Jekyll and Mathjax&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here are some important details. I had to modify the Ruby library for Markdown in
my &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; file. Now I’m using redcarpet so the corresponding line in the
configuration file is: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;markdown: redcarpet&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To load the MathJax javascript, I added the following lines in my layout &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;post.html&lt;/code&gt;
(located in my folder &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_layouts&lt;/code&gt;)&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text/javascript&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Of course you can choose a different file location in your jekyll layouts.&lt;/p&gt;

&lt;p&gt;Note that by default, the &lt;strong&gt;tex2jax&lt;/strong&gt; preprocessor defines the
LaTeX math delimiters, which are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\\(...\\)&lt;/code&gt; for in-line math, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\\[...\\]&lt;/code&gt; for
displayed equations. It also defines the TeX delimiters &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$$...$$&lt;/code&gt; for displayed
equations, but it does not define &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$...$&lt;/code&gt; as in-line math delimiters. To enable in-line math delimiter with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$...$&lt;/code&gt;, please use the following configuration:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text/x-mathjax-config&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MathJax.Hub.Config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tex2jax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inlineMath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'\\('&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'\\)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;processEscapes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text/javascript&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;a-couple-of-examples&quot;&gt;A Couple of Examples&lt;/h3&gt;

&lt;p&gt;Here’s a short list of examples. To know more about the details behind MathJax, you can
always checked the provided documentation available at
&lt;a href=&quot;http://docs.mathjax.org/en/latest/&quot;&gt;http://docs.mathjax.org/en/latest/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let’s try a first example. Here’s a dummy equation:&lt;/p&gt;

\[a^2 + b^2 = c^2\]

&lt;p&gt;How do you write such expression? Very simple: using &lt;strong&gt;double dollar&lt;/strong&gt; signs&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;$$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$$&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To display inline math use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\\( ... \\)&lt;/code&gt; like this &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\\( sin(x^2) \\)&lt;/code&gt; which gets
rendered as \( sin(x^2) \)&lt;/p&gt;

&lt;p&gt;Here’s another example using type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathsf&lt;/code&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;$$&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mathsf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PCs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;times&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mathsf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Loadings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$$&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;which gets displayed as&lt;/p&gt;

\[\mathsf{Data = PCs} \times \mathsf{Loadings}\]

&lt;p&gt;Or even better:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mathbf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mathbf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mathbf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mathsf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;is displayed as&lt;/p&gt;

&lt;p&gt;\[ \mathbf{X} = \mathbf{Z} \mathbf{P^\mathsf{T}} \]&lt;/p&gt;

&lt;p&gt;If you want to use subscripts like this \( \mathbf{X}_{n,p} \) you need to scape the
underscores with a backslash like so &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathbf{X}\_{n,p}&lt;/code&gt;:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;$$&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mathbf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mathbf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mathbf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$$&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;will be displayed as&lt;/p&gt;

&lt;p&gt;\[ \mathbf{X}_{n,p} = \mathbf{A}_{n,k} \mathbf{B}_{k,p} \]&lt;/p&gt;

&lt;hr /&gt;

\[\lim_{x\to 0}{\frac{e^x-1}{2x}}
\overset{\left[\frac{0}{0}\right]}{\underset{\mathrm{H}}{=}}
\lim_{x\to 0}{\frac{e^x}{2}}={\frac{1}{2}}\]</content><author><name>Yeonsoo Kim</name></author><category term="resources" /><category term="jekyll" /><summary type="html">One of the rewards of switching my website to Jekyll is the ability to support MathJax, which means I can write LaTeX-like equations that get nicely displayed in a web browser, like this one \( \sqrt{\frac{n!}{k!(n-k)!}} \) or this one \( x^2 + y^2 = r^2 \).</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://gastonsanchez.com/images/blog/mathjax_logo.png" /><media:content medium="image" url="http://gastonsanchez.com/images/blog/mathjax_logo.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>